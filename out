E:\Anaconda\envs\py310\python.exe E:\important\Transformer\GANLDA1-master\main1.py
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 1 times train_loss is tensor(0.7219, grad_fn=<BinaryCrossEntropyBackward0>)
0.8552706658757113 0.10178676934739937 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 2 times train_loss is tensor(0.6894, grad_fn=<BinaryCrossEntropyBackward0>)
0.8619519344925084 0.12289064777966949 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 3 times train_loss is tensor(0.6849, grad_fn=<BinaryCrossEntropyBackward0>)
0.8622666327123073 0.13536055631998903 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 4 times train_loss is tensor(0.6808, grad_fn=<BinaryCrossEntropyBackward0>)
0.8618250192421166 0.14607324027926316 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 5 times train_loss is tensor(0.6770, grad_fn=<BinaryCrossEntropyBackward0>)
0.8614456521482238 0.15120171715183556 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 6 times train_loss is tensor(0.6732, grad_fn=<BinaryCrossEntropyBackward0>)
0.861215189888376 0.15413191917121757 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 7 times train_loss is tensor(0.6694, grad_fn=<BinaryCrossEntropyBackward0>)
0.8611471531514924 0.15526423874774473 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 8 times train_loss is tensor(0.6656, grad_fn=<BinaryCrossEntropyBackward0>)
0.8612001920666545 0.15588491260623527 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 9 times train_loss is tensor(0.6618, grad_fn=<BinaryCrossEntropyBackward0>)
0.8613440648016191 0.15611787189663032 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 10 times train_loss is tensor(0.6577, grad_fn=<BinaryCrossEntropyBackward0>)
0.8615754724264603 0.15698197296166239 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 11 times train_loss is tensor(0.6536, grad_fn=<BinaryCrossEntropyBackward0>)
0.8618695104821283 0.15714669224515 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 12 times train_loss is tensor(0.6492, grad_fn=<BinaryCrossEntropyBackward0>)
0.8622168631844147 0.15693090812375737 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 13 times train_loss is tensor(0.6447, grad_fn=<BinaryCrossEntropyBackward0>)
0.8625942903105603 0.15697056094775447 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 14 times train_loss is tensor(0.6400, grad_fn=<BinaryCrossEntropyBackward0>)
0.8630005510690109 0.15716577588641895 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 15 times train_loss is tensor(0.6350, grad_fn=<BinaryCrossEntropyBackward0>)
0.863424763914788 0.15700813909130998 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 16 times train_loss is tensor(0.6299, grad_fn=<BinaryCrossEntropyBackward0>)
0.8638659736353458 0.15680956447351366 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 17 times train_loss is tensor(0.6246, grad_fn=<BinaryCrossEntropyBackward0>)
0.8643211077944556 0.15678229042361172 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 18 times train_loss is tensor(0.6192, grad_fn=<BinaryCrossEntropyBackward0>)
0.8647681866560157 0.15660561781870133 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 19 times train_loss is tensor(0.6137, grad_fn=<BinaryCrossEntropyBackward0>)
0.8652065110438326 0.1567530398095982 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 20 times train_loss is tensor(0.6080, grad_fn=<BinaryCrossEntropyBackward0>)
0.8656400889115776 0.15694410414318336 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 21 times train_loss is tensor(0.6024, grad_fn=<BinaryCrossEntropyBackward0>)
0.8660622928567433 0.15728405200474413 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 22 times train_loss is tensor(0.5968, grad_fn=<BinaryCrossEntropyBackward0>)
0.8664916165820171 0.15729902309184163 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 23 times train_loss is tensor(0.5913, grad_fn=<BinaryCrossEntropyBackward0>)
0.8669029094395482 0.1572797679551937 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 24 times train_loss is tensor(0.5859, grad_fn=<BinaryCrossEntropyBackward0>)
0.86731576805785 0.1574163484909812 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 25 times train_loss is tensor(0.5807, grad_fn=<BinaryCrossEntropyBackward0>)
0.8677314233809246 0.15748201917253418 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 26 times train_loss is tensor(0.5756, grad_fn=<BinaryCrossEntropyBackward0>)
0.8681669609115209 0.15755258817193885 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 27 times train_loss is tensor(0.5706, grad_fn=<BinaryCrossEntropyBackward0>)
0.8686207459560042 0.15830658366224093 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 28 times train_loss is tensor(0.5657, grad_fn=<BinaryCrossEntropyBackward0>)
0.869105334143196 0.1590631809122292 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 29 times train_loss is tensor(0.5608, grad_fn=<BinaryCrossEntropyBackward0>)
0.8696199081262788 0.15982031988077514 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 30 times train_loss is tensor(0.5557, grad_fn=<BinaryCrossEntropyBackward0>)
0.8701532515435053 0.16064041482063707 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 31 times train_loss is tensor(0.5505, grad_fn=<BinaryCrossEntropyBackward0>)
0.8707343851306691 0.1616703007563494 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 32 times train_loss is tensor(0.5451, grad_fn=<BinaryCrossEntropyBackward0>)
0.8713528015497684 0.1627214990035159 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 33 times train_loss is tensor(0.5394, grad_fn=<BinaryCrossEntropyBackward0>)
0.8720271717594266 0.16466020996891767 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 34 times train_loss is tensor(0.5334, grad_fn=<BinaryCrossEntropyBackward0>)
0.8727699332178412 0.16728184660642562 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 35 times train_loss is tensor(0.5273, grad_fn=<BinaryCrossEntropyBackward0>)
0.8735712186778912 0.1686035577030937 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 36 times train_loss is tensor(0.5211, grad_fn=<BinaryCrossEntropyBackward0>)
0.874392268174839 0.17042653428037904 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 37 times train_loss is tensor(0.5149, grad_fn=<BinaryCrossEntropyBackward0>)
0.8752206048602791 0.17262024075833154 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 38 times train_loss is tensor(0.5089, grad_fn=<BinaryCrossEntropyBackward0>)
0.8760866872125992 0.17403404617562312 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 39 times train_loss is tensor(0.5033, grad_fn=<BinaryCrossEntropyBackward0>)
0.8769625284889679 0.17810255628618482 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 40 times train_loss is tensor(0.4980, grad_fn=<BinaryCrossEntropyBackward0>)
0.8778197480444732 0.17926527809222415 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 41 times train_loss is tensor(0.4931, grad_fn=<BinaryCrossEntropyBackward0>)
0.8787047770868734 0.18014273363802163 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 42 times train_loss is tensor(0.4886, grad_fn=<BinaryCrossEntropyBackward0>)
0.8795986492309849 0.18019667910237497 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 43 times train_loss is tensor(0.4842, grad_fn=<BinaryCrossEntropyBackward0>)
0.880535210513089 0.17867818146504513 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 44 times train_loss is tensor(0.4797, grad_fn=<BinaryCrossEntropyBackward0>)
0.8814903738209525 0.17854951431263127 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 45 times train_loss is tensor(0.4751, grad_fn=<BinaryCrossEntropyBackward0>)
0.882446512036466 0.17841549129873494 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 46 times train_loss is tensor(0.4704, grad_fn=<BinaryCrossEntropyBackward0>)
0.883413758290654 0.17825533176092412 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 47 times train_loss is tensor(0.4659, grad_fn=<BinaryCrossEntropyBackward0>)
0.8843712948585538 0.17488204010964065 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 48 times train_loss is tensor(0.4617, grad_fn=<BinaryCrossEntropyBackward0>)
0.8853286246278609 0.17454071306776717 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 49 times train_loss is tensor(0.4582, grad_fn=<BinaryCrossEntropyBackward0>)
0.8863545918347249 0.17317399116974008 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 50 times train_loss is tensor(0.4552, grad_fn=<BinaryCrossEntropyBackward0>)
0.8874702210027015 0.16940707605628386 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 51 times train_loss is tensor(0.4524, grad_fn=<BinaryCrossEntropyBackward0>)
0.8887113178309229 0.1644592624398406 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 52 times train_loss is tensor(0.4494, grad_fn=<BinaryCrossEntropyBackward0>)
0.890047246585066 0.15935038521026168 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 53 times train_loss is tensor(0.4462, grad_fn=<BinaryCrossEntropyBackward0>)
0.8914609119148289 0.15344684167906125 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 54 times train_loss is tensor(0.4429, grad_fn=<BinaryCrossEntropyBackward0>)
0.89298404263281 0.14653519934718265 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 55 times train_loss is tensor(0.4397, grad_fn=<BinaryCrossEntropyBackward0>)
0.8945453523099599 0.13750815274218647 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 56 times train_loss is tensor(0.4368, grad_fn=<BinaryCrossEntropyBackward0>)
0.8960465623771517 0.12573050940464153 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 57 times train_loss is tensor(0.4342, grad_fn=<BinaryCrossEntropyBackward0>)
0.8973697090087769 0.1106373790614755 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 58 times train_loss is tensor(0.4316, grad_fn=<BinaryCrossEntropyBackward0>)
0.8985565064351784 0.09828050353016256 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 59 times train_loss is tensor(0.4288, grad_fn=<BinaryCrossEntropyBackward0>)
0.8996894869898082 0.09200980008731542 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 60 times train_loss is tensor(0.4260, grad_fn=<BinaryCrossEntropyBackward0>)
0.9008022505201476 0.08960121475361006 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 61 times train_loss is tensor(0.4234, grad_fn=<BinaryCrossEntropyBackward0>)
0.9018870273076557 0.08840642891710909 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 62 times train_loss is tensor(0.4212, grad_fn=<BinaryCrossEntropyBackward0>)
0.9029681801960214 0.08739584907284187 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 63 times train_loss is tensor(0.4193, grad_fn=<BinaryCrossEntropyBackward0>)
0.9040436608944256 0.08639493320924269 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 64 times train_loss is tensor(0.4173, grad_fn=<BinaryCrossEntropyBackward0>)
0.9051501613816824 0.08576337358112379 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 65 times train_loss is tensor(0.4154, grad_fn=<BinaryCrossEntropyBackward0>)
0.906252929646725 0.08546787054006982 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 66 times train_loss is tensor(0.4136, grad_fn=<BinaryCrossEntropyBackward0>)
0.9073046088119048 0.0852018215834282 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 67 times train_loss is tensor(0.4119, grad_fn=<BinaryCrossEntropyBackward0>)
0.9082828055439354 0.08518995292352763 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 68 times train_loss is tensor(0.4104, grad_fn=<BinaryCrossEntropyBackward0>)
0.909140881836466 0.08539680877037313 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 69 times train_loss is tensor(0.4089, grad_fn=<BinaryCrossEntropyBackward0>)
0.9098737268099997 0.08587709277276957 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 70 times train_loss is tensor(0.4072, grad_fn=<BinaryCrossEntropyBackward0>)
0.9105115035163639 0.08654581965629286 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 71 times train_loss is tensor(0.4055, grad_fn=<BinaryCrossEntropyBackward0>)
0.9111072213280645 0.08747055681960242 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 72 times train_loss is tensor(0.4038, grad_fn=<BinaryCrossEntropyBackward0>)
0.911703490602678 0.08866813158334684 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 73 times train_loss is tensor(0.4021, grad_fn=<BinaryCrossEntropyBackward0>)
0.9123265846089851 0.09009444553061127 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 74 times train_loss is tensor(0.4004, grad_fn=<BinaryCrossEntropyBackward0>)
0.9129686942382367 0.09167562311119083 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 75 times train_loss is tensor(0.3986, grad_fn=<BinaryCrossEntropyBackward0>)
0.9136146148701187 0.09331541014985673 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 76 times train_loss is tensor(0.3968, grad_fn=<BinaryCrossEntropyBackward0>)
0.9142273787943603 0.0949750519484562 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 77 times train_loss is tensor(0.3952, grad_fn=<BinaryCrossEntropyBackward0>)
0.9147909837389341 0.09669111793488683 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 78 times train_loss is tensor(0.3936, grad_fn=<BinaryCrossEntropyBackward0>)
0.9152737107387948 0.09823255145732977 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 79 times train_loss is tensor(0.3920, grad_fn=<BinaryCrossEntropyBackward0>)
0.9156835757012837 0.09965609810472319 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 80 times train_loss is tensor(0.3905, grad_fn=<BinaryCrossEntropyBackward0>)
0.9160443112267608 0.1010221244548371 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 81 times train_loss is tensor(0.3891, grad_fn=<BinaryCrossEntropyBackward0>)
0.9164182523194925 0.10254704514677968 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 82 times train_loss is tensor(0.3877, grad_fn=<BinaryCrossEntropyBackward0>)
0.9168119968393297 0.10413521711917384 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 83 times train_loss is tensor(0.3865, grad_fn=<BinaryCrossEntropyBackward0>)
0.9172378345311895 0.10603546873264437 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 84 times train_loss is tensor(0.3852, grad_fn=<BinaryCrossEntropyBackward0>)
0.9177026685290358 0.10816324835383256 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 85 times train_loss is tensor(0.3839, grad_fn=<BinaryCrossEntropyBackward0>)
0.9181956566780977 0.11064983944698738 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 86 times train_loss is tensor(0.3827, grad_fn=<BinaryCrossEntropyBackward0>)
0.9186822143756928 0.1136027965755237 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 87 times train_loss is tensor(0.3815, grad_fn=<BinaryCrossEntropyBackward0>)
0.9191356055180955 0.1167774173577791 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 88 times train_loss is tensor(0.3803, grad_fn=<BinaryCrossEntropyBackward0>)
0.9195678933565261 0.12006078007918568 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 89 times train_loss is tensor(0.3791, grad_fn=<BinaryCrossEntropyBackward0>)
0.9199747154254418 0.12341536054846783 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 90 times train_loss is tensor(0.3779, grad_fn=<BinaryCrossEntropyBackward0>)
0.9203854765151641 0.12717937631342247 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 91 times train_loss is tensor(0.3767, grad_fn=<BinaryCrossEntropyBackward0>)
0.9208258787364567 0.13168816464236463 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 92 times train_loss is tensor(0.3756, grad_fn=<BinaryCrossEntropyBackward0>)
0.9212761974426301 0.13786839179450938 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 93 times train_loss is tensor(0.3745, grad_fn=<BinaryCrossEntropyBackward0>)
0.9217123258263475 0.14338260962654065 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 94 times train_loss is tensor(0.3734, grad_fn=<BinaryCrossEntropyBackward0>)
0.9220909346587352 0.14801637904964024 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 95 times train_loss is tensor(0.3723, grad_fn=<BinaryCrossEntropyBackward0>)
0.9223897290820269 0.15209651278393754 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 96 times train_loss is tensor(0.3712, grad_fn=<BinaryCrossEntropyBackward0>)
0.9226449874778528 0.1551557394212342 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 97 times train_loss is tensor(0.3701, grad_fn=<BinaryCrossEntropyBackward0>)
0.9228885962196429 0.157946640140173 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 98 times train_loss is tensor(0.3690, grad_fn=<BinaryCrossEntropyBackward0>)
0.9231499797928233 0.1613661900954618 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 99 times train_loss is tensor(0.3678, grad_fn=<BinaryCrossEntropyBackward0>)
0.9234020771244518 0.16509663697227445 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 100 times train_loss is tensor(0.3667, grad_fn=<BinaryCrossEntropyBackward0>)
0.923615808393423 0.16852162075466717 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 101 times train_loss is tensor(0.3655, grad_fn=<BinaryCrossEntropyBackward0>)
0.9237655699644935 0.17051510579891999 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 102 times train_loss is tensor(0.3644, grad_fn=<BinaryCrossEntropyBackward0>)
0.9239020176452376 0.17226813655533912 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 103 times train_loss is tensor(0.3632, grad_fn=<BinaryCrossEntropyBackward0>)
0.9240512277533952 0.1753462320317264 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 104 times train_loss is tensor(0.3621, grad_fn=<BinaryCrossEntropyBackward0>)
0.9242255688142997 0.18042488791574318 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 105 times train_loss is tensor(0.3609, grad_fn=<BinaryCrossEntropyBackward0>)
0.9244439382802707 0.18592141024416792 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 106 times train_loss is tensor(0.3597, grad_fn=<BinaryCrossEntropyBackward0>)
0.924670018379471 0.1911946004280717 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 107 times train_loss is tensor(0.3585, grad_fn=<BinaryCrossEntropyBackward0>)
0.9248921890005207 0.19659038131495168 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 108 times train_loss is tensor(0.3573, grad_fn=<BinaryCrossEntropyBackward0>)
0.9251569207413868 0.20265825380113422 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 109 times train_loss is tensor(0.3561, grad_fn=<BinaryCrossEntropyBackward0>)
0.9254696297556784 0.20994707738598425 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 110 times train_loss is tensor(0.3549, grad_fn=<BinaryCrossEntropyBackward0>)
0.9257527961139196 0.21644767143753404 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 111 times train_loss is tensor(0.3537, grad_fn=<BinaryCrossEntropyBackward0>)
0.9259835341052238 0.2210721285036073 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 112 times train_loss is tensor(0.3525, grad_fn=<BinaryCrossEntropyBackward0>)
0.9262142425538721 0.22533295948835974 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 113 times train_loss is tensor(0.3512, grad_fn=<BinaryCrossEntropyBackward0>)
0.9264689396392329 0.2305227949769586 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 114 times train_loss is tensor(0.3500, grad_fn=<BinaryCrossEntropyBackward0>)
0.9266719272289541 0.2336523276707511 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 115 times train_loss is tensor(0.3487, grad_fn=<BinaryCrossEntropyBackward0>)
0.9268408816789052 0.23583867778014836 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 116 times train_loss is tensor(0.3475, grad_fn=<BinaryCrossEntropyBackward0>)
0.9270399696380276 0.23996596204757042 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 117 times train_loss is tensor(0.3462, grad_fn=<BinaryCrossEntropyBackward0>)
0.9272165854834478 0.24517094130345135 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 118 times train_loss is tensor(0.3450, grad_fn=<BinaryCrossEntropyBackward0>)
0.9273582228241046 0.25038535673255097 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 119 times train_loss is tensor(0.3438, grad_fn=<BinaryCrossEntropyBackward0>)
0.9275111946971326 0.25684144363139916 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 120 times train_loss is tensor(0.3426, grad_fn=<BinaryCrossEntropyBackward0>)
0.9276571058753647 0.2636969557059329 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 121 times train_loss is tensor(0.3413, grad_fn=<BinaryCrossEntropyBackward0>)
0.9277848778627817 0.26924399364417423 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 122 times train_loss is tensor(0.3401, grad_fn=<BinaryCrossEntropyBackward0>)
0.9279393367161644 0.27545558962031 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 123 times train_loss is tensor(0.3389, grad_fn=<BinaryCrossEntropyBackward0>)
0.9280798612834432 0.2801021473264853 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 124 times train_loss is tensor(0.3377, grad_fn=<BinaryCrossEntropyBackward0>)
0.9282182686270386 0.28407485612315186 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 125 times train_loss is tensor(0.3366, grad_fn=<BinaryCrossEntropyBackward0>)
0.9283453709809186 0.2877358761865132 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 126 times train_loss is tensor(0.3354, grad_fn=<BinaryCrossEntropyBackward0>)
0.9284587950850474 0.29054850359707707 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 127 times train_loss is tensor(0.3343, grad_fn=<BinaryCrossEntropyBackward0>)
0.9285660644691658 0.2939524995282346 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 128 times train_loss is tensor(0.3332, grad_fn=<BinaryCrossEntropyBackward0>)
0.9286444312881149 0.2958938546128299 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 129 times train_loss is tensor(0.3321, grad_fn=<BinaryCrossEntropyBackward0>)
0.9287595393236385 0.3001951575835831 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 130 times train_loss is tensor(0.3312, grad_fn=<BinaryCrossEntropyBackward0>)
0.9287450338795179 0.2993966766236232 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 131 times train_loss is tensor(0.3306, grad_fn=<BinaryCrossEntropyBackward0>)
0.9288405157438724 0.3022341348131877 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 132 times train_loss is tensor(0.3303, grad_fn=<BinaryCrossEntropyBackward0>)
0.9288402301648637 0.3016193976718477 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 133 times train_loss is tensor(0.3291, grad_fn=<BinaryCrossEntropyBackward0>)
0.928920408933384 0.3020537786876355 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 134 times train_loss is tensor(0.3274, grad_fn=<BinaryCrossEntropyBackward0>)
0.9289407539758507 0.30127098023167864 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 135 times train_loss is tensor(0.3275, grad_fn=<BinaryCrossEntropyBackward0>)
0.9289928967637794 0.301249402552271 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 136 times train_loss is tensor(0.3265, grad_fn=<BinaryCrossEntropyBackward0>)
0.9290414747378778 0.3005096477454472 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 137 times train_loss is tensor(0.3251, grad_fn=<BinaryCrossEntropyBackward0>)
0.9290121585755241 0.2988337605539848 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 138 times train_loss is tensor(0.3252, grad_fn=<BinaryCrossEntropyBackward0>)
0.9290922684111802 0.2995083062817015 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 139 times train_loss is tensor(0.3238, grad_fn=<BinaryCrossEntropyBackward0>)
0.9291009933422671 0.2988682924150394 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 140 times train_loss is tensor(0.3231, grad_fn=<BinaryCrossEntropyBackward0>)
0.9289882782618835 0.2956777824949429 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 141 times train_loss is tensor(0.3228, grad_fn=<BinaryCrossEntropyBackward0>)
0.929081495189274 0.29597178948112995 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 142 times train_loss is tensor(0.3214, grad_fn=<BinaryCrossEntropyBackward0>)
0.9291255728321008 0.2955921689459092 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 143 times train_loss is tensor(0.3211, grad_fn=<BinaryCrossEntropyBackward0>)
0.9290131531782777 0.2928299302888566 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 144 times train_loss is tensor(0.3204, grad_fn=<BinaryCrossEntropyBackward0>)
0.9291016038904921 0.2926234580840269 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 145 times train_loss is tensor(0.3194, grad_fn=<BinaryCrossEntropyBackward0>)
0.9292152938785252 0.29294327291990857 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 146 times train_loss is tensor(0.3191, grad_fn=<BinaryCrossEntropyBackward0>)
0.9291507037848475 0.2901181071979261 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 147 times train_loss is tensor(0.3182, grad_fn=<BinaryCrossEntropyBackward0>)
0.9291813986044837 0.2890327275011003 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 148 times train_loss is tensor(0.3176, grad_fn=<BinaryCrossEntropyBackward0>)
0.9293010463614871 0.28991297480192046 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 149 times train_loss is tensor(0.3172, grad_fn=<BinaryCrossEntropyBackward0>)
0.9292241468277885 0.28731166567923366 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 150 times train_loss is tensor(0.3163, grad_fn=<BinaryCrossEntropyBackward0>)
0.9291878192083988 0.2857058836488757 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 151 times train_loss is tensor(0.3158, grad_fn=<BinaryCrossEntropyBackward0>)
0.9293171274139302 0.28629158390013804 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 152 times train_loss is tensor(0.3153, grad_fn=<BinaryCrossEntropyBackward0>)
0.9292274359101619 0.28367596645282733 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 153 times train_loss is tensor(0.3145, grad_fn=<BinaryCrossEntropyBackward0>)
0.9291993506918103 0.28213595697174404 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 154 times train_loss is tensor(0.3140, grad_fn=<BinaryCrossEntropyBackward0>)
0.9293618943853985 0.28301275842412327 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 155 times train_loss is tensor(0.3135, grad_fn=<BinaryCrossEntropyBackward0>)
0.9292805733008443 0.2805498018166002 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 156 times train_loss is tensor(0.3128, grad_fn=<BinaryCrossEntropyBackward0>)
0.9292939167338269 0.2797260813149693 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 157 times train_loss is tensor(0.3123, grad_fn=<BinaryCrossEntropyBackward0>)
0.929433407308144 0.2804394017401954 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 158 times train_loss is tensor(0.3118, grad_fn=<BinaryCrossEntropyBackward0>)
0.9293043255963086 0.27812651552260115 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 159 times train_loss is tensor(0.3112, grad_fn=<BinaryCrossEntropyBackward0>)
0.929342150043605 0.27759171842681263 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 160 times train_loss is tensor(0.3106, grad_fn=<BinaryCrossEntropyBackward0>)
0.9294207433562507 0.27781945221931453 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 161 times train_loss is tensor(0.3101, grad_fn=<BinaryCrossEntropyBackward0>)
0.9292709325474199 0.27536447628185795 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 162 times train_loss is tensor(0.3096, grad_fn=<BinaryCrossEntropyBackward0>)
0.9293892902751091 0.27607242944425137 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 163 times train_loss is tensor(0.3090, grad_fn=<BinaryCrossEntropyBackward0>)
0.9293719388884557 0.2750638237438741 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 164 times train_loss is tensor(0.3084, grad_fn=<BinaryCrossEntropyBackward0>)
0.9293135921427564 0.2738497574372216 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 165 times train_loss is tensor(0.3080, grad_fn=<BinaryCrossEntropyBackward0>)
0.9294713006883044 0.2747616930844369 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 166 times train_loss is tensor(0.3075, grad_fn=<BinaryCrossEntropyBackward0>)
0.929354036038889 0.27254160808468353 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 167 times train_loss is tensor(0.3070, grad_fn=<BinaryCrossEntropyBackward0>)
0.9294796809550708 0.2732037516641428 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 168 times train_loss is tensor(0.3064, grad_fn=<BinaryCrossEntropyBackward0>)
0.9294714582491369 0.27238297125050626 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 169 times train_loss is tensor(0.3058, grad_fn=<BinaryCrossEntropyBackward0>)
0.9294386068156089 0.2712380781258933 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 170 times train_loss is tensor(0.3053, grad_fn=<BinaryCrossEntropyBackward0>)
0.9295682793805653 0.2718939977747571 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 171 times train_loss is tensor(0.3049, grad_fn=<BinaryCrossEntropyBackward0>)
0.9294142439719195 0.2695520085580705 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 172 times train_loss is tensor(0.3044, grad_fn=<BinaryCrossEntropyBackward0>)
0.9296672669734376 0.27136139908533274 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 173 times train_loss is tensor(0.3040, grad_fn=<BinaryCrossEntropyBackward0>)
0.9294334860885601 0.2680927069045166 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 174 times train_loss is tensor(0.3036, grad_fn=<BinaryCrossEntropyBackward0>)
0.929810509465073 0.2710574980583002 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 175 times train_loss is tensor(0.3032, grad_fn=<BinaryCrossEntropyBackward0>)
0.9294628514886742 0.26656659150279355 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 176 times train_loss is tensor(0.3029, grad_fn=<BinaryCrossEntropyBackward0>)
0.9299671840176593 0.27124037112539806 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 177 times train_loss is tensor(0.3026, grad_fn=<BinaryCrossEntropyBackward0>)
0.9295553790874235 0.2660083017589038 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 178 times train_loss is tensor(0.3020, grad_fn=<BinaryCrossEntropyBackward0>)
0.9300361267293286 0.27039013008731905 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 179 times train_loss is tensor(0.3012, grad_fn=<BinaryCrossEntropyBackward0>)
0.9298029563926763 0.267027599701049 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 180 times train_loss is tensor(0.3004, grad_fn=<BinaryCrossEntropyBackward0>)
0.9299631268262286 0.267694895428088 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 181 times train_loss is tensor(0.2997, grad_fn=<BinaryCrossEntropyBackward0>)
0.9300993184706199 0.2681326683247206 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 182 times train_loss is tensor(0.2993, grad_fn=<BinaryCrossEntropyBackward0>)
0.929881077022825 0.2654490170797998 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 183 times train_loss is tensor(0.2991, grad_fn=<BinaryCrossEntropyBackward0>)
0.9303810076960587 0.2694047489057853 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 184 times train_loss is tensor(0.2990, grad_fn=<BinaryCrossEntropyBackward0>)
0.929954628388838 0.2642260721671239 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 185 times train_loss is tensor(0.2986, grad_fn=<BinaryCrossEntropyBackward0>)
0.9306156059277536 0.26967965479625544 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 186 times train_loss is tensor(0.2982, grad_fn=<BinaryCrossEntropyBackward0>)
0.9302656633192867 0.26529136250141067 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 187 times train_loss is tensor(0.2972, grad_fn=<BinaryCrossEntropyBackward0>)
0.9306578913161135 0.2680516900304357 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 188 times train_loss is tensor(0.2964, grad_fn=<BinaryCrossEntropyBackward0>)
0.9306612493313513 0.2672631193274019 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 189 times train_loss is tensor(0.2958, grad_fn=<BinaryCrossEntropyBackward0>)
0.9305698246584279 0.26553534240636073 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 190 times train_loss is tensor(0.2955, grad_fn=<BinaryCrossEntropyBackward0>)
0.930984061934012 0.2685520842109887 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 191 times train_loss is tensor(0.2954, grad_fn=<BinaryCrossEntropyBackward0>)
0.9305159093111361 0.2636767117803545 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 192 times train_loss is tensor(0.2953, grad_fn=<BinaryCrossEntropyBackward0>)
0.9312828662048559 0.2694331246240301 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 193 times train_loss is tensor(0.2952, grad_fn=<BinaryCrossEntropyBackward0>)
0.9307204528140759 0.263281212958951 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 194 times train_loss is tensor(0.2945, grad_fn=<BinaryCrossEntropyBackward0>)
0.9314682266764669 0.2687746741540366 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 195 times train_loss is tensor(0.2937, grad_fn=<BinaryCrossEntropyBackward0>)
0.9312127713296008 0.26529222546455355 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 196 times train_loss is tensor(0.2927, grad_fn=<BinaryCrossEntropyBackward0>)
0.9314042766736702 0.26619842926217246 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 197 times train_loss is tensor(0.2921, grad_fn=<BinaryCrossEntropyBackward0>)
0.9316612386959949 0.26755992572939785 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 198 times train_loss is tensor(0.2919, grad_fn=<BinaryCrossEntropyBackward0>)
0.9312523978789161 0.26358504734328425 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 199 times train_loss is tensor(0.2918, grad_fn=<BinaryCrossEntropyBackward0>)
0.9319301950366762 0.26834999738113585 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 200 times train_loss is tensor(0.2918, grad_fn=<BinaryCrossEntropyBackward0>)
0.9313318873187952 0.2630461426539907 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 201 times train_loss is tensor(0.2912, grad_fn=<BinaryCrossEntropyBackward0>)
0.9319234396159927 0.26665334453745293 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 202 times train_loss is tensor(0.2901, grad_fn=<BinaryCrossEntropyBackward0>)
0.9319988915595449 0.2666388126538148 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 203 times train_loss is tensor(0.2898, grad_fn=<BinaryCrossEntropyBackward0>)
0.9316476687693159 0.263284743330747 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 204 times train_loss is tensor(0.2900, grad_fn=<BinaryCrossEntropyBackward0>)
0.9321864578828077 0.2671563921218044 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 205 times train_loss is tensor(0.2891, grad_fn=<BinaryCrossEntropyBackward0>)
0.9321832377332983 0.2666018210432685 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 206 times train_loss is tensor(0.2886, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318821094401786 0.26374892222396223 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 207 times train_loss is tensor(0.2888, grad_fn=<BinaryCrossEntropyBackward0>)
0.9323650136959754 0.26698077882398774 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 208 times train_loss is tensor(0.2882, grad_fn=<BinaryCrossEntropyBackward0>)
0.9322744457600773 0.26572269903806184 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 209 times train_loss is tensor(0.2875, grad_fn=<BinaryCrossEntropyBackward0>)
0.9320423783492511 0.26365285152187784 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 210 times train_loss is tensor(0.2876, grad_fn=<BinaryCrossEntropyBackward0>)
0.9325170402040097 0.26668450300499336 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 211 times train_loss is tensor(0.2873, grad_fn=<BinaryCrossEntropyBackward0>)
0.9323535412978758 0.2649538992773696 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 212 times train_loss is tensor(0.2865, grad_fn=<BinaryCrossEntropyBackward0>)
0.9322515403540864 0.26373732178370324 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 213 times train_loss is tensor(0.2865, grad_fn=<BinaryCrossEntropyBackward0>)
0.9327050004293532 0.2666924528235623 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 214 times train_loss is tensor(0.2863, grad_fn=<BinaryCrossEntropyBackward0>)
0.9324691712536564 0.2644098055937458 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 215 times train_loss is tensor(0.2856, grad_fn=<BinaryCrossEntropyBackward0>)
0.9324997774453245 0.26430441212389344 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 216 times train_loss is tensor(0.2853, grad_fn=<BinaryCrossEntropyBackward0>)
0.932841320091921 0.2665238623283209 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 217 times train_loss is tensor(0.2853, grad_fn=<BinaryCrossEntropyBackward0>)
0.9325325993361961 0.264244906079235 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 218 times train_loss is tensor(0.2848, grad_fn=<BinaryCrossEntropyBackward0>)
0.9326965118395149 0.26506402969679654 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 219 times train_loss is tensor(0.2843, grad_fn=<BinaryCrossEntropyBackward0>)
0.9328474157266194 0.26606379492391663 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 220 times train_loss is tensor(0.2841, grad_fn=<BinaryCrossEntropyBackward0>)
0.9325664650675818 0.2637688285081611 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 221 times train_loss is tensor(0.2839, grad_fn=<BinaryCrossEntropyBackward0>)
0.9328619211707401 0.26583942609617606 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 222 times train_loss is tensor(0.2835, grad_fn=<BinaryCrossEntropyBackward0>)
0.9327968583945655 0.2651573334673304 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 223 times train_loss is tensor(0.2831, grad_fn=<BinaryCrossEntropyBackward0>)
0.932697772326173 0.2644734798414195 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 224 times train_loss is tensor(0.2829, grad_fn=<BinaryCrossEntropyBackward0>)
0.9329834301150745 0.2663721420776295 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 225 times train_loss is tensor(0.2827, grad_fn=<BinaryCrossEntropyBackward0>)
0.9327475418540656 0.26442266564441624 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 226 times train_loss is tensor(0.2823, grad_fn=<BinaryCrossEntropyBackward0>)
0.932898465436274 0.26546942067686385 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 227 times train_loss is tensor(0.2819, grad_fn=<BinaryCrossEntropyBackward0>)
0.9329302927243922 0.2656711135346437 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 228 times train_loss is tensor(0.2816, grad_fn=<BinaryCrossEntropyBackward0>)
0.9327563258704645 0.2645565298177219 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 229 times train_loss is tensor(0.2814, grad_fn=<BinaryCrossEntropyBackward0>)
0.9329932284293312 0.2661371567288929 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 230 times train_loss is tensor(0.2812, grad_fn=<BinaryCrossEntropyBackward0>)
0.9327497378581653 0.26438432752866914 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 231 times train_loss is tensor(0.2808, grad_fn=<BinaryCrossEntropyBackward0>)
0.9329133450873713 0.26543114614556335 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 232 times train_loss is tensor(0.2805, grad_fn=<BinaryCrossEntropyBackward0>)
0.932875993322572 0.2650078064660232 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 233 times train_loss is tensor(0.2802, grad_fn=<BinaryCrossEntropyBackward0>)
0.9328069028976226 0.26464238630851983 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 234 times train_loss is tensor(0.2800, grad_fn=<BinaryCrossEntropyBackward0>)
0.9329883046533228 0.26582093756409203 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 235 times train_loss is tensor(0.2797, grad_fn=<BinaryCrossEntropyBackward0>)
0.9327505552049827 0.26422528722369903 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 236 times train_loss is tensor(0.2795, grad_fn=<BinaryCrossEntropyBackward0>)
0.9330082557937087 0.266204407427406 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 237 times train_loss is tensor(0.2793, grad_fn=<BinaryCrossEntropyBackward0>)
0.9327263696172295 0.2642635954019541 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 238 times train_loss is tensor(0.2790, grad_fn=<BinaryCrossEntropyBackward0>)
0.9329458813992347 0.26582667671305205 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 239 times train_loss is tensor(0.2787, grad_fn=<BinaryCrossEntropyBackward0>)
0.932738925246051 0.26442190127821236 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 240 times train_loss is tensor(0.2784, grad_fn=<BinaryCrossEntropyBackward0>)
0.9328810845069645 0.265405872880134 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 241 times train_loss is tensor(0.2781, grad_fn=<BinaryCrossEntropyBackward0>)
0.9327714911005701 0.26455729181591614 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 242 times train_loss is tensor(0.2779, grad_fn=<BinaryCrossEntropyBackward0>)
0.9328448356679909 0.2649565745126482 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 243 times train_loss is tensor(0.2776, grad_fn=<BinaryCrossEntropyBackward0>)
0.9327916293444446 0.2645493654351621 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 244 times train_loss is tensor(0.2774, grad_fn=<BinaryCrossEntropyBackward0>)
0.9328288137008598 0.26478864559979026 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 245 times train_loss is tensor(0.2771, grad_fn=<BinaryCrossEntropyBackward0>)
0.9327799009099925 0.2644349804571093 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 246 times train_loss is tensor(0.2769, grad_fn=<BinaryCrossEntropyBackward0>)
0.9328047167410748 0.26470826884334464 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 247 times train_loss is tensor(0.2766, grad_fn=<BinaryCrossEntropyBackward0>)
0.9327139715492405 0.2642787332694003 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 248 times train_loss is tensor(0.2764, grad_fn=<BinaryCrossEntropyBackward0>)
0.932797232601542 0.26514974053606755 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 249 times train_loss is tensor(0.2762, grad_fn=<BinaryCrossEntropyBackward0>)
0.9326064264336658 0.26401968433262546 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 250 times train_loss is tensor(0.2760, grad_fn=<BinaryCrossEntropyBackward0>)
0.9329130595083628 0.26619173915458383 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 251 times train_loss is tensor(0.2760, grad_fn=<BinaryCrossEntropyBackward0>)
0.932346007920583 0.26262290715664727 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 252 times train_loss is tensor(0.2764, grad_fn=<BinaryCrossEntropyBackward0>)
0.9332598902903925 0.2682220449280348 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 253 times train_loss is tensor(0.2780, grad_fn=<BinaryCrossEntropyBackward0>)
0.9317827870305375 0.2598313918715333 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 254 times train_loss is tensor(0.2800, grad_fn=<BinaryCrossEntropyBackward0>)
0.9335673997972193 0.2698950796061614 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 255 times train_loss is tensor(0.2820, grad_fn=<BinaryCrossEntropyBackward0>)
0.9324208099257022 0.2634301004975886 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 256 times train_loss is tensor(0.2757, grad_fn=<BinaryCrossEntropyBackward0>)
0.9323075039921976 0.26286576505863046 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 257 times train_loss is tensor(0.2761, grad_fn=<BinaryCrossEntropyBackward0>)
0.9334077808265798 0.26948417894625265 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 258 times train_loss is tensor(0.2795, grad_fn=<BinaryCrossEntropyBackward0>)
0.93241015487442 0.2641510024839041 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 259 times train_loss is tensor(0.2746, grad_fn=<BinaryCrossEntropyBackward0>)
0.9319870646495728 0.26245192879155804 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 260 times train_loss is tensor(0.2763, grad_fn=<BinaryCrossEntropyBackward0>)
0.933177249633868 0.2687772995414539 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 261 times train_loss is tensor(0.2777, grad_fn=<BinaryCrossEntropyBackward0>)
0.9325910445574155 0.26553344158426534 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 262 times train_loss is tensor(0.2737, grad_fn=<BinaryCrossEntropyBackward0>)
0.9317767603287034 0.2614785946074308 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 263 times train_loss is tensor(0.2773, grad_fn=<BinaryCrossEntropyBackward0>)
0.9330988237296067 0.26804890433732254 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 264 times train_loss is tensor(0.2754, grad_fn=<BinaryCrossEntropyBackward0>)
0.9330144400563752 0.26739396463830534 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 265 times train_loss is tensor(0.2741, grad_fn=<BinaryCrossEntropyBackward0>)
0.9320235301346909 0.26188399234883925 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 266 times train_loss is tensor(0.2764, grad_fn=<BinaryCrossEntropyBackward0>)
0.932910134785414 0.2665233011122116 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 267 times train_loss is tensor(0.2731, grad_fn=<BinaryCrossEntropyBackward0>)
0.9332270388568646 0.26845185991670967 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 268 times train_loss is tensor(0.2747, grad_fn=<BinaryCrossEntropyBackward0>)
0.9323973727519022 0.26364456748846865 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 269 times train_loss is tensor(0.2735, grad_fn=<BinaryCrossEntropyBackward0>)
0.9324392937808376 0.26403966724097017 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 270 times train_loss is tensor(0.2730, grad_fn=<BinaryCrossEntropyBackward0>)
0.9331296465674191 0.26744655597299244 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 271 times train_loss is tensor(0.2738, grad_fn=<BinaryCrossEntropyBackward0>)
0.9327565425166089 0.2653019024604537 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 272 times train_loss is tensor(0.2722, grad_fn=<BinaryCrossEntropyBackward0>)
0.9322067832301705 0.2625309129137384 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 273 times train_loss is tensor(0.2735, grad_fn=<BinaryCrossEntropyBackward0>)
0.9329654090948838 0.2661048599526778 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 274 times train_loss is tensor(0.2722, grad_fn=<BinaryCrossEntropyBackward0>)
0.9330558884028137 0.2664212196365438 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 275 times train_loss is tensor(0.2723, grad_fn=<BinaryCrossEntropyBackward0>)
0.9324314551294322 0.2631238081540804 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 276 times train_loss is tensor(0.2724, grad_fn=<BinaryCrossEntropyBackward0>)
0.9327364732055987 0.26468735769824314 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 277 times train_loss is tensor(0.2714, grad_fn=<BinaryCrossEntropyBackward0>)
0.9331121770101414 0.2665457235026056 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 278 times train_loss is tensor(0.2721, grad_fn=<BinaryCrossEntropyBackward0>)
0.9326572496496242 0.2643005048730033 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 279 times train_loss is tensor(0.2712, grad_fn=<BinaryCrossEntropyBackward0>)
0.9324340745782688 0.2632688048884719 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 280 times train_loss is tensor(0.2715, grad_fn=<BinaryCrossEntropyBackward0>)
0.9329084114638111 0.2659047289662688 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 281 times train_loss is tensor(0.2713, grad_fn=<BinaryCrossEntropyBackward0>)
0.9327639872659336 0.2652502139995408 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 282 times train_loss is tensor(0.2708, grad_fn=<BinaryCrossEntropyBackward0>)
0.9323174992574945 0.2630517614024511 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 283 times train_loss is tensor(0.2712, grad_fn=<BinaryCrossEntropyBackward0>)
0.9327028536630135 0.26512224692104464 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 284 times train_loss is tensor(0.2705, grad_fn=<BinaryCrossEntropyBackward0>)
0.9328499563950398 0.26584193499775727 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 285 times train_loss is tensor(0.2707, grad_fn=<BinaryCrossEntropyBackward0>)
0.9324475460294277 0.2638490207558164 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 286 times train_loss is tensor(0.2704, grad_fn=<BinaryCrossEntropyBackward0>)
0.932545992006939 0.26432347180509885 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 287 times train_loss is tensor(0.2701, grad_fn=<BinaryCrossEntropyBackward0>)
0.9328264699834797 0.26572432471797586 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 288 times train_loss is tensor(0.2703, grad_fn=<BinaryCrossEntropyBackward0>)
0.9325431953021661 0.26429776265681826 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 289 times train_loss is tensor(0.2698, grad_fn=<BinaryCrossEntropyBackward0>)
0.9323804054197774 0.2633452249644182 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 290 times train_loss is tensor(0.2699, grad_fn=<BinaryCrossEntropyBackward0>)
0.9326864082511457 0.26517523834887374 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 291 times train_loss is tensor(0.2697, grad_fn=<BinaryCrossEntropyBackward0>)
0.9325549631268263 0.26449413069370514 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 292 times train_loss is tensor(0.2695, grad_fn=<BinaryCrossEntropyBackward0>)
0.9323007978092742 0.26308900205013686 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 293 times train_loss is tensor(0.2695, grad_fn=<BinaryCrossEntropyBackward0>)
0.9325742741763311 0.26456888668812245 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 294 times train_loss is tensor(0.2692, grad_fn=<BinaryCrossEntropyBackward0>)
0.9325760762783502 0.26468695324444225 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 295 times train_loss is tensor(0.2691, grad_fn=<BinaryCrossEntropyBackward0>)
0.9323105468857706 0.26328541352347423 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 296 times train_loss is tensor(0.2691, grad_fn=<BinaryCrossEntropyBackward0>)
0.9324940461700507 0.26421835918166525 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 297 times train_loss is tensor(0.2688, grad_fn=<BinaryCrossEntropyBackward0>)
0.9325494091074888 0.26460345059659957 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 298 times train_loss is tensor(0.2688, grad_fn=<BinaryCrossEntropyBackward0>)
0.9322816640157056 0.26323037668956706 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 299 times train_loss is tensor(0.2687, grad_fn=<BinaryCrossEntropyBackward0>)
0.9323812424616988 0.26382375616682596 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 300 times train_loss is tensor(0.2685, grad_fn=<BinaryCrossEntropyBackward0>)
0.9324683243641829 0.264501897942402 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 301 times train_loss is tensor(0.2685, grad_fn=<BinaryCrossEntropyBackward0>)
0.9322350161618024 0.26313775547010176 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 302 times train_loss is tensor(0.2683, grad_fn=<BinaryCrossEntropyBackward0>)
0.9323028362525416 0.26363346811284555 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 303 times train_loss is tensor(0.2681, grad_fn=<BinaryCrossEntropyBackward0>)
0.9324140643525708 0.2643556657416801 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 304 times train_loss is tensor(0.2681, grad_fn=<BinaryCrossEntropyBackward0>)
0.9322304665927706 0.26337578820188345 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 305 times train_loss is tensor(0.2680, grad_fn=<BinaryCrossEntropyBackward0>)
0.9322640073549397 0.2636542817951486 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 306 times train_loss is tensor(0.2678, grad_fn=<BinaryCrossEntropyBackward0>)
0.9323590657745573 0.26418786823030405 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 307 times train_loss is tensor(0.2678, grad_fn=<BinaryCrossEntropyBackward0>)
0.932187718369466 0.2633051511842892 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 308 times train_loss is tensor(0.2676, grad_fn=<BinaryCrossEntropyBackward0>)
0.9321986393046525 0.2633663563549929 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 309 times train_loss is tensor(0.2675, grad_fn=<BinaryCrossEntropyBackward0>)
0.9322745442355975 0.26372500898642276 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 310 times train_loss is tensor(0.2674, grad_fn=<BinaryCrossEntropyBackward0>)
0.9321191498647735 0.2630542047336301 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 311 times train_loss is tensor(0.2673, grad_fn=<BinaryCrossEntropyBackward0>)
0.9321590521455452 0.26322420944756536 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 312 times train_loss is tensor(0.2672, grad_fn=<BinaryCrossEntropyBackward0>)
0.9322227264168855 0.2634309126793595 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 313 times train_loss is tensor(0.2671, grad_fn=<BinaryCrossEntropyBackward0>)
0.9320972587566402 0.2629930154309156 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 314 times train_loss is tensor(0.2670, grad_fn=<BinaryCrossEntropyBackward0>)
0.9321584612924243 0.26322412605577394 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 315 times train_loss is tensor(0.2669, grad_fn=<BinaryCrossEntropyBackward0>)
0.9321804114858696 0.2634512383536256 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 316 times train_loss is tensor(0.2668, grad_fn=<BinaryCrossEntropyBackward0>)
0.9320674994544457 0.2629713460139984 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 317 times train_loss is tensor(0.2667, grad_fn=<BinaryCrossEntropyBackward0>)
0.9321403024065054 0.26335835892392456 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 318 times train_loss is tensor(0.2666, grad_fn=<BinaryCrossEntropyBackward0>)
0.9321110157868077 0.26315958912419785 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 319 times train_loss is tensor(0.2665, grad_fn=<BinaryCrossEntropyBackward0>)
0.9320398573759346 0.26290266713796256 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 320 times train_loss is tensor(0.2664, grad_fn=<BinaryCrossEntropyBackward0>)
0.9321206762353359 0.26321167244398447 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 321 times train_loss is tensor(0.2663, grad_fn=<BinaryCrossEntropyBackward0>)
0.9320571693723801 0.26289648466769666 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 322 times train_loss is tensor(0.2662, grad_fn=<BinaryCrossEntropyBackward0>)
0.9320422601786267 0.26288740465782695 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 323 times train_loss is tensor(0.2661, grad_fn=<BinaryCrossEntropyBackward0>)
0.9321048906094532 0.26328179001850793 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 324 times train_loss is tensor(0.2660, grad_fn=<BinaryCrossEntropyBackward0>)
0.9320131508148652 0.2628602587812142 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 325 times train_loss is tensor(0.2659, grad_fn=<BinaryCrossEntropyBackward0>)
0.9320468688329705 0.2631731943916929 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 326 times train_loss is tensor(0.2658, grad_fn=<BinaryCrossEntropyBackward0>)
0.9320456871267284 0.26315475470060773 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 327 times train_loss is tensor(0.2657, grad_fn=<BinaryCrossEntropyBackward0>)
0.9319792259981676 0.2629557607826908 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 328 times train_loss is tensor(0.2656, grad_fn=<BinaryCrossEntropyBackward0>)
0.9320342738139412 0.26318211963189175 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 329 times train_loss is tensor(0.2655, grad_fn=<BinaryCrossEntropyBackward0>)
0.9319726576809724 0.2628966511111509 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 330 times train_loss is tensor(0.2654, grad_fn=<BinaryCrossEntropyBackward0>)
0.9319648879624312 0.2629019719100739 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 331 times train_loss is tensor(0.2653, grad_fn=<BinaryCrossEntropyBackward0>)
0.9319836278539191 0.2629954346822337 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 332 times train_loss is tensor(0.2652, grad_fn=<BinaryCrossEntropyBackward0>)
0.9319164380065088 0.2626819004368857 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 333 times train_loss is tensor(0.2651, grad_fn=<BinaryCrossEntropyBackward0>)
0.9319631843359323 0.2629128022544285 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 334 times train_loss is tensor(0.2650, grad_fn=<BinaryCrossEntropyBackward0>)
0.9319228487628717 0.26272502529330105 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 335 times train_loss is tensor(0.2649, grad_fn=<BinaryCrossEntropyBackward0>)
0.9319104703899866 0.26275920195066804 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 336 times train_loss is tensor(0.2648, grad_fn=<BinaryCrossEntropyBackward0>)
0.9319348430812281 0.2628774355658363 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 337 times train_loss is tensor(0.2648, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318737291734122 0.2625357387046651 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 338 times train_loss is tensor(0.2647, grad_fn=<BinaryCrossEntropyBackward0>)
0.9319199338874747 0.2627968389653159 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 339 times train_loss is tensor(0.2646, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318740442950767 0.2626133396780983 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 340 times train_loss is tensor(0.2645, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318821488303866 0.26262214712127635 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 341 times train_loss is tensor(0.2644, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318759547201679 0.262572932237376 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 342 times train_loss is tensor(0.2643, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318432706950244 0.26247760084971483 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 343 times train_loss is tensor(0.2642, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318725376196182 0.2626885550529995 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 344 times train_loss is tensor(0.2641, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318196956554964 0.26248306442367875 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 345 times train_loss is tensor(0.2640, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318624438788011 0.2628309750047592 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 346 times train_loss is tensor(0.2639, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318143779774073 0.26244157491192416 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 347 times train_loss is tensor(0.2639, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318454666991242 0.26270177098149616 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 348 times train_loss is tensor(0.2638, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318205130023137 0.26261791037544935 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 349 times train_loss is tensor(0.2637, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318262639726915 0.26272259155152455 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 350 times train_loss is tensor(0.2636, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318230142805259 0.2627973758195231 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 351 times train_loss is tensor(0.2635, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318093655734307 0.2628518581885714 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 352 times train_loss is tensor(0.2634, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318289031166321 0.2629590613578549 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 353 times train_loss is tensor(0.2633, grad_fn=<BinaryCrossEntropyBackward0>)
0.9317901923896542 0.262676596529341 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 354 times train_loss is tensor(0.2632, grad_fn=<BinaryCrossEntropyBackward0>)
0.931841813257326 0.2630843138015057 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 355 times train_loss is tensor(0.2631, grad_fn=<BinaryCrossEntropyBackward0>)
0.9317644410411304 0.2627886596620135 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 356 times train_loss is tensor(0.2631, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318615083613595 0.2632326844459173 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 357 times train_loss is tensor(0.2630, grad_fn=<BinaryCrossEntropyBackward0>)
0.9317321312229635 0.26269942192089213 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 358 times train_loss is tensor(0.2629, grad_fn=<BinaryCrossEntropyBackward0>)
0.931884275901622 0.26347814821764154 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 359 times train_loss is tensor(0.2628, grad_fn=<BinaryCrossEntropyBackward0>)
0.9316933318680175 0.2625037095671716 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 360 times train_loss is tensor(0.2627, grad_fn=<BinaryCrossEntropyBackward0>)
0.9319188408092011 0.26367696046739175 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 361 times train_loss is tensor(0.2627, grad_fn=<BinaryCrossEntropyBackward0>)
0.9316534394347977 0.2623324627261729 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 362 times train_loss is tensor(0.2626, grad_fn=<BinaryCrossEntropyBackward0>)
0.9319588218703888 0.2638001686441328 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 363 times train_loss is tensor(0.2626, grad_fn=<BinaryCrossEntropyBackward0>)
0.9315794153862879 0.26218424636640886 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 364 times train_loss is tensor(0.2626, grad_fn=<BinaryCrossEntropyBackward0>)
0.9320219151361603 0.26415039358966313 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 365 times train_loss is tensor(0.2626, grad_fn=<BinaryCrossEntropyBackward0>)
0.9314813337682013 0.26172233147268126 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 366 times train_loss is tensor(0.2626, grad_fn=<BinaryCrossEntropyBackward0>)
0.9321203118759114 0.26455979991062456 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 367 times train_loss is tensor(0.2627, grad_fn=<BinaryCrossEntropyBackward0>)
0.9313821098340805 0.2613281417729405 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 368 times train_loss is tensor(0.2628, grad_fn=<BinaryCrossEntropyBackward0>)
0.9322145431011596 0.2650306685887682 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 369 times train_loss is tensor(0.2630, grad_fn=<BinaryCrossEntropyBackward0>)
0.9313422370959648 0.26107842333448994 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 370 times train_loss is tensor(0.2628, grad_fn=<BinaryCrossEntropyBackward0>)
0.9322132136816372 0.26495840151834793 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 371 times train_loss is tensor(0.2627, grad_fn=<BinaryCrossEntropyBackward0>)
0.9314580935454417 0.2615806408070693 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 372 times train_loss is tensor(0.2623, grad_fn=<BinaryCrossEntropyBackward0>)
0.9320281486365867 0.26410511933294706 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 373 times train_loss is tensor(0.2619, grad_fn=<BinaryCrossEntropyBackward0>)
0.9317111953273759 0.26271058672857944 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 374 times train_loss is tensor(0.2615, grad_fn=<BinaryCrossEntropyBackward0>)
0.9317392017653117 0.2628246016137006 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 375 times train_loss is tensor(0.2614, grad_fn=<BinaryCrossEntropyBackward0>)
0.9319516134623126 0.2637814651252637 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 376 times train_loss is tensor(0.2615, grad_fn=<BinaryCrossEntropyBackward0>)
0.9315247811676992 0.2619892716956937 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 377 times train_loss is tensor(0.2616, grad_fn=<BinaryCrossEntropyBackward0>)
0.9321150237404784 0.2645748061881519 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 378 times train_loss is tensor(0.2617, grad_fn=<BinaryCrossEntropyBackward0>)
0.9314758486817278 0.26141276699083205 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 379 times train_loss is tensor(0.2616, grad_fn=<BinaryCrossEntropyBackward0>)
0.9321413856372271 0.2648364074131804 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 380 times train_loss is tensor(0.2615, grad_fn=<BinaryCrossEntropyBackward0>)
0.9315550328474945 0.26178783116957666 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 381 times train_loss is tensor(0.2613, grad_fn=<BinaryCrossEntropyBackward0>)
0.9320054992669483 0.26409116510482483 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 382 times train_loss is tensor(0.2610, grad_fn=<BinaryCrossEntropyBackward0>)
0.9316948877812362 0.2625443295995456 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 383 times train_loss is tensor(0.2608, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318075536238597 0.2630441278814106 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 384 times train_loss is tensor(0.2606, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318662548814316 0.26326759463851074 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 385 times train_loss is tensor(0.2606, grad_fn=<BinaryCrossEntropyBackward0>)
0.9316598698862648 0.2622727141769706 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 386 times train_loss is tensor(0.2606, grad_fn=<BinaryCrossEntropyBackward0>)
0.9320109646583175 0.2639170976027626 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 387 times train_loss is tensor(0.2606, grad_fn=<BinaryCrossEntropyBackward0>)
0.9315584007102842 0.2617125591604276 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 388 times train_loss is tensor(0.2606, grad_fn=<BinaryCrossEntropyBackward0>)
0.9320798187420185 0.2641329461520594 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 389 times train_loss is tensor(0.2606, grad_fn=<BinaryCrossEntropyBackward0>)
0.9314824563891312 0.26131446908056843 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 390 times train_loss is tensor(0.2606, grad_fn=<BinaryCrossEntropyBackward0>)
0.9320898632450756 0.26407384052992466 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 391 times train_loss is tensor(0.2605, grad_fn=<BinaryCrossEntropyBackward0>)
0.9314792362396217 0.26132455318081443 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 392 times train_loss is tensor(0.2604, grad_fn=<BinaryCrossEntropyBackward0>)
0.9320760372820441 0.26374102924843457 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 393 times train_loss is tensor(0.2603, grad_fn=<BinaryCrossEntropyBackward0>)
0.9315461208129192 0.2613351159593528 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 394 times train_loss is tensor(0.2601, grad_fn=<BinaryCrossEntropyBackward0>)
0.9320254897975423 0.26344965756749683 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 395 times train_loss is tensor(0.2599, grad_fn=<BinaryCrossEntropyBackward0>)
0.9316217894026159 0.26166077666615656 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 396 times train_loss is tensor(0.2598, grad_fn=<BinaryCrossEntropyBackward0>)
0.9319218640076701 0.2629996457373931 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 397 times train_loss is tensor(0.2596, grad_fn=<BinaryCrossEntropyBackward0>)
0.9316979306748093 0.26194366823726933 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 398 times train_loss is tensor(0.2595, grad_fn=<BinaryCrossEntropyBackward0>)
0.931832349759838 0.2625373339007834 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 399 times train_loss is tensor(0.2594, grad_fn=<BinaryCrossEntropyBackward0>)
0.9317787396866588 0.26225659042613786 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 400 times train_loss is tensor(0.2593, grad_fn=<BinaryCrossEntropyBackward0>)
0.9317640471390497 0.26209209409909245 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 401 times train_loss is tensor(0.2592, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318417443244619 0.26246549310733314 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 402 times train_loss is tensor(0.2591, grad_fn=<BinaryCrossEntropyBackward0>)
0.9316910570835019 0.26170753852176276 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 403 times train_loss is tensor(0.2590, grad_fn=<BinaryCrossEntropyBackward0>)
0.9319082054530228 0.2627086073187976 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 404 times train_loss is tensor(0.2590, grad_fn=<BinaryCrossEntropyBackward0>)
0.9315813061162752 0.26116835788248216 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 405 times train_loss is tensor(0.2590, grad_fn=<BinaryCrossEntropyBackward0>)
0.9320254996450943 0.26305337145678376 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 406 times train_loss is tensor(0.2591, grad_fn=<BinaryCrossEntropyBackward0>)
0.9314033510037807 0.26018511241145614 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 407 times train_loss is tensor(0.2592, grad_fn=<BinaryCrossEntropyBackward0>)
0.9322545537050035 0.2643828411048174 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 408 times train_loss is tensor(0.2597, grad_fn=<BinaryCrossEntropyBackward0>)
0.9310914297936504 0.25851851132105014 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 409 times train_loss is tensor(0.2603, grad_fn=<BinaryCrossEntropyBackward0>)
0.9325929845251628 0.2656283144959862 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 410 times train_loss is tensor(0.2618, grad_fn=<BinaryCrossEntropyBackward0>)
0.9308412330395611 0.25731812254590525 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 411 times train_loss is tensor(0.2620, grad_fn=<BinaryCrossEntropyBackward0>)
0.9326899435223197 0.266319989215627 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 412 times train_loss is tensor(0.2621, grad_fn=<BinaryCrossEntropyBackward0>)
0.9312883808339854 0.25919940548804876 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 413 times train_loss is tensor(0.2596, grad_fn=<BinaryCrossEntropyBackward0>)
0.9319367338112153 0.2624049181541093 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 414 times train_loss is tensor(0.2581, grad_fn=<BinaryCrossEntropyBackward0>)
0.9321840747752198 0.2636897322249768 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 415 times train_loss is tensor(0.2587, grad_fn=<BinaryCrossEntropyBackward0>)
0.9310994457009921 0.25796654396487534 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 416 times train_loss is tensor(0.2597, grad_fn=<BinaryCrossEntropyBackward0>)
0.9324345374132135 0.2651525271048729 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 417 times train_loss is tensor(0.2598, grad_fn=<BinaryCrossEntropyBackward0>)
0.9315490159932124 0.2600312268410434 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 418 times train_loss is tensor(0.2583, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318330784786871 0.26134012119192823 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 419 times train_loss is tensor(0.2578, grad_fn=<BinaryCrossEntropyBackward0>)
0.9323756392046015 0.26470936466726225 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 420 times train_loss is tensor(0.2586, grad_fn=<BinaryCrossEntropyBackward0>)
0.9313848769961973 0.25939043569570663 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 421 times train_loss is tensor(0.2588, grad_fn=<BinaryCrossEntropyBackward0>)
0.9322410428636365 0.2634921559594605 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 422 times train_loss is tensor(0.2581, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318011921052568 0.26144775242440943 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 423 times train_loss is tensor(0.2574, grad_fn=<BinaryCrossEntropyBackward0>)
0.9315530731846431 0.2602312569890623 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 424 times train_loss is tensor(0.2577, grad_fn=<BinaryCrossEntropyBackward0>)
0.9322943181200471 0.26397279910124066 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 425 times train_loss is tensor(0.2581, grad_fn=<BinaryCrossEntropyBackward0>)
0.9315151994995867 0.2599435180325115 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 426 times train_loss is tensor(0.2577, grad_fn=<BinaryCrossEntropyBackward0>)
0.9320194434006039 0.2623605315253491 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 427 times train_loss is tensor(0.2572, grad_fn=<BinaryCrossEntropyBackward0>)
0.9320073309116234 0.26230631351751926 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 428 times train_loss is tensor(0.2571, grad_fn=<BinaryCrossEntropyBackward0>)
0.9314907283328252 0.259701369989216 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 429 times train_loss is tensor(0.2574, grad_fn=<BinaryCrossEntropyBackward0>)
0.9321321584809875 0.26302854276844256 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 430 times train_loss is tensor(0.2574, grad_fn=<BinaryCrossEntropyBackward0>)
0.9315655795757044 0.2602284342461301 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 431 times train_loss is tensor(0.2569, grad_fn=<BinaryCrossEntropyBackward0>)
0.9317588082413769 0.26103642056651083 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 432 times train_loss is tensor(0.2567, grad_fn=<BinaryCrossEntropyBackward0>)
0.9320076460332879 0.2623727881862961 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 433 times train_loss is tensor(0.2568, grad_fn=<BinaryCrossEntropyBackward0>)
0.9314937121410863 0.25979021365655985 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 434 times train_loss is tensor(0.2569, grad_fn=<BinaryCrossEntropyBackward0>)
0.9320196206565402 0.2622877635601183 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 435 times train_loss is tensor(0.2567, grad_fn=<BinaryCrossEntropyBackward0>)
0.9316481709944688 0.2604067317980301 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 436 times train_loss is tensor(0.2564, grad_fn=<BinaryCrossEntropyBackward0>)
0.9316366198159531 0.26039933035191193 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 437 times train_loss is tensor(0.2563, grad_fn=<BinaryCrossEntropyBackward0>)
0.9319043255175282 0.261551935405344 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 438 times train_loss is tensor(0.2564, grad_fn=<BinaryCrossEntropyBackward0>)
0.9314456757823486 0.25956597045608976 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 439 times train_loss is tensor(0.2564, grad_fn=<BinaryCrossEntropyBackward0>)
0.9319066003020441 0.2614775271646554 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 440 times train_loss is tensor(0.2562, grad_fn=<BinaryCrossEntropyBackward0>)
0.9316247929059809 0.260257482031183 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 441 times train_loss is tensor(0.2560, grad_fn=<BinaryCrossEntropyBackward0>)
0.9316567088220674 0.26035477819563785 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 442 times train_loss is tensor(0.2559, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318242944622882 0.2611580836786982 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 443 times train_loss is tensor(0.2559, grad_fn=<BinaryCrossEntropyBackward0>)
0.931448255840977 0.25942611706367297 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 444 times train_loss is tensor(0.2559, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318365645121012 0.2612411061707176 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 445 times train_loss is tensor(0.2558, grad_fn=<BinaryCrossEntropyBackward0>)
0.9315148646828182 0.259448255561152 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 446 times train_loss is tensor(0.2556, grad_fn=<BinaryCrossEntropyBackward0>)
0.9317076797513059 0.2603538960363045 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 447 times train_loss is tensor(0.2555, grad_fn=<BinaryCrossEntropyBackward0>)
0.9316913131198542 0.2602013064552892 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 448 times train_loss is tensor(0.2554, grad_fn=<BinaryCrossEntropyBackward0>)
0.9315231563216164 0.25934392248282323 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 449 times train_loss is tensor(0.2554, grad_fn=<BinaryCrossEntropyBackward0>)
0.9317610042454767 0.2605010841789873 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 450 times train_loss is tensor(0.2554, grad_fn=<BinaryCrossEntropyBackward0>)
0.9314208993414744 0.2588871017198486 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 451 times train_loss is tensor(0.2553, grad_fn=<BinaryCrossEntropyBackward0>)
0.9317197528500785 0.26018403372306104 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 452 times train_loss is tensor(0.2552, grad_fn=<BinaryCrossEntropyBackward0>)
0.9314778378872353 0.25913165409177574 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 453 times train_loss is tensor(0.2551, grad_fn=<BinaryCrossEntropyBackward0>)
0.9316233748584908 0.259719930175156 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 454 times train_loss is tensor(0.2549, grad_fn=<BinaryCrossEntropyBackward0>)
0.9315704147237447 0.2595259400875057 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 455 times train_loss is tensor(0.2549, grad_fn=<BinaryCrossEntropyBackward0>)
0.9314941749760312 0.25914057170406296 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 456 times train_loss is tensor(0.2548, grad_fn=<BinaryCrossEntropyBackward0>)
0.9316157036154696 0.2597203290536364 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 457 times train_loss is tensor(0.2547, grad_fn=<BinaryCrossEntropyBackward0>)
0.931387683548522 0.2586750805960727 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 458 times train_loss is tensor(0.2547, grad_fn=<BinaryCrossEntropyBackward0>)
0.9316370137180338 0.25997736987342107 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 459 times train_loss is tensor(0.2546, grad_fn=<BinaryCrossEntropyBackward0>)
0.9313307548503134 0.2584209555047727 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 460 times train_loss is tensor(0.2546, grad_fn=<BinaryCrossEntropyBackward0>)
0.9316373879250106 0.2598971259366225 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 461 times train_loss is tensor(0.2545, grad_fn=<BinaryCrossEntropyBackward0>)
0.9312819405349662 0.2581719292648256 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 462 times train_loss is tensor(0.2544, grad_fn=<BinaryCrossEntropyBackward0>)
0.931617161053168 0.2598862110544483 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 463 times train_loss is tensor(0.2544, grad_fn=<BinaryCrossEntropyBackward0>)
0.9312185321475305 0.2579391033121985 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 464 times train_loss is tensor(0.2543, grad_fn=<BinaryCrossEntropyBackward0>)
0.9316178799244653 0.259753498670158 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 465 times train_loss is tensor(0.2542, grad_fn=<BinaryCrossEntropyBackward0>)
0.9311622927779628 0.2576046295502925 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 466 times train_loss is tensor(0.2542, grad_fn=<BinaryCrossEntropyBackward0>)
0.9316537250138064 0.2599851023338389 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 467 times train_loss is tensor(0.2542, grad_fn=<BinaryCrossEntropyBackward0>)
0.9310707203917593 0.257062533063663 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 468 times train_loss is tensor(0.2541, grad_fn=<BinaryCrossEntropyBackward0>)
0.931725927265193 0.26038203187674896 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 469 times train_loss is tensor(0.2542, grad_fn=<BinaryCrossEntropyBackward0>)
0.9308973936287126 0.25599970726307275 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 470 times train_loss is tensor(0.2543, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318795195339981 0.26130611504506207 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 471 times train_loss is tensor(0.2546, grad_fn=<BinaryCrossEntropyBackward0>)
0.9306718748399774 0.25485032777981803 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 472 times train_loss is tensor(0.2549, grad_fn=<BinaryCrossEntropyBackward0>)
0.9321119414566972 0.2623211576504084 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 473 times train_loss is tensor(0.2556, grad_fn=<BinaryCrossEntropyBackward0>)
0.9304937720142025 0.2539406432945724 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 474 times train_loss is tensor(0.2557, grad_fn=<BinaryCrossEntropyBackward0>)
0.9322097473433275 0.2631637612475677 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 475 times train_loss is tensor(0.2560, grad_fn=<BinaryCrossEntropyBackward0>)
0.9306541689414513 0.2545225072817004 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 476 times train_loss is tensor(0.2549, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318281743977828 0.2612037493217986 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 477 times train_loss is tensor(0.2539, grad_fn=<BinaryCrossEntropyBackward0>)
0.9312259375066471 0.257573571282064 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 478 times train_loss is tensor(0.2531, grad_fn=<BinaryCrossEntropyBackward0>)
0.9310858068414489 0.25687592392779734 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 479 times train_loss is tensor(0.2532, grad_fn=<BinaryCrossEntropyBackward0>)
0.9317780503580175 0.2607035723757837 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 480 times train_loss is tensor(0.2538, grad_fn=<BinaryCrossEntropyBackward0>)
0.9307392911810839 0.25513632758124327 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 481 times train_loss is tensor(0.2540, grad_fn=<BinaryCrossEntropyBackward0>)
0.9318974519262206 0.26150307718656224 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 482 times train_loss is tensor(0.2539, grad_fn=<BinaryCrossEntropyBackward0>)
0.9309815114180396 0.2560954490068572 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 483 times train_loss is tensor(0.2532, grad_fn=<BinaryCrossEntropyBackward0>)
0.9314080285909887 0.258570325949112 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 484 times train_loss is tensor(0.2527, grad_fn=<BinaryCrossEntropyBackward0>)
0.9313773239238005 0.2585140819454762 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 485 times train_loss is tensor(0.2527, grad_fn=<BinaryCrossEntropyBackward0>)
0.9308496133063274 0.2556442358017539 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 486 times train_loss is tensor(0.2529, grad_fn=<BinaryCrossEntropyBackward0>)
0.9316435032548129 0.2601069793940178 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 487 times train_loss is tensor(0.2532, grad_fn=<BinaryCrossEntropyBackward0>)
0.9308008186860844 0.25545912439578067 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 488 times train_loss is tensor(0.2530, grad_fn=<BinaryCrossEntropyBackward0>)
0.931547095720569 0.25939466314256054 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 489 times train_loss is tensor(0.2527, grad_fn=<BinaryCrossEntropyBackward0>)
0.9310518918723032 0.25664246451046285 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 490 times train_loss is tensor(0.2523, grad_fn=<BinaryCrossEntropyBackward0>)
0.9310688788995322 0.2567745986057181 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 491 times train_loss is tensor(0.2522, grad_fn=<BinaryCrossEntropyBackward0>)
0.931297036832208 0.2580142722046478 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 492 times train_loss is tensor(0.2523, grad_fn=<BinaryCrossEntropyBackward0>)
0.9307431514214745 0.25509285779867397 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 493 times train_loss is tensor(0.2524, grad_fn=<BinaryCrossEntropyBackward0>)
0.9314539871162507 0.2589781655054064 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 494 times train_loss is tensor(0.2524, grad_fn=<BinaryCrossEntropyBackward0>)
0.9307813205330915 0.2550771732913538 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 495 times train_loss is tensor(0.2522, grad_fn=<BinaryCrossEntropyBackward0>)
0.9313055352695983 0.257880998112615 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 496 times train_loss is tensor(0.2520, grad_fn=<BinaryCrossEntropyBackward0>)
0.9309062367304236 0.25578053629522046 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 497 times train_loss is tensor(0.2518, grad_fn=<BinaryCrossEntropyBackward0>)
0.9309397479499366 0.25589244974965347 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 498 times train_loss is tensor(0.2517, grad_fn=<BinaryCrossEntropyBackward0>)
0.9310864272372259 0.2567310361172438 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
E:\Anaconda\envs\py310\lib\site-packages\dgl\backend\pytorch\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  assert input.numel() == input.storage().size(), (
the 499 times train_loss is tensor(0.2516, grad_fn=<BinaryCrossEntropyBackward0>)
0.9307385033769225 0.2550115751081932 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064

,0
the 254 times train_loss is tensor(0.2800, grad_fn=<BinaryCrossEntropyBackward0>)
0.9335673997972193 0.2698950796061614 0.005710297569951145 0.005710297569951145 1.0 0.01135575042584064
