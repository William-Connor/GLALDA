
wandb: logging graph, to disable use `wandb.watch(log_graph=False)`
the 1 times train_loss is tensor(0.6658, grad_fn=<BinaryCrossEntropyBackward0>)
the 1 times test_loss is tensor(0.6836, grad_fn=<BinaryCrossEntropyBackward0>)
0.8104715321783967 0.8284903739324858 0.7272727272727273 0.7123050259965338 0.7625231910946196 0.7365591397849461
the 2 times train_loss is tensor(0.6832, grad_fn=<BinaryCrossEntropyBackward0>)
the 2 times test_loss is tensor(0.6762, grad_fn=<BinaryCrossEntropyBackward0>)
0.8252931801831882 0.8376627125819367 0.712430426716141 0.6601398601398601 0.87569573283859 0.7527910685805422
the 3 times train_loss is tensor(0.6754, grad_fn=<BinaryCrossEntropyBackward0>)
the 3 times test_loss is tensor(0.6695, grad_fn=<BinaryCrossEntropyBackward0>)
0.8294288536801125 0.8406013627313653 0.7022263450834879 0.6449468085106383 0.8998144712430427 0.7513555383423703
the 4 times train_loss is tensor(0.6684, grad_fn=<BinaryCrossEntropyBackward0>)
the 4 times test_loss is tensor(0.6630, grad_fn=<BinaryCrossEntropyBackward0>)
0.8311688311688312 0.8421289088304665 0.7040816326530612 0.6451187335092349 0.9072356215213359 0.7540478026214341
the 5 times train_loss is tensor(0.6616, grad_fn=<BinaryCrossEntropyBackward0>)
the 5 times test_loss is tensor(0.6564, grad_fn=<BinaryCrossEntropyBackward0>)
0.8324699419319085 0.8431811920539959 0.7105751391465677 0.650730411686587 0.9090909090909091 0.7585139318885448
the 6 times train_loss is tensor(0.6548, grad_fn=<BinaryCrossEntropyBackward0>)
the 6 times test_loss is tensor(0.6498, grad_fn=<BinaryCrossEntropyBackward0>)
