
wandb: logging graph, to disable use `wandb.watch(log_graph=False)`
the 1 times train_loss is tensor(0.6671, grad_fn=<BinaryCrossEntropyBackward0>)
the 1 times test_loss is tensor(0.6856, grad_fn=<BinaryCrossEntropyBackward0>)
0.8326713043119086 0.8482429976604917 0.5 0.5 1.0 0.6666666666666666
the 2 times train_loss is tensor(0.6849, grad_fn=<BinaryCrossEntropyBackward0>)
the 2 times test_loss is tensor(0.6811, grad_fn=<BinaryCrossEntropyBackward0>)
0.8353268782635335 0.8477331593501891 0.5 0.5 1.0 0.6666666666666666
the 3 times train_loss is tensor(0.6801, grad_fn=<BinaryCrossEntropyBackward0>)
the 3 times test_loss is tensor(0.6770, grad_fn=<BinaryCrossEntropyBackward0>)
0.8362786166920807 0.8470360402033144 0.5 0.5 1.0 0.6666666666666666
the 4 times train_loss is tensor(0.6757, grad_fn=<BinaryCrossEntropyBackward0>)
the 4 times test_loss is tensor(0.6730, grad_fn=<BinaryCrossEntropyBackward0>)
0.8368431197744741 0.8467442904007664 0.5 0.5 1.0 0.6666666666666666
the 5 times train_loss is tensor(0.6714, grad_fn=<BinaryCrossEntropyBackward0>)
the 5 times test_loss is tensor(0.6690, grad_fn=<BinaryCrossEntropyBackward0>)
0.8368482829124229 0.8462798150545421 0.5009276437847866 0.500464252553389 1.0 0.6670792079207921
the 6 times train_loss is tensor(0.6671, grad_fn=<BinaryCrossEntropyBackward0>)
the 6 times test_loss is tensor(0.6649, grad_fn=<BinaryCrossEntropyBackward0>)
0.8368000936249015 0.845908025178044 0.5027829313543599 0.5013953488372093 1.0 0.6679058240396529
the 7 times train_loss is tensor(0.6627, grad_fn=<BinaryCrossEntropyBackward0>)
the 7 times test_loss is tensor(0.6606, grad_fn=<BinaryCrossEntropyBackward0>)
0.8366486415784057 0.8455281406370769 0.5111317254174397 0.5056285178236398 1.0 0.6716510903426792
the 8 times train_loss is tensor(0.6581, grad_fn=<BinaryCrossEntropyBackward0>)
the 8 times test_loss is tensor(0.6562, grad_fn=<BinaryCrossEntropyBackward0>)
0.8365402156814825 0.8452486886737431 0.536178107606679 0.5187680461982676 1.0 0.6831432192648923
the 9 times train_loss is tensor(0.6533, grad_fn=<BinaryCrossEntropyBackward0>)
the 9 times test_loss is tensor(0.6514, grad_fn=<BinaryCrossEntropyBackward0>)
0.8366004522908843 0.8451375149815052 0.5816326530612245 0.545360824742268 0.9814471243042672 0.7011265738899933
the 10 times train_loss is tensor(0.6482, grad_fn=<BinaryCrossEntropyBackward0>)
the 10 times test_loss is tensor(0.6465, grad_fn=<BinaryCrossEntropyBackward0>)
0.8367639516592604 0.8451930461757033 0.6521335807050093 0.5938215102974829 0.9628942486085343 0.7346072186836519
the 11 times train_loss is tensor(0.6429, grad_fn=<BinaryCrossEntropyBackward0>)
the 11 times test_loss is tensor(0.6413, grad_fn=<BinaryCrossEntropyBackward0>)
0.8368310724525938 0.8451455007910238 0.6966604823747681 0.6321695760598504 0.9406307977736549 0.756152125279642
the 12 times train_loss is tensor(0.6373, grad_fn=<BinaryCrossEntropyBackward0>)
the 12 times test_loss is tensor(0.6358, grad_fn=<BinaryCrossEntropyBackward0>)
0.8368827038320811 0.8452040330744871 0.7170686456400742 0.6547619047619048 0.9183673469387755 0.7644787644787644
the 13 times train_loss is tensor(0.6314, grad_fn=<BinaryCrossEntropyBackward0>)
the 13 times test_loss is tensor(0.6301, grad_fn=<BinaryCrossEntropyBackward0>)
0.836958429855329 0.8451916838320874 0.7226345083487941 0.6652892561983471 0.8961038961038961 0.7636363636363638
the 14 times train_loss is tensor(0.6253, grad_fn=<BinaryCrossEntropyBackward0>)
the 14 times test_loss is tensor(0.6242, grad_fn=<BinaryCrossEntropyBackward0>)
0.8371924921090041 0.8453535880180414 0.7291280148423006 0.6756756756756757 0.8812615955473099 0.7648953301127215
the 15 times train_loss is tensor(0.6190, grad_fn=<BinaryCrossEntropyBackward0>)
the 15 times test_loss is tensor(0.6182, grad_fn=<BinaryCrossEntropyBackward0>)
