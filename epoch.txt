the 1 times train_loss is 0.6931
the 1 times test_loss is 0.6925
0.7940097273518952 0.7845068135532981 0.5 0.0 0.0 0.0
the 2 times train_loss is 0.6925
the 2 times test_loss is 0.6769
0.858230558204054 0.8647264467573894 0.525974025974026 0.5133333333333333 1.0 0.6784140969162996
the 3 times train_loss is 0.6772
the 3 times test_loss is 0.6307
0.8513704689161885 0.8608628956641653 0.7244897959183674 0.7023411371237458 0.7792207792207793 0.7387862796833773
the 4 times train_loss is 0.6308
the 4 times test_loss is 0.5737
0.8724395138389307 0.8779994674053344 0.764378478664193 0.8450363196125908 0.647495361781076 0.7331932773109244
the 5 times train_loss is 0.5738
the 5 times test_loss is 0.5192
0.8648600273302103 0.8671082246812398 0.7523191094619666 0.7982456140350878 0.6753246753246753 0.7316582914572864
the 6 times train_loss is 0.5199
the 6 times test_loss is 0.4783
0.8820016453199595 0.8841568343505003 0.7662337662337663 0.8560794044665012 0.640074211502783 0.7324840764331211
the 7 times train_loss is 0.4804
the 7 times test_loss is 0.4481
0.8863008181852603 0.8922023750969825 0.8024118738404453 0.8574561403508771 0.725417439703154 0.7859296482412059
the 8 times train_loss is 0.4558
the 8 times test_loss is 0.4198
0.893546421773297 0.8968183245449749 0.8079777365491652 0.8547008547008547 0.7421150278293135 0.7944389275074478
the 9 times train_loss is 0.4423
the 9 times test_loss is 0.4962
0.915923461643048 0.9232902834915249 0.7541743970315399 0.959731543624161 0.5306122448979592 0.6833930704898447
the 10 times train_loss is 0.4732
the 10 times test_loss is 0.4612
0.9142230682119363 0.9162851579989775 0.7458256029684601 0.6745718050065876 0.9499072356215214 0.7889060092449923
the 11 times train_loss is 0.4933
the 11 times test_loss is 0.3933
0.9146533297076631 0.9151350457092101 0.8320964749536178 0.7963576158940397 0.8923933209647495 0.8416447944007
the 12 times train_loss is 0.4185
the 12 times test_loss is 0.3898
0.9130424306676626 0.9149486421811701 0.8404452690166976 0.892933618843683 0.7736549165120594 0.8290258449304176
the 13 times train_loss is 0.3906
the 13 times test_loss is 0.4306
0.9133177980249276 0.9158724541685923 0.8330241187384044 0.9107551487414187 0.738404452690167 0.8155737704918034
the 14 times train_loss is 0.4147
the 14 times test_loss is 0.4012
0.915926903735014 0.918890011772837 0.8330241187384044 0.9107551487414187 0.738404452690167 0.8155737704918034
the 15 times train_loss is 0.3913
the 15 times test_loss is 0.3785
0.9177030231893736 0.9196068395601487 0.8423005565862709 0.9037199124726477 0.7662337662337663 0.8293172690763052
the 16 times train_loss is 0.3795
the 16 times test_loss is 0.3751
0.9179319223051002 0.9175673192607027 0.8432282003710575 0.87 0.8070500927643784 0.8373435996150144
the 17 times train_loss is 0.3830
the 17 times test_loss is 0.3665
0.9192209857462972 0.9188866819741374 0.8423005565862709 0.863905325443787 0.8126159554730983 0.8374760994263862
the 18 times train_loss is 0.3750
the 18 times test_loss is 0.3586
0.9224152470905718 0.9242938354662967 0.8404452690166976 0.8895966029723992 0.7773654916512059 0.8297029702970297
the 19 times train_loss is 0.3578
the 19 times test_loss is 0.3769
0.9239332096474954 0.9266820971465092 0.8274582560296846 0.9057471264367816 0.7309833024118738 0.8090349075975359
the 20 times train_loss is 0.3679
the 20 times test_loss is 0.3699
0.9265078944379236 0.9293543398465954 0.8283858998144712 0.9116279069767442 0.7272727272727273 0.8090815273477813
the 21 times train_loss is 0.3623
the 21 times test_loss is 0.3442
0.9275439641196332 0.9295842962671373 0.8460111317254174 0.8845360824742268 0.7959183673469388 0.837890625
the 22 times train_loss is 0.3450
the 22 times test_loss is 0.3459
0.9271859865551887 0.9292555819498978 0.8506493506493507 0.8539325842696629 0.8460111317254174 0.8499534016775396
the 23 times train_loss is 0.3539
the 23 times test_loss is 0.3376
0.9289655481015142 0.9316727279464692 0.8562152133580705 0.8735408560311284 0.8330241187384044 0.8528015194681862
the 24 times train_loss is 0.3419
the 24 times test_loss is 0.3512
0.9319257471921134 0.936370744271969 0.8562152133580705 0.9210526315789473 0.7792207792207793 0.8442211055276382
the 25 times train_loss is 0.3496
the 25 times test_loss is 0.3465
0.9325935130334813 0.93665992910055 0.8571428571428571 0.9139784946236559 0.7884972170686456 0.846613545816733
the 26 times train_loss is 0.3462
the 26 times test_loss is 0.3322
0.9314163175811732 0.9339879396800888 0.8580705009276438 0.8669201520912547 0.8460111317254174 0.8563380281690142
the 27 times train_loss is 0.3385
the 27 times test_loss is 0.3332
0.9315918642714296 0.933876658218771 0.8506493506493507 0.8436363636363636 0.8608534322820037 0.852157943067034
the 28 times train_loss is 0.3427
the 28 times test_loss is 0.3281
0.9342147383493793 0.9366608515207582 0.8562152133580705 0.872093023255814 0.8348794063079777 0.8530805687203792
the 29 times train_loss is 0.3331
the 29 times test_loss is 0.3360
0.935822195297414 0.9384939389420598 0.8487940630797773 0.893305439330544 0.7922077922077922 0.8397246804326449
the 30 times train_loss is 0.3349
the 30 times test_loss is 0.3376
0.9354332389052771 0.9378444045880528 0.8469387755102041 0.8928571428571429 0.7884972170686456 0.8374384236453203
the 31 times train_loss is 0.3360
the 31 times test_loss is 0.3273
0.9348928304666445 0.9367374085342961 0.8543599257884972 0.8774703557312253 0.8237476808905381 0.8497607655502394
the 32 times train_loss is 0.3315
the 32 times test_loss is 0.3252
0.9344488006030545 0.9358900657911027 0.8617810760667903 0.8679245283018868 0.8534322820037106 0.8606173994387278
the 33 times train_loss is 0.3336
the 33 times test_loss is 0.3242
0.9352163871114308 0.9367721066576903 0.859925788497217 0.8674242424242424 0.849721706864564 0.8584817244611058
the 34 times train_loss is 0.3300
the 34 times test_loss is 0.3280
0.9365071715986107 0.9386072570608868 0.8562152133580705 0.8870967741935484 0.8163265306122449 0.8502415458937197
the 35 times train_loss is 0.3281
the 35 times test_loss is 0.3313
0.9375191466365598 0.939934474777551 0.8580705009276438 0.8954918032786885 0.8107606679035251 0.8510223953261927
the 36 times train_loss is 0.3295
the 36 times test_loss is 0.3227
0.9379975974198078 0.939838256853132 0.8571428571428571 0.882703777335984 0.8237476808905381 0.8522072936660269
the 37 times train_loss is 0.3256
the 37 times test_loss is 0.3163
0.9385207953986114 0.9396830376851091 0.8580705009276438 0.8683206106870229 0.8441558441558441 0.8560677328316086
the 38 times train_loss is 0.3256
the 38 times test_loss is 0.3138
0.9397909273339965 0.9406271802373648 0.8664192949907236 0.8776290630975143 0.8515769944341373 0.864406779661017
the 39 times train_loss is 0.3231
the 39 times test_loss is 0.3196
0.9401661153582701 0.9409167977366765 0.862708719851577 0.8949494949494949 0.8218923933209648 0.8568665377176016
the 40 times train_loss is 0.3210
the 40 times test_loss is 0.3247
0.9386102897897226 0.9395914732819115 0.8608534322820037 0.8929292929292929 0.8200371057513914 0.8549323017408124
the 41 times train_loss is 0.3218
the 41 times test_loss is 0.3133
0.9404655773592958 0.9412884796932784 0.8580705009276438 0.8711538461538462 0.8404452690166976 0.8555240793201133
the 42 times train_loss is 0.3181
the 42 times test_loss is 0.3092
0.9418665087893818 0.9425294037458304 0.8645640074211502 0.8815533980582524 0.8423005565862709 0.8614800759013282
the 43 times train_loss is 0.3168
the 43 times test_loss is 0.3149
0.9428612733675019 0.9434912261228693 0.8608534322820037 0.9026915113871635 0.8089053803339518 0.8532289628180039
the 44 times train_loss is 0.3160
the 44 times test_loss is 0.3135
0.94329841904716 0.9436825437317868 0.8571428571428571 0.8969072164948454 0.8070500927643784 0.8496093749999999
the 45 times train_loss is 0.3134
the 45 times test_loss is 0.3106
0.9413777317302363 0.94131991596889 0.862708719851577 0.8695652173913043 0.8534322820037106 0.8614232209737827
the 46 times train_loss is 0.3167
the 46 times test_loss is 0.3082
0.9450056966622034 0.9451267289942719 0.8589981447124304 0.8924949290060852 0.8163265306122449 0.8527131782945737
the 47 times train_loss is 0.3119
the 47 times test_loss is 0.3109
0.9457526306187849 0.9456842872947997 0.8580705009276438 0.9020833333333333 0.8033395176252319 0.8498527968596664
the 48 times train_loss is 0.3128
the 48 times test_loss is 0.3046
0.9439868374403226 0.9436204717714144 0.8636363636363636 0.8754789272030651 0.8478664192949907 0.8614514608859567
the 49 times train_loss is 0.3110
the 49 times test_loss is 0.3043
0.9449850441104085 0.9445791476864014 0.8636363636363636 0.8828125 0.8385899814471243 0.8601332064700286
the 50 times train_loss is 0.3083
the 50 times test_loss is 0.3059
0.9469126156112639 0.946478329702229 0.8580705009276438 0.8987603305785123 0.8070500927643784 0.8504398826979472
the 51 times train_loss is 0.3095
the 51 times test_loss is 0.3004
0.9466338061620331 0.946049144761175 0.8617810760667903 0.8838582677165354 0.8330241187384044 0.8576886341929321
the 52 times train_loss is 0.3071
the 52 times test_loss is 0.3063
0.9436529545196388 0.9425381550530256 0.8617810760667903 0.870722433460076 0.849721706864564 0.8600938967136151
the 53 times train_loss is 0.3086
the 53 times test_loss is 0.2996
0.947112256945281 0.9463660754065435 0.862708719851577 0.8871287128712871 0.8311688311688312 0.8582375478927203
the 54 times train_loss is 0.3068
the 54 times test_loss is 0.3033
0.9472740352676743 0.9464847647522372 0.859925788497217 0.8959183673469387 0.8144712430426716 0.8532555879494654
the 55 times train_loss is 0.3068
the 55 times test_loss is 0.3037
0.9451330540649385 0.9438128283421051 0.859925788497217 0.875968992248062 0.8385899814471243 0.8568720379146919
the 56 times train_loss is 0.3051
the 56 times test_loss is 0.2992
0.9462345234939987 0.9447244195925868 0.8664192949907236 0.871939736346516 0.8589981447124304 0.8654205607476636
the 57 times train_loss is 0.3055
the 57 times test_loss is 0.3028
0.9472551037618623 0.9457122969837944 0.859925788497217 0.8911290322580645 0.8200371057513914 0.8541062801932368
the 58 times train_loss is 0.3041
the 58 times test_loss is 0.3006
0.9475734972687001 0.9459349014319415 0.859925788497217 0.8911290322580645 0.8200371057513914 0.8541062801932368
the 59 times train_loss is 0.3034
the 59 times test_loss is 0.2980
0.9464410490119475 0.9445195123042438 0.8645640074211502 0.875717017208413 0.849721706864564 0.8625235404896422
the 60 times train_loss is 0.3028
the 60 times test_loss is 0.3035
0.9453120428471609 0.9432832389950008 0.8636363636363636 0.8798449612403101 0.8423005565862709 0.8606635071090047
the 61 times train_loss is 0.3021
the 61 times test_loss is 0.2971
0.9473256666471614 0.9457719558834508 0.8608534322820037 0.883629191321499 0.8311688311688312 0.8565965583173997
the 62 times train_loss is 0.3027
the 62 times test_loss is 0.2992
0.9476354549240846 0.9458780290110823 0.8589981447124304 0.8893360160965795 0.8200371057513914 0.8532818532818532
the 63 times train_loss is 0.3004
the 63 times test_loss is 0.3058
0.9438216170259637 0.9412844449439398 0.8664192949907236 0.883495145631068 0.8441558441558441 0.8633776091081594
the 64 times train_loss is 0.3026
the 64 times test_loss is 0.2939
0.9473050140953666 0.9458573606072975 0.859925788497217 0.8716475095785441 0.8441558441558441 0.8576814326107446
the 65 times train_loss is 0.3055
the 65 times test_loss is 0.3036
0.9480863689716061 0.946841422674605 0.8589981447124304 0.9006211180124224 0.8070500927643784 0.8512720156555773
the 66 times train_loss is 0.3039
the 66 times test_loss is 0.3019
0.9469917837264775 0.9448264217290072 0.8608534322820037 0.8897795591182365 0.8237476808905381 0.8554913294797687
the 67 times train_loss is 0.2993
the 67 times test_loss is 0.2964
0.946413512276221 0.9438624591129181 0.862708719851577 0.8548094373865699 0.8738404452690167 0.8642201834862385
the 68 times train_loss is 0.3047
the 68 times test_loss is 0.2974
0.9480381796840848 0.9460202922290852 0.8645640074211502 0.896969696969697 0.8237476808905381 0.8588007736943907
the 69 times train_loss is 0.2979
the 69 times test_loss is 0.3041
0.9484236939842557 0.946546601220957 0.8589981447124304 0.9006211180124224 0.8070500927643784 0.8512720156555773
the 70 times train_loss is 0.3015
the 70 times test_loss is 0.2912
0.9480691585117771 0.9459258565504097 0.862708719851577 0.8723809523809524 0.849721706864564 0.8609022556390977
the 71 times train_loss is 0.2989
the 71 times test_loss is 0.2948
0.947150119956905 0.9443865655018875 0.8701298701298701 0.8814531548757171 0.8552875695732839 0.8681732580037664
the 72 times train_loss is 0.2971
the 72 times test_loss is 0.3086
0.9457836094464771 0.9428826941782963 0.8608534322820037 0.8993839835728953 0.8126159554730983 0.8538011695906433
the 73 times train_loss is 0.2995
the 73 times test_loss is 0.2912
0.9480485059599822 0.9461624593121376 0.862708719851577 0.8766859344894027 0.8441558441558441 0.8601134215500945
the 74 times train_loss is 0.2982
the 74 times test_loss is 0.2923
0.9482274947422046 0.9464259841902432 0.8617810760667903 0.880859375 0.8367346938775511 0.8582302568981922
the 75 times train_loss is 0.2971
the 75 times test_loss is 0.3039
0.9479624536608369 0.9452071403152966 0.859925788497217 0.9024896265560166 0.8070500927643784 0.8521057786483839
the 76 times train_loss is 0.2965
the 76 times test_loss is 0.2944
0.9469573628068194 0.9439573763999283 0.8682745825602969 0.8696461824953445 0.8664192949907236 0.8680297397769517
the 77 times train_loss is 0.2962
the 77 times test_loss is 0.2900
0.9488746080317774 0.9467311452363062 0.8710575139146568 0.8846153846153846 0.8534322820037106 0.8687440982058545
the 78 times train_loss is 0.2931
the 78 times test_loss is 0.3014
0.9491603016649399 0.9471151716421714 0.8636363636363636 0.9066390041493776 0.8107606679035251 0.8560235063663076
the 79 times train_loss is 0.2965
the 79 times test_loss is 0.2892
0.9489503340550254 0.9467165890315913 0.8701298701298701 0.8771266540642723 0.8608534322820037 0.8689138576779026
the 80 times train_loss is 0.2925
the 80 times test_loss is 0.2948
0.9469642469907511 0.9439747148345291 0.865491651205937 0.8759541984732825 0.8515769944341373 0.8635936030103482
the 81 times train_loss is 0.2930
the 81 times test_loss is 0.2971
0.9490501547220339 0.9466675749835305 0.8608534322820037 0.8961303462321792 0.8163265306122449 0.8543689320388349
the 82 times train_loss is 0.2918
the 82 times test_loss is 0.2897
0.9487128297093841 0.9470260728615942 0.8682745825602969 0.8795411089866156 0.8534322820037106 0.8662900188323918
the 83 times train_loss is 0.2928
the 83 times test_loss is 0.2944
0.9486130090423756 0.9460365456926401 0.8645640074211502 0.8906560636182903 0.8311688311688312 0.8598848368522074
the 84 times train_loss is 0.2896
the 84 times test_loss is 0.2978
0.9466131536102381 0.9434963410971211 0.8664192949907236 0.8864970645792564 0.8404452690166976 0.8628571428571429
the 85 times train_loss is 0.2907
the 85 times test_loss is 0.2883
0.9490157338023757 0.9471419291301634 0.8701298701298701 0.8757062146892656 0.862708719851577 0.8691588785046729
the 86 times train_loss is 0.2914
the 86 times test_loss is 0.3045
0.9492153751363929 0.9471543332406401 0.859925788497217 0.9058577405857741 0.8033395176252319 0.8515240904621436
the 87 times train_loss is 0.2937
the 87 times test_loss is 0.2896
0.9483445258690422 0.9459881156698854 0.8673469387755102 0.8639705882352942 0.8719851576994434 0.8679593721144968
the 88 times train_loss is 0.2930
the 88 times test_loss is 0.3037
0.946375649264597 0.943401071716913 0.865491651205937 0.9020408163265307 0.8200371057513914 0.859086491739553
the 89 times train_loss is 0.2904
the 89 times test_loss is 0.2905
0.949029502170239 0.9476550653974241 0.8636363636363636 0.8798449612403101 0.8423005565862709 0.8606635071090047
the 90 times train_loss is 0.2887
the 90 times test_loss is 0.2924
0.9489606603309229 0.9472993561365628 0.8664192949907236 0.888015717092338 0.8385899814471243 0.8625954198473282
the 91 times train_loss is 0.2871
the 91 times test_loss is 0.3036
0.9454428423418617 0.9423514622230803 0.8636363636363636 0.892 0.8274582560296846 0.8585178055822907
the 92 times train_loss is 0.2884
the 92 times test_loss is 0.2911
0.9475597289008368 0.9453753199453796 0.8673469387755102 0.8666666666666667 0.8682745825602969 0.8674698795180723
the 93 times train_loss is 0.2885
the 93 times test_loss is 0.3079
0.9481173477992985 0.9464667291304113 0.859925788497217 0.9092827004219409 0.7996289424860853 0.8509378084896346
the 94 times train_loss is 0.2901
the 94 times test_loss is 0.2913
0.9474013926704093 0.9458950171627092 0.8664192949907236 0.8664192949907236 0.8664192949907236 0.8664192949907236
the 95 times train_loss is 0.2883
the 95 times test_loss is 0.3069
0.9447131188451092 0.9425415284069427 0.8645640074211502 0.8953722334004024 0.8256029684601113 0.859073359073359
the 96 times train_loss is 0.2864
the 96 times test_loss is 0.2965
0.9469332681630588 0.9460628921503784 0.8608534322820037 0.8776699029126214 0.8385899814471243 0.857685009487666
the 97 times train_loss is 0.2834
the 97 times test_loss is 0.2969
0.9466252009321185 0.9459140478522765 0.862708719851577 0.8766859344894027 0.8441558441558441 0.8601134215500945
the 98 times train_loss is 0.2832
the 98 times test_loss is 0.3112
0.9436254177839123 0.9416453321437658 0.862708719851577 0.896551724137931 0.8200371057513914 0.8565891472868218
the 99 times train_loss is 0.2840
the 99 times test_loss is 0.2987
0.9450160229381008 0.9439295190287209 0.865491651205937 0.8689138576779026 0.8608534322820037 0.8648648648648649
the 100 times train_loss is 0.2843
the 100 times test_loss is 0.3191
0.9450022545702376 0.9444827228014219 0.8636363636363636 0.9083333333333333 0.8089053803339518 0.8557409224730127
the 101 times train_loss is 0.2868
the 101 times test_loss is 0.3030
0.9434395448177585 0.9425155894721443 0.865491651205937 0.8581818181818182 0.87569573283859 0.866850321395776
the 102 times train_loss is 0.2895
the 102 times test_loss is 0.3203
0.9437149121750236 0.9430198541378129 0.8562152133580705 0.9067796610169492 0.7940630797773655 0.8466864490603364
the 103 times train_loss is 0.2855
the 103 times test_loss is 0.3044
0.944021258359981 0.9444439116341741 0.865491651205937 0.8773946360153256 0.849721706864564 0.8633364750235627
the 104 times train_loss is 0.2804
the 104 times test_loss is 0.3077
0.942176297066305 0.9419838950657997 0.8636363636363636 0.869811320754717 0.8552875695732839 0.862488306828812
the 105 times train_loss is 0.2803
the 105 times test_loss is 0.3327
0.9405172087387831 0.9396604929405652 0.8580705009276438 0.9141630901287554 0.7903525046382189 0.8477611940298507
the 106 times train_loss is 0.2854
the 106 times test_loss is 0.3068
0.942802757804083 0.9437742291086321 0.8636363636363636 0.8563636363636363 0.8738404452690167 0.8650137741046832
the 107 times train_loss is 0.2906
the 107 times test_loss is 0.3187
0.9421969496181 0.9425278278839635 0.862708719851577 0.8981670061099797 0.8181818181818182 0.8563106796116505
the 108 times train_loss is 0.2795
the 108 times test_loss is 0.3280
0.9396394752875008 0.9392751616995035 0.8589981447124304 0.9039665970772442 0.8033395176252319 0.8506876227897839
the 109 times train_loss is 0.2814
the 109 times test_loss is 0.3103
0.9413639633623732 0.9429400505404462 0.8645640074211502 0.8645640074211502 0.8645640074211502 0.8645640074211502
the 110 times train_loss is 0.2854
the 110 times test_loss is 0.3210
0.9415222995928005 0.9431797756009336 0.8608534322820037 0.8929292929292929 0.8200371057513914 0.8549323017408124
the 111 times train_loss is 0.2791
the 111 times test_loss is 0.3326
0.9360631417350209 0.9357174286322429 0.8636363636363636 0.8983739837398373 0.8200371057513914 0.8574199806013578
the 112 times train_loss is 0.2801
the 112 times test_loss is 0.3113
0.9408029023719455 0.94210264606661 0.8617810760667903 0.8679245283018868 0.8534322820037106 0.8606173994387278
the 113 times train_loss is 0.2792
the 113 times test_loss is 0.3190
0.9415876993401511 0.9427144094839108 0.859925788497217 0.888 0.8237476808905381 0.8546679499518768
the 114 times train_loss is 0.2776
the 114 times test_loss is 0.3265
0.9395878439080134 0.9393206034255056 0.8580705009276438 0.8938775510204081 0.8126159554730983 0.8513119533527697
the 115 times train_loss is 0.2755
the 115 times test_loss is 0.3218
0.9373057369346793 0.9364320744544418 0.862708719851577 0.8640595903165735 0.8608534322820037 0.862453531598513
the 116 times train_loss is 0.2789
the 116 times test_loss is 0.3264
0.9413949421900655 0.9428256781161449 0.8580705009276438 0.8922764227642277 0.8144712430426716 0.8516003879728419
the 117 times train_loss is 0.2794
the 117 times test_loss is 0.3163
0.9406583345093814 0.9423361640679616 0.859925788497217 0.87890625 0.8348794063079777 0.8563273073263559
the 118 times train_loss is 0.2750
the 118 times test_loss is 0.3193
0.9376637144991241 0.9380468326897373 0.8580705009276438 0.8683206106870229 0.8441558441558441 0.8560677328316086
the 119 times train_loss is 0.2763
the 119 times test_loss is 0.3291
0.9380457867073293 0.9378437837393503 0.8580705009276438 0.8922764227642277 0.8144712430426716 0.8516003879728419
the 120 times train_loss is 0.2753
the 120 times test_loss is 0.3203
0.9395706334481844 0.9404314219336241 0.862708719851577 0.8810916179337231 0.8385899814471243 0.8593155893536121
the 121 times train_loss is 0.2740
the 121 times test_loss is 0.3169
0.9416634253633988 0.9422493443115407 0.8636363636363636 0.8798449612403101 0.8423005565862709 0.8606635071090047
the 122 times train_loss is 0.2738
the 122 times test_loss is 0.3273
0.9389613831702356 0.9391543359429795 0.8580705009276438 0.8938775510204081 0.8126159554730983 0.8513119533527697
the 123 times train_loss is 0.2738
the 123 times test_loss is 0.3265
0.9354263547213455 0.9359508249368541 0.8617810760667903 0.8735632183908046 0.8460111317254174 0.8595664467483506
the 124 times train_loss is 0.2745
the 124 times test_loss is 0.3276
0.9380423446153634 0.9389303669282595 0.8589981447124304 0.8862275449101796 0.8237476808905381 0.8538461538461538
the 125 times train_loss is 0.2714
the 125 times test_loss is 0.3251
0.9398253482536546 0.9410542317214223 0.8580705009276438 0.8891129032258065 0.8181818181818182 0.8521739130434782
the 126 times train_loss is 0.2718
the 126 times test_loss is 0.3210
0.9390887405729706 0.9407138050181765 0.8617810760667903 0.875 0.8441558441558441 0.8593012275731822
the 127 times train_loss is 0.2718
the 127 times test_loss is 0.3328
0.9375707780160469 0.9384350624345031 0.8552875695732839 0.8868686868686869 0.8144712430426716 0.849129593810445
the 128 times train_loss is 0.2712
the 128 times test_loss is 0.3279
0.937240337187329 0.9378613078866523 0.8589981447124304 0.8771929824561403 0.8348794063079777 0.8555133079847909
the 129 times train_loss is 0.2695
the 129 times test_loss is 0.3220
0.9392642872632271 0.9403521704288467 0.8580705009276438 0.8754863813229572 0.8348794063079777 0.8547008547008547
the 130 times train_loss is 0.2701
the 130 times test_loss is 0.3290
0.9398046957018598 0.9411257802111401 0.8552875695732839 0.8853118712273642 0.8163265306122449 0.8494208494208494
the 131 times train_loss is 0.2696
the 131 times test_loss is 0.3277
0.9371474007042521 0.9382066478201438 0.859925788497217 0.877431906614786 0.8367346938775511 0.8566001899335234
the 132 times train_loss is 0.2693
the 132 times test_loss is 0.3348
0.9367894231398074 0.9369931347858327 0.8636363636363636 0.8951612903225806 0.8237476808905381 0.8579710144927536
the 133 times train_loss is 0.2694
the 133 times test_loss is 0.3264
0.9379838290519447 0.939769970018808 0.8589981447124304 0.8757281553398059 0.8367346938775511 0.855787476280835
the 134 times train_loss is 0.2710
the 134 times test_loss is 0.3339
0.938895983422885 0.9405307331014674 0.8543599257884972 0.8913934426229508 0.8070500927643784 0.8471275559883155
the 135 times train_loss is 0.2691
the 135 times test_loss is 0.3314
0.9350098615934821 0.9358795641685638 0.8580705009276438 0.865530303030303 0.8478664192949907 0.8566073102155576
the 136 times train_loss is 0.2699
the 136 times test_loss is 0.3364
0.9379012188447651 0.9394856726620808 0.8534322820037106 0.8895705521472392 0.8070500927643784 0.8463035019455253
the 137 times train_loss is 0.2696
the 137 times test_loss is 0.3234
0.9387445313763894 0.940145913878102 0.8589981447124304 0.8757281553398059 0.8367346938775511 0.855787476280835
the 138 times train_loss is 0.2684
the 138 times test_loss is 0.3350
0.9375466833722863 0.9376477439838472 0.8580705009276438 0.8954918032786885 0.8107606679035251 0.8510223953261927
the 139 times train_loss is 0.2710
the 139 times test_loss is 0.3283
0.935897921320662 0.9373407398217123 0.8617810760667903 0.870722433460076 0.849721706864564 0.8600938967136151
the 140 times train_loss is 0.2730
the 140 times test_loss is 0.3397
0.9397048750348512 0.9409966677106414 0.852504638218924 0.902542372881356 0.7903525046382189 0.8427299703264095
the 141 times train_loss is 0.2722
the 141 times test_loss is 0.3227
0.9376499461312607 0.9386061103120996 0.859925788497217 0.8646616541353384 0.8534322820037106 0.8590102707749766
the 142 times train_loss is 0.2718
the 142 times test_loss is 0.3309
0.9391162773086972 0.9395981244549417 0.852504638218924 0.8877551020408163 0.8070500927643784 0.8454810495626821
the 143 times train_loss is 0.2673
the 143 times test_loss is 0.3277
0.9387169946406627 0.9396270000853474 0.8562152133580705 0.8824701195219123 0.8218923933209648 0.851104707012488
the 144 times train_loss is 0.2674
the 144 times test_loss is 0.3227
0.9394260655856204 0.9401787282433668 0.865491651205937 0.8817829457364341 0.8441558441558441 0.8625592417061612
the 145 times train_loss is 0.2659
the 145 times test_loss is 0.3312
0.9381903545698933 0.9382094205868532 0.8692022263450835 0.9044715447154471 0.8256029684601113 0.8632395732298739
the 146 times train_loss is 0.2681
the 146 times test_loss is 0.3289
0.9351888503757044 0.9370080324590571 0.8589981447124304 0.864406779661017 0.8515769944341373 0.8579439252336448
the 147 times train_loss is 0.2755
the 147 times test_loss is 0.3484
0.9395396546204922 0.9406422396394378 0.852504638218924 0.9130434782608695 0.7792207792207793 0.8408408408408409
the 148 times train_loss is 0.2760
the 148 times test_loss is 0.3214
0.9380389025233976 0.9380074389398211 0.8664192949907236 0.8747628083491461 0.8552875695732839 0.8649155722326454
the 149 times train_loss is 0.2685
the 149 times test_loss is 0.3196
0.9388546783192953 0.9398830273934773 0.8692022263450835 0.8783269961977186 0.8571428571428571 0.8676056338028169
the 150 times train_loss is 0.2698
the 150 times test_loss is 0.3364
0.9403244515886976 0.9411716712888666 0.8608534322820037 0.9112050739957717 0.7996289424860853 0.8517786561264822
the 151 times train_loss is 0.2755
the 151 times test_loss is 0.3155
0.9396945487589538 0.9410679289281403 0.8664192949907236 0.8597449908925319 0.87569573283859 0.8676470588235294
the 152 times train_loss is 0.2872
the 152 times test_loss is 0.3317
0.9378254928215172 0.9359550981587949 0.8460111317254174 0.8926315789473684 0.7866419294990723 0.8362919132149901
the 153 times train_loss is 0.2837
the 153 times test_loss is 0.3221
0.9434808499213482 0.9435234867238486 0.8543599257884972 0.9012605042016807 0.7959183673469388 0.8453201970443349
the 154 times train_loss is 0.2781
the 154 times test_loss is 0.3085
0.9422589072734845 0.9427918514682508 0.8636363636363636 0.8754789272030651 0.8478664192949907 0.8614514608859567
the 155 times train_loss is 0.2689
the 155 times test_loss is 0.3398
0.9333886362775841 0.9318441272578211 0.8636363636363636 0.892 0.8274582560296846 0.8585178055822907
the 156 times train_loss is 0.2808
the 156 times test_loss is 0.3282
0.941715056742886 0.9438657047294999 0.8617810760667903 0.8421052631578947 0.8905380333951762 0.865644724977457
the 157 times train_loss is 0.3123
the 157 times test_loss is 0.3326
0.9456734625035711 0.9459762319386141 0.859925788497217 0.9163090128755365 0.7922077922077922 0.8497512437810946
the 158 times train_loss is 0.2807
the 158 times test_loss is 0.3500
0.9385724267780986 0.936843313255193 0.8478664192949907 0.9157427937915743 0.7662337662337663 0.8343434343434345
the 159 times train_loss is 0.2877
the 159 times test_loss is 0.3129
0.9390508775613466 0.9395330526623661 0.862708719851577 0.8709677419354839 0.8515769944341373 0.8611632270168855
the 160 times train_loss is 0.2858
the 160 times test_loss is 0.3103
0.9400594105073299 0.9409805872101338 0.865491651205937 0.8661710037174721 0.8645640074211502 0.8653667595171773
the 161 times train_loss is 0.2928
the 161 times test_loss is 0.3105
0.9420523817555359 0.9418881099285026 0.8608534322820037 0.8866799204771372 0.8274582560296846 0.8560460652591171
the 162 times train_loss is 0.2822
the 162 times test_loss is 0.3196
0.9454462844338275 0.9442475635177104 0.8552875695732839 0.908315565031983 0.7903525046382189 0.8452380952380952
the 163 times train_loss is 0.2825
the 163 times test_loss is 0.3082
0.946561522230751 0.9447437990039718 0.8617810760667903 0.8995901639344263 0.8144712430426716 0.8549172346640701
the 164 times train_loss is 0.2764
the 164 times test_loss is 0.3042
0.9446959083852803 0.9420407015363405 0.865491651205937 0.8716981132075472 0.8571428571428571 0.864359214218896
the 165 times train_loss is 0.2821
the 165 times test_loss is 0.3031
0.9441933629582715 0.9416230743414177 0.8682745825602969 0.8738229755178908 0.8608534322820037 0.8672897196261682
the 166 times train_loss is 0.2766
the 166 times test_loss is 0.3140
0.9432467876676729 0.9416881790040396 0.8571428571428571 0.8904665314401623 0.8144712430426716 0.8507751937984495
the 167 times train_loss is 0.2776
the 167 times test_loss is 0.3134
0.9426237690218607 0.9428559804687562 0.8617810760667903 0.8931451612903226 0.8218923933209648 0.8560386473429952
the 168 times train_loss is 0.2743
the 168 times test_loss is 0.3077
0.9423415174806641 0.9431553611851274 0.8682745825602969 0.882466281310212 0.849721706864564 0.8657844990548206
the 169 times train_loss is 0.2703
the 169 times test_loss is 0.3127
0.9412090692239116 0.9413642697587424 0.862708719851577 0.8840864440078585 0.8348794063079777 0.8587786259541985
the 170 times train_loss is 0.2737
the 170 times test_loss is 0.3192
0.9409887753380994 0.9408291480134459 0.8562152133580705 0.8870967741935484 0.8163265306122449 0.8502415458937197
the 171 times train_loss is 0.2722
the 171 times test_loss is 0.3217
0.9400112212198086 0.9396826459418284 0.8552875695732839 0.8868686868686869 0.8144712430426716 0.849129593810445
the 172 times train_loss is 0.2711
the 172 times test_loss is 0.3177
0.9400559684153641 0.939879189181766 0.8673469387755102 0.8837209302325582 0.8460111317254174 0.8644549763033176
the 173 times train_loss is 0.2713
the 173 times test_loss is 0.3141
0.9428061998960489 0.9420338857702475 0.865491651205937 0.8908730158730159 0.8330241187384044 0.8609779482262704
the 174 times train_loss is 0.2686
the 174 times test_loss is 0.3156
0.9427889894362198 0.9415541191137877 0.862708719851577 0.8871287128712871 0.8311688311688312 0.8582375478927203
the 175 times train_loss is 0.2704
the 175 times test_loss is 0.3076
0.9435290392088695 0.9431267619404333 0.8645640074211502 0.8686679174484052 0.8589981447124304 0.8638059701492536
the 176 times train_loss is 0.2702
the 176 times test_loss is 0.3131
0.9433844713463054 0.9433663132873378 0.8636363636363636 0.8951612903225806 0.8237476808905381 0.8579710144927536
the 177 times train_loss is 0.2665
the 177 times test_loss is 0.3222
0.9421866233422025 0.9422649078898122 0.8562152133580705 0.8966942148760331 0.8051948051948052 0.8484848484848485
the 178 times train_loss is 0.2686
the 178 times test_loss is 0.3165
0.9402143046457915 0.9406097072546945 0.8608534322820037 0.8806262230919765 0.8348794063079777 0.8571428571428571
the 179 times train_loss is 0.2677
the 179 times test_loss is 0.3152
0.940389851336048 0.9405320826758258 0.859925788497217 0.877431906614786 0.8367346938775511 0.8566001899335234
the 180 times train_loss is 0.2677
the 180 times test_loss is 0.3202
0.9417563618464758 0.9415308318215593 0.8571428571428571 0.8857715430861723 0.8200371057513914 0.8516377649325625
the 181 times train_loss is 0.2665
the 181 times test_loss is 0.3162
0.9431194302649378 0.9430031914622415 0.8580705009276438 0.8844621513944223 0.8237476808905381 0.8530259365994236
the 182 times train_loss is 0.2655
the 182 times test_loss is 0.3127
0.9423518437565616 0.9423033392064928 0.8571428571428571 0.8752436647173489 0.8330241187384044 0.8536121673003801
the 183 times train_loss is 0.2660
the 183 times test_loss is 0.3230
0.9398597691733127 0.9387265097829666 0.8552875695732839 0.8792079207920792 0.8237476808905381 0.8505747126436781
the 184 times train_loss is 0.2657
the 184 times test_loss is 0.3170
0.941236605959638 0.9417215690973563 0.8571428571428571 0.8796844181459567 0.8274582560296846 0.8527724665391969
the 185 times train_loss is 0.2642
the 185 times test_loss is 0.3231
0.9408304391076721 0.9416516260001553 0.8534322820037106 0.8832997987927566 0.8144712430426716 0.8474903474903476
the 186 times train_loss is 0.2640
the 186 times test_loss is 0.3272
0.9388684466871585 0.9398156360065861 0.8562152133580705 0.8824701195219123 0.8218923933209648 0.851104707012488
the 187 times train_loss is 0.2636
the 187 times test_loss is 0.3285
0.9372644318310897 0.9381910419211654 0.8543599257884972 0.8745098039215686 0.8274582560296846 0.8503336510962821
the 188 times train_loss is 0.2638
the 188 times test_loss is 0.3376
0.9372919685668162 0.937842654261976 0.8552875695732839 0.890020366598778 0.8107606679035251 0.8485436893203884
the 189 times train_loss is 0.2633
the 189 times test_loss is 0.3305
0.9388684466871586 0.9402196950407431 0.8562152133580705 0.8779527559055118 0.8274582560296846 0.8519579751671442
the 190 times train_loss is 0.2639
the 190 times test_loss is 0.3370
0.9374675152570727 0.9380815674037593 0.8571428571428571 0.8857715430861723 0.8200371057513914 0.8516377649325625
the 191 times train_loss is 0.2630
the 191 times test_loss is 0.3286
0.9377910719018591 0.9391809250980168 0.8571428571428571 0.8709055876685935 0.8385899814471243 0.8544423440453688
the 192 times train_loss is 0.2630
the 192 times test_loss is 0.3378
0.9376292935794659 0.9384877260982274 0.859925788497217 0.9008264462809917 0.8089053803339518 0.852394916911046
the 193 times train_loss is 0.2628
the 193 times test_loss is 0.3275
0.9385827530539961 0.9404853948810215 0.859925788497217 0.87890625 0.8348794063079777 0.8563273073263559
the 194 times train_loss is 0.2644
the 194 times test_loss is 0.3363
0.9372265688194658 0.9378160876258513 0.8543599257884972 0.889795918367347 0.8089053803339518 0.8474246841593781
the 195 times train_loss is 0.2624
the 195 times test_loss is 0.3286
0.9385930793298934 0.939682592738337 0.859925788497217 0.8849206349206349 0.8274582560296846 0.8552253116011505
the 196 times train_loss is 0.2613
the 196 times test_loss is 0.3300
0.9385070270307482 0.9397220857986746 0.859925788497217 0.8849206349206349 0.8274582560296846 0.8552253116011505
the 197 times train_loss is 0.2608
the 197 times test_loss is 0.3370
0.9371198639685254 0.9380564034211357 0.8562152133580705 0.8855421686746988 0.8181818181818182 0.8505303760848602
the 198 times train_loss is 0.2612
the 198 times test_loss is 0.3319
0.9372678739230554 0.9390319711917003 0.8552875695732839 0.8689788053949904 0.8367346938775511 0.8525519848771268
the 199 times train_loss is 0.2626
the 199 times test_loss is 0.3486
0.9358703845849353 0.9364139200626824 0.8543599257884972 0.8979166666666667 0.7996289424860853 0.845927379784102
the 200 times train_loss is 0.2640
the 200 times test_loss is 0.3309
0.9373401578543377 0.9395660830551417 0.8636363636363636 0.8740458015267175 0.849721706864564 0.8617121354656633
the 201 times train_loss is 0.2714
the 201 times test_loss is 0.3317
0.9382832910529704 0.9401221338266874 0.8534322820037106 0.8772277227722772 0.8218923933209648 0.8486590038314178
the 202 times train_loss is 0.2623
the 202 times test_loss is 0.3640
0.9328482278389514 0.9322292843993456 0.852504638218924 0.907725321888412 0.7847866419294991 0.8417910447761194
the 203 times train_loss is 0.2779
the 203 times test_loss is 0.3226
0.9381318390064745 0.9410180113131321 0.862708719851577 0.862708719851577 0.862708719851577 0.862708719851577
the 204 times train_loss is 0.2749
the 204 times test_loss is 0.3214
0.9385999635138251 0.9412972464444741 0.859925788497217 0.8632958801498127 0.8552875695732839 0.8592730661696178
the 205 times train_loss is 0.2793
the 205 times test_loss is 0.3323
0.9392711714471588 0.9407622776940658 0.8534322820037106 0.8895705521472392 0.8070500927643784 0.8463035019455253
the 206 times train_loss is 0.2713
the 206 times test_loss is 0.3407
0.9384175326396371 0.9381291982968087 0.849721706864564 0.9053763440860215 0.7810760667903525 0.8386454183266933
the 207 times train_loss is 0.2708
the 207 times test_loss is 0.3254
0.938937288526475 0.9378255091983466 0.8580705009276438 0.8891129032258065 0.8181818181818182 0.8521739130434782
the 208 times train_loss is 0.2696
the 208 times test_loss is 0.3133
0.9412159534078433 0.9416446296790767 0.859925788497217 0.8745173745173745 0.8404452690166976 0.8571428571428571
the 209 times train_loss is 0.2693
the 209 times test_loss is 0.3147
0.9408683021192961 0.9426562640999722 0.8692022263450835 0.8901960784313725 0.8423005565862709 0.86558627264061
the 210 times train_loss is 0.2696
the 210 times test_loss is 0.3208
0.9389063096987825 0.941448646822921 0.8580705009276438 0.8814229249011858 0.8274582560296846 0.8535885167464116
the 211 times train_loss is 0.2704
the 211 times test_loss is 0.3215
0.9382970594208335 0.9402448787348817 0.859925788497217 0.8818897637795275 0.8311688311688312 0.8557784145176696
the 212 times train_loss is 0.2657
the 212 times test_loss is 0.3225
0.9390577617452783 0.9392510068900819 0.8552875695732839 0.8837675350701403 0.8181818181818182 0.8497109826589596
the 213 times train_loss is 0.2650
the 213 times test_loss is 0.3243
0.9405103245548514 0.9399968841973283 0.8562152133580705 0.8902439024390244 0.8126159554730983 0.8496605237633366
the 214 times train_loss is 0.2675
the 214 times test_loss is 0.3214
0.9417770143982707 0.9416018205775457 0.8580705009276438 0.886 0.8218923933209648 0.8527430221366697
the 215 times train_loss is 0.2644
the 215 times test_loss is 0.3212
0.9410679434533131 0.9411949444038529 0.8562152133580705 0.8779527559055118 0.8274582560296846 0.8519579751671442
the 216 times train_loss is 0.2641
the 216 times test_loss is 0.3238
0.9401661153582701 0.9406131149829271 0.8571428571428571 0.8781925343811395 0.8293135435992579 0.8530534351145038
the 217 times train_loss is 0.2649
the 217 times test_loss is 0.3263
0.9398253482536546 0.9402862377140955 0.8608534322820037 0.8866799204771372 0.8274582560296846 0.8560460652591171
the 218 times train_loss is 0.2632
the 218 times test_loss is 0.3265
0.9384244168235687 0.938899189436288 0.859925788497217 0.87890625 0.8348794063079777 0.8563273073263559
the 219 times train_loss is 0.2633
the 219 times test_loss is 0.3234
0.9389200780666458 0.9394981974033372 0.8580705009276438 0.8754863813229572 0.8348794063079777 0.8547008547008547
the 220 times train_loss is 0.2620
the 220 times test_loss is 0.3258
0.9400835051510905 0.9409606430423842 0.8562152133580705 0.8809523809523809 0.8237476808905381 0.8513902205177372
the 221 times train_loss is 0.2614
the 221 times test_loss is 0.3301
0.9402762623011761 0.9410232355298003 0.8562152133580705 0.8855421686746988 0.8181818181818182 0.8505303760848602
the 222 times train_loss is 0.2623
the 222 times test_loss is 0.3285
0.9395706334481845 0.9401067222810615 0.8562152133580705 0.8779527559055118 0.8274582560296846 0.8519579751671442
the 223 times train_loss is 0.2612
the 223 times test_loss is 0.3261
0.9388512362273295 0.9390428743422913 0.8589981447124304 0.8757281553398059 0.8367346938775511 0.855787476280835
the 224 times train_loss is 0.2609
the 224 times test_loss is 0.3259
0.9392229821596374 0.9400967222207 0.8580705009276438 0.8784313725490196 0.8311688311688312 0.8541468064823643
the 225 times train_loss is 0.2610
the 225 times test_loss is 0.3254
0.9394088551257913 0.9411656283093658 0.8571428571428571 0.8752436647173489 0.8330241187384044 0.8536121673003801
the 226 times train_loss is 0.2602
the 226 times test_loss is 0.3292
0.9386860158129704 0.9406153117870371 0.8562152133580705 0.8779527559055118 0.8274582560296846 0.8519579751671442
the 227 times train_loss is 0.2602
the 227 times test_loss is 0.3348
0.9373332736704059 0.9386371742087819 0.8534322820037106 0.878727634194831 0.8200371057513914 0.8483685220729366
the 228 times train_loss is 0.2596
the 228 times test_loss is 0.3373
0.9362386884252774 0.9369613958948483 0.8543599257884972 0.878968253968254 0.8218923933209648 0.8494726749760307
the 229 times train_loss is 0.2598
the 229 times test_loss is 0.3339
0.9377962350398078 0.938622316157267 0.8543599257884972 0.8759842519685039 0.8256029684601113 0.8500477554918815
the 230 times train_loss is 0.2589
the 230 times test_loss is 0.3334
0.9395086757927997 0.9406875684899336 0.8580705009276438 0.8829365079365079 0.8256029684601113 0.8533077660594439
the 231 times train_loss is 0.2588
the 231 times test_loss is 0.3333
0.9389097517907484 0.9402408990486382 0.8543599257884972 0.8774703557312253 0.8237476808905381 0.8497607655502394
the 232 times train_loss is 0.2587
the 232 times test_loss is 0.3333
0.937405557601688 0.9383980394303633 0.8534322820037106 0.8742632612966601 0.8256029684601113 0.8492366412213739
the 233 times train_loss is 0.2582
the 233 times test_loss is 0.3335
0.9372885264748503 0.9380519021130438 0.8552875695732839 0.8777120315581854 0.8256029684601113 0.8508604206500956
the 234 times train_loss is 0.2584
the 234 times test_loss is 0.3289
0.9386343844334832 0.9397233320532405 0.8562152133580705 0.8779527559055118 0.8274582560296846 0.8519579751671442
the 235 times train_loss is 0.2578
the 235 times test_loss is 0.3317
0.9396188227357058 0.9407296849169138 0.8562152133580705 0.8824701195219123 0.8218923933209648 0.851104707012488
the 236 times train_loss is 0.2580
the 236 times test_loss is 0.3323
0.9386653632611756 0.9395579329777364 0.8552875695732839 0.8777120315581854 0.8256029684601113 0.8508604206500956
the 237 times train_loss is 0.2572
the 237 times test_loss is 0.3357
0.9370579063131408 0.9376989341212407 0.8571428571428571 0.8796844181459567 0.8274582560296846 0.8527724665391969
the 238 times train_loss is 0.2572
the 238 times test_loss is 0.3378
0.9371026535086965 0.9380323943474322 0.8571428571428571 0.8811881188118812 0.8256029684601113 0.8524904214559387
the 239 times train_loss is 0.2569
the 239 times test_loss is 0.3351
0.9377015775107479 0.9391429522106896 0.8562152133580705 0.8764705882352941 0.8293135435992579 0.8522402287893232
the 240 times train_loss is 0.2569
the 240 times test_loss is 0.3410
0.9377084616946795 0.9391828109371065 0.8534322820037106 0.8848484848484849 0.8126159554730983 0.8471953578336556
the 241 times train_loss is 0.2575
the 241 times test_loss is 0.3342
0.9361250993904056 0.9375371417058604 0.8543599257884972 0.8659003831417624 0.8385899814471243 0.8520263901979265
the 242 times train_loss is 0.2601
the 242 times test_loss is 0.3517
0.9368513807951921 0.9377564363468404 0.8534322820037106 0.9044585987261147 0.7903525046382189 0.8435643564356435
the 243 times train_loss is 0.2630
the 243 times test_loss is 0.3321
0.9364348876673286 0.9379689477381215 0.8580705009276438 0.8614232209737828 0.8534322820037106 0.8574091332712022
the 244 times train_loss is 0.2670
the 244 times test_loss is 0.3338
0.9394604865052785 0.9408856443139262 0.8552875695732839 0.8853118712273642 0.8163265306122449 0.8494208494208494
the 245 times train_loss is 0.2582
the 245 times test_loss is 0.3480
0.9380629971671584 0.9385215769767689 0.8534322820037106 0.9027484143763214 0.7922077922077922 0.8438735177865612
the 246 times train_loss is 0.2651
the 246 times test_loss is 0.3244
0.9375811042919444 0.938485644428279 0.859925788497217 0.8605947955390335 0.8589981447124304 0.8597957288765089
the 247 times train_loss is 0.2652
the 247 times test_loss is 0.3254
0.9377910719018592 0.9394009752781075 0.8580705009276438 0.8697318007662835 0.8423005565862709 0.8557964184731385
the 248 times train_loss is 0.2601
the 248 times test_loss is 0.3474
0.9388856571469876 0.940310803950432 0.8543599257884972 0.9081196581196581 0.7884972170686456 0.8440913604766633
the 249 times train_loss is 0.2654
the 249 times test_loss is 0.3291
0.9387961627558765 0.9398056854828232 0.8562152133580705 0.8824701195219123 0.8218923933209648 0.851104707012488
the 250 times train_loss is 0.2575
the 250 times test_loss is 0.3266
0.937605198935705 0.9383090161073259 0.859925788497217 0.8632958801498127 0.8552875695732839 0.8592730661696178
the 251 times train_loss is 0.2627
the 251 times test_loss is 0.3325
0.938104302270748 0.9393035579974499 0.8543599257884972 0.8804780876494024 0.8200371057513914 0.8491834774255523
the 252 times train_loss is 0.2566
the 252 times test_loss is 0.3458
0.9386412686174148 0.9398650826084687 0.8534322820037106 0.8977035490605428 0.7977736549165121 0.8447937131630648
the 253 times train_loss is 0.2622
the 253 times test_loss is 0.3288
0.9384416272833978 0.9397658669163946 0.8534322820037106 0.864244741873805 0.8385899814471243 0.8512241054613936
the 254 times train_loss is 0.2576
the 254 times test_loss is 0.3282
0.9383865538119449 0.9391377948710563 0.859925788497217 0.8688212927756654 0.8478664192949907 0.8582159624413146
the 255 times train_loss is 0.2590
the 255 times test_loss is 0.3384
0.939081856389039 0.9396740508621968 0.849721706864564 0.885480572597137 0.8033395176252319 0.8424124513618677
the 256 times train_loss is 0.2579
the 256 times test_loss is 0.3356
0.939229866343569 0.940335774236297 0.8534322820037106 0.8848484848484849 0.8126159554730983 0.8471953578336556
the 257 times train_loss is 0.2569
the 257 times test_loss is 0.3282
0.9383452487083549 0.9395169792567943 0.8580705009276438 0.8697318007662835 0.8423005565862709 0.8557964184731385
the 258 times train_loss is 0.2575
the 258 times test_loss is 0.3321
0.9379769448680131 0.9385595599966516 0.8608534322820037 0.8776699029126214 0.8385899814471243 0.857685009487666
the 259 times train_loss is 0.2560
the 259 times test_loss is 0.3371
0.9385242374905771 0.9394706945459647 0.8543599257884972 0.8850806451612904 0.8144712430426716 0.8483091787439613
the 260 times train_loss is 0.2564
the 260 times test_loss is 0.3310
0.9385896372379278 0.9403878633958016 0.8589981447124304 0.8771929824561403 0.8348794063079777 0.8555133079847909
the 261 times train_loss is 0.2567
the 261 times test_loss is 0.3348
0.9371783795319443 0.9385885560154716 0.8571428571428571 0.8781925343811395 0.8293135435992579 0.8530534351145038
the 262 times train_loss is 0.2551
the 262 times test_loss is 0.3464
0.9356087855955336 0.9361772881820909 0.849721706864564 0.8870636550308009 0.8014842300556586 0.8421052631578947
the 263 times train_loss is 0.2577
the 263 times test_loss is 0.3312
0.9384416272833978 0.9402211426850378 0.8580705009276438 0.8711538461538462 0.8404452690166976 0.8555240793201133
the 264 times train_loss is 0.2568
the 264 times test_loss is 0.3349
0.9390577617452783 0.940702060096752 0.8515769944341373 0.873767258382643 0.8218923933209648 0.8470363288718928
the 265 times train_loss is 0.2547
the 265 times test_loss is 0.3444
0.936651739461175 0.9372407227491222 0.8571428571428571 0.8936605316973415 0.8107606679035251 0.850194552529183
the 266 times train_loss is 0.2565
the 266 times test_loss is 0.3336
0.9360941205627131 0.9371650274828193 0.8571428571428571 0.8652751423149905 0.8460111317254174 0.8555347091932457
the 267 times train_loss is 0.2584
the 267 times test_loss is 0.3362
0.9386688053531413 0.9395506708321836 0.8543599257884972 0.882 0.8181818181818182 0.848893166506256
the 268 times train_loss is 0.2543
the 268 times test_loss is 0.3422
0.938510469122714 0.9391989527609964 0.8506493506493507 0.895397489539749 0.7940630797773655 0.8416912487708949
the 269 times train_loss is 0.2570
the 269 times test_loss is 0.3292
0.93806988135109 0.9391839478018812 0.8608534322820037 0.8690702087286527 0.849721706864564 0.8592870544090055
the 270 times train_loss is 0.2571
the 270 times test_loss is 0.3343
0.9374847257169017 0.9383374327467999 0.8571428571428571 0.8737864077669902 0.8348794063079777 0.8538899430740037
the 271 times train_loss is 0.2537
the 271 times test_loss is 0.3464
0.9371955899917734 0.9376632527907619 0.8562152133580705 0.8983402489626556 0.8033395176252319 0.8481880509304603
the 272 times train_loss is 0.2572
the 272 times test_loss is 0.3293
0.9385380058584405 0.9398594422533495 0.8589981447124304 0.8714011516314779 0.8423005565862709 0.8566037735849057
the 273 times train_loss is 0.2565
the 273 times test_loss is 0.3318
0.9382970594208336 0.939428470371412 0.8571428571428571 0.8767123287671232 0.8311688311688312 0.8533333333333334
the 274 times train_loss is 0.2545
the 274 times test_loss is 0.3499
0.9359564368840807 0.9366326532232064 0.852504638218924 0.8941908713692946 0.7996289424860853 0.8442703232125367
the 275 times train_loss is 0.2576
the 275 times test_loss is 0.3350
0.9371508427962177 0.9387806886837942 0.8543599257884972 0.8673076923076923 0.8367346938775511 0.8517469310670445
the 276 times train_loss is 0.2546
the 276 times test_loss is 0.3352
0.9383659012601498 0.9399109625792488 0.8571428571428571 0.8752436647173489 0.8330241187384044 0.8536121673003801
the 277 times train_loss is 0.2535
the 277 times test_loss is 0.3478
0.9371749374399786 0.9378684909317216 0.8571428571428571 0.8936605316973415 0.8107606679035251 0.850194552529183
the 278 times train_loss is 0.2559
the 278 times test_loss is 0.3378
0.9366930445647648 0.9377623360918164 0.8552875695732839 0.8732943469785575 0.8311688311688312 0.8517110266159695
the 279 times train_loss is 0.2535
the 279 times test_loss is 0.3368
0.9366758341049356 0.9381596165150787 0.8543599257884972 0.8715953307392996 0.8311688311688312 0.8509021842355177
the 280 times train_loss is 0.2537
the 280 times test_loss is 0.3443
0.936775654771944 0.9380707424541871 0.852504638218924 0.8877551020408163 0.8070500927643784 0.8454810495626821
the 281 times train_loss is 0.2538
the 281 times test_loss is 0.3367
0.937295410658782 0.9386894071769104 0.8562152133580705 0.8735408560311284 0.8330241187384044 0.8528015194681862
the 282 times train_loss is 0.2522
the 282 times test_loss is 0.3378
0.9372231267275 0.9386304428934319 0.8515769944341373 0.8679611650485437 0.8293135435992579 0.8481973434535105
the 283 times train_loss is 0.2527
the 283 times test_loss is 0.3487
0.9368651491630554 0.9380016432141379 0.8487940630797773 0.8852459016393442 0.8014842300556586 0.8412852969814996
the 284 times train_loss is 0.2530
the 284 times test_loss is 0.3401
0.9366379710933117 0.9378430222120406 0.8515769944341373 0.8708414872798435 0.8256029684601113 0.8476190476190475
the 285 times train_loss is 0.2516
the 285 times test_loss is 0.3398
0.9363281828163885 0.937889020079899 0.8515769944341373 0.8693957115009746 0.8274582560296846 0.8479087452471483
the 286 times train_loss is 0.2516
the 286 times test_loss is 0.3512
0.935729258814337 0.9373540436936214 0.8469387755102041 0.8847736625514403 0.7977736549165121 0.8390243902439025
the 287 times train_loss is 0.2528
the 287 times test_loss is 0.3407
0.9356225539633968 0.9370033199182979 0.852504638218924 0.8639846743295019 0.8367346938775511 0.8501413760603205
the 288 times train_loss is 0.2528
the 288 times test_loss is 0.3463
0.9366414131852775 0.9376192232866232 0.8534322820037106 0.8832997987927566 0.8144712430426716 0.8474903474903476
the 289 times train_loss is 0.2516
the 289 times test_loss is 0.3429
0.9372747581069871 0.9386950282415704 0.8515769944341373 0.873767258382643 0.8218923933209648 0.8470363288718928
the 290 times train_loss is 0.2507
the 290 times test_loss is 0.3416
0.935250808031089 0.9368118954565865 0.8552875695732839 0.8689788053949904 0.8367346938775511 0.8525519848771268
the 291 times train_loss is 0.2511
the 291 times test_loss is 0.3518
0.9344488006030545 0.9357249401724975 0.8552875695732839 0.8884381338742393 0.8126159554730983 0.8488372093023255
the 292 times train_loss is 0.2523
the 292 times test_loss is 0.3405
0.9363212986324569 0.938169547299037 0.8506493506493507 0.8648648648648649 0.8311688311688312 0.847682119205298
the 293 times train_loss is 0.2541
the 293 times test_loss is 0.3508
0.9364624244030552 0.9375978159450383 0.849721706864564 0.8839103869653768 0.8051948051948052 0.8427184466019418
the 294 times train_loss is 0.2515
the 294 times test_loss is 0.3463
0.9349685564898923 0.9361275308563516 0.8543599257884972 0.873046875 0.8293135435992579 0.8506184586108467
the 295 times train_loss is 0.2502
the 295 times test_loss is 0.3441
0.9350373983292085 0.9371460665210987 0.8515769944341373 0.8651252408477842 0.8330241187384044 0.8487712665406426
the 296 times train_loss is 0.2522
the 296 times test_loss is 0.3536
0.9358187532054482 0.9374244806112705 0.8487940630797773 0.8868312757201646 0.7996289424860853 0.8409756097560975
the 297 times train_loss is 0.2528
the 297 times test_loss is 0.3382
0.9360872363787816 0.9369133764416004 0.8580705009276438 0.865530303030303 0.8478664192949907 0.8566073102155576
the 298 times train_loss is 0.2537
the 298 times test_loss is 0.3465
0.9364245613914312 0.9376613447990033 0.849721706864564 0.8792756539235412 0.8107606679035251 0.8436293436293435
the 299 times train_loss is 0.2505
the 299 times test_loss is 0.3502
0.9355709225839095 0.9372877086811038 0.8552875695732839 0.8884381338742393 0.8126159554730983 0.8488372093023255
the 300 times train_loss is 0.2510
the 300 times test_loss is 0.3397
0.935839405757243 0.9374937644584159 0.8552875695732839 0.8552875695732839 0.8552875695732839 0.8552875695732839
the 301 times train_loss is 0.2556
the 301 times test_loss is 0.3596
0.9372850843828846 0.9386177714537425 0.8432282003710575 0.8936170212765957 0.7792207792207793 0.8325074331020813
the 302 times train_loss is 0.2558
the 302 times test_loss is 0.3395
0.9366999287486963 0.9375319728043341 0.8543599257884972 0.8715953307392996 0.8311688311688312 0.8509021842355177
the 303 times train_loss is 0.2510
the 303 times test_loss is 0.3390
0.9354917544686959 0.9369514412352935 0.8552875695732839 0.8647619047619047 0.8423005565862709 0.8533834586466165
the 304 times train_loss is 0.2504
the 304 times test_loss is 0.3590
0.9352611343069863 0.9370528214521303 0.8487940630797773 0.8949579831932774 0.7903525046382189 0.8394088669950738
the 305 times train_loss is 0.2566
the 305 times test_loss is 0.3312
0.9377979560857908 0.9393045738699508 0.8608534322820037 0.8635514018691589 0.8571428571428571 0.8603351955307262
the 306 times train_loss is 0.2572
the 306 times test_loss is 0.3402
0.9368444966112605 0.9371428931486044 0.8580705009276438 0.8829365079365079 0.8256029684601113 0.8533077660594439
the 307 times train_loss is 0.2524
the 307 times test_loss is 0.3510
0.9365519187941663 0.937519012765248 0.8487940630797773 0.8900414937759336 0.7959183673469388 0.840352595494613
the 308 times train_loss is 0.2531
the 308 times test_loss is 0.3359
0.9372059162676708 0.9391229451863928 0.8571428571428571 0.8625235404896422 0.849721706864564 0.8560747663551402
the 309 times train_loss is 0.2547
the 309 times test_loss is 0.3373
0.9381697020180986 0.9393793574277799 0.8543599257884972 0.873046875 0.8293135435992579 0.8506184586108467
the 310 times train_loss is 0.2493
the 310 times test_loss is 0.3527
0.9366104343575852 0.9371277928321897 0.849721706864564 0.8886597938144329 0.7996289424860853 0.8417968749999999
the 311 times train_loss is 0.2526
the 311 times test_loss is 0.3378
0.9361870570457901 0.9370017517407978 0.8534322820037106 0.8684719535783365 0.8330241187384044 0.8503787878787877
the 312 times train_loss is 0.2502
the 312 times test_loss is 0.3383
0.9362352463333116 0.9376811972610327 0.8562152133580705 0.8692307692307693 0.8385899814471243 0.8536355051935789
the 313 times train_loss is 0.2492
the 313 times test_loss is 0.3532
0.9365794555298929 0.9379229562324842 0.8515769944341373 0.8907216494845361 0.8014842300556586 0.84375
the 314 times train_loss is 0.2532
the 314 times test_loss is 0.3351
0.9374193259695512 0.9385411557108309 0.8534322820037106 0.8670520231213873 0.8348794063079777 0.8506616257088847
the 315 times train_loss is 0.2501
the 315 times test_loss is 0.3393
0.9362386884252772 0.93674566491899 0.8543599257884972 0.8745098039215686 0.8274582560296846 0.8503336510962821
the 316 times train_loss is 0.2498
the 316 times test_loss is 0.3502
0.9365897818057903 0.9376979985981402 0.8506493506493507 0.8888888888888888 0.8014842300556586 0.8429268292682927
the 317 times train_loss is 0.2501
the 317 times test_loss is 0.3428
0.9357705639179268 0.9371202936777036 0.8562152133580705 0.8692307692307693 0.8385899814471243 0.8536355051935789
the 318 times train_loss is 0.2492
the 318 times test_loss is 0.3424
0.9368272861514313 0.9382539867593193 0.8562152133580705 0.8706563706563707 0.8367346938775511 0.8533585619678336
the 319 times train_loss is 0.2483
the 319 times test_loss is 0.3537
0.9359426685162174 0.9366604137260268 0.8506493506493507 0.8857142857142857 0.8051948051948052 0.8435374149659864
the 320 times train_loss is 0.2495
the 320 times test_loss is 0.3440
0.9357086062625422 0.9366438181600054 0.8506493506493507 0.869140625 0.8256029684601113 0.8468125594671742
the 321 times train_loss is 0.2484
the 321 times test_loss is 0.3458
0.9347689151558751 0.9357444511959776 0.8543599257884972 0.8715953307392996 0.8311688311688312 0.8509021842355177
the 322 times train_loss is 0.2475
the 322 times test_loss is 0.3522
0.9368169598755338 0.9386977933791316 0.852504638218924 0.8861788617886179 0.8089053803339518 0.845780795344326
the 323 times train_loss is 0.2497
the 323 times test_loss is 0.3437
0.9351854082837384 0.93629340557642 0.8562152133580705 0.867816091954023 0.8404452690166976 0.8539114043355325
the 324 times train_loss is 0.2483
the 324 times test_loss is 0.3490
0.9357154904464737 0.9368276675998716 0.8487940630797773 0.876 0.8126159554730983 0.8431183830606351
the 325 times train_loss is 0.2473
the 325 times test_loss is 0.3573
0.9340632863028834 0.9347982785930987 0.849721706864564 0.8808080808080808 0.8089053803339518 0.8433268858800774
the 326 times train_loss is 0.2477
the 326 times test_loss is 0.3449
0.9362696672529696 0.9382690634368901 0.8552875695732839 0.8647619047619047 0.8423005565862709 0.8533834586466165
the 327 times train_loss is 0.2520
the 327 times test_loss is 0.3705
0.9311306239480105 0.9309646817997155 0.8534322820037106 0.8895705521472392 0.8070500927643784 0.8463035019455253
the 328 times train_loss is 0.2609
the 328 times test_loss is 0.3460
0.9352473659391232 0.9377856761343255 0.8617810760667903 0.877906976744186 0.8404452690166976 0.8587677725118483
the 329 times train_loss is 0.2748
the 329 times test_loss is 0.3394
0.9338016873134818 0.9359692013623333 0.859925788497217 0.875968992248062 0.8385899814471243 0.8568720379146919
the 330 times train_loss is 0.2728
the 330 times test_loss is 0.3341
0.9358600583090378 0.9364640983839524 0.8589981447124304 0.8877755511022044 0.8218923933209648 0.8535645472061658
the 331 times train_loss is 0.2708
the 331 times test_loss is 0.3226
0.9381937966618592 0.9387225580680963 0.8580705009276438 0.876953125 0.8330241187384044 0.8544243577545194
the 332 times train_loss is 0.2647
the 332 times test_loss is 0.3326
0.938438185191432 0.9399735392845536 0.8617810760667903 0.8979591836734694 0.8163265306122449 0.8551992225461612
the 333 times train_loss is 0.2595
the 333 times test_loss is 0.3372
0.9390887405729705 0.939825321996446 0.8589981447124304 0.8893360160965795 0.8200371057513914 0.8532818532818532
the 334 times train_loss is 0.2678
the 334 times test_loss is 0.3360
0.9361182152064739 0.938354013538413 0.852504638218924 0.8815261044176707 0.8144712430426716 0.8466730954676952
the 335 times train_loss is 0.2583
the 335 times test_loss is 0.3281
0.9368066335996366 0.9386481973482721 0.8543599257884972 0.8701550387596899 0.8330241187384044 0.8511848341232228
the 336 times train_loss is 0.2583
the 336 times test_loss is 0.3389
0.9360906784707472 0.9376827125885319 0.8589981447124304 0.8862275449101796 0.8237476808905381 0.8538461538461538
the 337 times train_loss is 0.2604
the 337 times test_loss is 0.3440
0.935398817985619 0.9368362840446409 0.8580705009276438 0.874031007751938 0.8367346938775511 0.8549763033175356
the 338 times train_loss is 0.2606
the 338 times test_loss is 0.3427
0.936724023392457 0.9375381295227457 0.8589981447124304 0.8714011516314779 0.8423005565862709 0.8566037735849057
the 339 times train_loss is 0.2601
the 339 times test_loss is 0.3431
0.9379459660403208 0.9382576495226156 0.8534322820037106 0.8772277227722772 0.8218923933209648 0.8486590038314178
the 340 times train_loss is 0.2566
the 340 times test_loss is 0.3423
0.9357430271822003 0.9359918579764475 0.849721706864564 0.8732673267326733 0.8181818181818182 0.8448275862068967
the 341 times train_loss is 0.2546
the 341 times test_loss is 0.3326
0.9380285762475001 0.9389072956631518 0.8506493506493507 0.8735177865612648 0.8200371057513914 0.845933014354067
the 342 times train_loss is 0.2546
the 342 times test_loss is 0.3247
0.9401007156109197 0.9413665401302929 0.8562152133580705 0.8779527559055118 0.8274582560296846 0.8519579751671442
the 343 times train_loss is 0.2554
the 343 times test_loss is 0.3280
0.9386619211692098 0.9389203168225508 0.8552875695732839 0.8762278978388998 0.8274582560296846 0.8511450381679388
the 344 times train_loss is 0.2527
the 344 times test_loss is 0.3391
0.9371887058078419 0.9372210610140296 0.8571428571428571 0.8873239436619719 0.8181818181818182 0.8513513513513514
the 345 times train_loss is 0.2528
the 345 times test_loss is 0.3349
0.9388030469398081 0.9391779311470999 0.8571428571428571 0.882703777335984 0.8237476808905381 0.8522072936660269
the 346 times train_loss is 0.2517
the 346 times test_loss is 0.3350
0.9380939759948506 0.9387140908308415 0.8552875695732839 0.8777120315581854 0.8256029684601113 0.8508604206500956
the 347 times train_loss is 0.2518
the 347 times test_loss is 0.3485
0.9349203672023709 0.9355086213327783 0.852504638218924 0.8815261044176707 0.8144712430426716 0.8466730954676952
the 348 times train_loss is 0.2502
the 348 times test_loss is 0.3551
0.933151131931943 0.9337827591715899 0.8487940630797773 0.8790322580645161 0.8089053803339518 0.842512077294686
the 349 times train_loss is 0.2503
the 349 times test_loss is 0.3447
0.9366207606334825 0.937869276653304 0.8506493506493507 0.8705882352941177 0.8237476808905381 0.8465204957102002
the 350 times train_loss is 0.2509
the 350 times test_loss is 0.3474
0.9362214779654483 0.9371013035519021 0.8506493506493507 0.8764940239043825 0.8163265306122449 0.8453410182516811
the 351 times train_loss is 0.2497
the 351 times test_loss is 0.3483
0.9351681978239095 0.9355936128501826 0.8515769944341373 0.8767395626242545 0.8181818181818182 0.8464491362763915
the 352 times train_loss is 0.2489
the 352 times test_loss is 0.3390
0.9368548228871579 0.9374604857362379 0.8506493506493507 0.8720472440944882 0.8218923933209648 0.8462273161413563
the 353 times train_loss is 0.2489
the 353 times test_loss is 0.3434
0.9356535327910891 0.9360849834759544 0.8515769944341373 0.8752475247524752 0.8200371057513914 0.846743295019157
the 354 times train_loss is 0.2482
the 354 times test_loss is 0.3468
0.9353919338016873 0.9359450321075529 0.849721706864564 0.8777555110220441 0.8126159554730983 0.8439306358381503
the 355 times train_loss is 0.2479
the 355 times test_loss is 0.3424
0.936724023392457 0.9378401258728174 0.849721706864564 0.8717948717948718 0.8200371057513914 0.8451242829827916
the 356 times train_loss is 0.2479
the 356 times test_loss is 0.3483
0.9348687358228837 0.9358441339797962 0.8506493506493507 0.875 0.8181818181818182 0.8456375838926175
the 357 times train_loss is 0.2471
the 357 times test_loss is 0.3505
0.9347035154085248 0.9359792371613811 0.8469387755102041 0.871031746031746 0.8144712430426716 0.8418024928092043
the 358 times train_loss is 0.2467
the 358 times test_loss is 0.3511
0.9348411990871571 0.9361943335565512 0.852504638218924 0.8754940711462451 0.8218923933209648 0.8478468899521531
the 359 times train_loss is 0.2467
the 359 times test_loss is 0.3598
0.9335228778642508 0.9344598024664911 0.8460111317254174 0.8782961460446247 0.8033395176252319 0.8391472868217055
the 360 times train_loss is 0.2470
the 360 times test_loss is 0.3501
0.9359220159644225 0.9374900141123161 0.8515769944341373 0.8693957115009746 0.8274582560296846 0.8479087452471483
the 361 times train_loss is 0.2479
the 361 times test_loss is 0.3648
0.9319842627555324 0.932839830920016 0.8441558441558441 0.8809034907597536 0.7959183673469388 0.8362573099415205
the 362 times train_loss is 0.2493
the 362 times test_loss is 0.3417
0.937071674681004 0.9391721801912104 0.8552875695732839 0.8661567877629063 0.8404452690166976 0.8531073446327683
the 363 times train_loss is 0.2516
the 363 times test_loss is 0.3583
0.9324816450445922 0.9332857889528433 0.849721706864564 0.8839103869653768 0.8051948051948052 0.8427184466019418
the 364 times train_loss is 0.2483
the 364 times test_loss is 0.3475
0.9350167457774137 0.9356988180936248 0.849721706864564 0.8732673267326733 0.8181818181818182 0.8448275862068967
the 365 times train_loss is 0.2455
the 365 times test_loss is 0.3463
0.9371783795319444 0.9385628283494594 0.8515769944341373 0.873767258382643 0.8218923933209648 0.8470363288718928
the 366 times train_loss is 0.2472
the 366 times test_loss is 0.3573
0.9336226985312595 0.934224524774582 0.8515769944341373 0.8767395626242545 0.8181818181818182 0.8464491362763915
the 367 times train_loss is 0.2466
the 367 times test_loss is 0.3574
0.9352576922150206 0.9367355920996606 0.8487940630797773 0.8852459016393442 0.8014842300556586 0.8412852969814996
the 368 times train_loss is 0.2464
the 368 times test_loss is 0.3535
0.9325005765504043 0.9337804268656381 0.8450834879406308 0.849624060150376 0.8385899814471243 0.8440709617180205
the 369 times train_loss is 0.2491
the 369 times test_loss is 0.3741
0.9361457519422004 0.937579588546182 0.8460111317254174 0.8959660297239915 0.7829313543599258 0.8356435643564357
the 370 times train_loss is 0.2535
the 370 times test_loss is 0.3568
0.9319050946403187 0.9316328546365296 0.8487940630797773 0.843065693430657 0.8571428571428571 0.8500459981600736
the 371 times train_loss is 0.2587
the 371 times test_loss is 0.3654
0.9366138764495509 0.9393972137156882 0.8469387755102041 0.8995726495726496 0.7810760667903525 0.836146971201589
the 372 times train_loss is 0.2644
the 372 times test_loss is 0.3467
0.9334505939329688 0.9361142381906699 0.8487940630797773 0.8715415019762845 0.8181818181818182 0.8440191387559808
the 373 times train_loss is 0.2511
the 373 times test_loss is 0.3695
0.9248350377425385 0.9247596755865195 0.8487940630797773 0.8547169811320755 0.8404452690166976 0.8475210477081385
the 374 times train_loss is 0.2628
the 374 times test_loss is 0.3456
0.9396257069196374 0.9416813354877751 0.8552875695732839 0.8853118712273642 0.8163265306122449 0.8494208494208494
the 375 times train_loss is 0.2605
the 375 times test_loss is 0.3531
0.939026782917586 0.9417732938161044 0.8487940630797773 0.8805668016194332 0.8070500927643784 0.8422071636011617
the 376 times train_loss is 0.2654
the 376 times test_loss is 0.3479
0.9349754406738239 0.9368738500891141 0.8515769944341373 0.8797595190380761 0.8144712430426716 0.8458574181117534
the 377 times train_loss is 0.2496
the 377 times test_loss is 0.3635
0.9272066391069836 0.9266002248123355 0.8515769944341373 0.8651252408477842 0.8330241187384044 0.8487712665406426
the 378 times train_loss is 0.2650
the 378 times test_loss is 0.3389
0.9340736125787809 0.9360490410676072 0.8543599257884972 0.8537037037037037 0.8552875695732839 0.8544949026876738
the 379 times train_loss is 0.2535
the 379 times test_loss is 0.3442
0.9407340605326293 0.9426586288100925 0.8562152133580705 0.9016736401673641 0.7996289424860853 0.847590953785644
the 380 times train_loss is 0.2567
the 380 times test_loss is 0.3321
0.9418286457777578 0.9433707730854893 0.8589981447124304 0.8924949290060852 0.8163265306122449 0.8527131782945737
the 381 times train_loss is 0.2554
the 381 times test_loss is 0.3286
0.9390749722051074 0.9401202326982316 0.8580705009276438 0.8784313725490196 0.8311688311688312 0.8541468064823643
the 382 times train_loss is 0.2497
the 382 times test_loss is 0.3497
0.9325384395620282 0.9333749420383459 0.8580705009276438 0.8844621513944223 0.8237476808905381 0.8530259365994236
the 383 times train_loss is 0.2545
the 383 times test_loss is 0.3411
0.9344728952468152 0.9358244876530822 0.8571428571428571 0.8709055876685935 0.8385899814471243 0.8544423440453688
the 384 times train_loss is 0.2510
the 384 times test_loss is 0.3335
0.9390990668488681 0.9405937001906013 0.8562152133580705 0.875 0.8311688311688312 0.8525214081826832
the 385 times train_loss is 0.2490
the 385 times test_loss is 0.3431
0.941126459016732 0.9423521203387126 0.8515769944341373 0.8972746331236897 0.7940630797773655 0.8425196850393701
the 386 times train_loss is 0.2533
the 386 times test_loss is 0.3362
0.939636033195535 0.9402667529838789 0.8552875695732839 0.8792079207920792 0.8237476808905381 0.8505747126436781
the 387 times train_loss is 0.2474
the 387 times test_loss is 0.3407
0.9356156697794652 0.9357162119860011 0.8552875695732839 0.8689788053949904 0.8367346938775511 0.8525519848771268
the 388 times train_loss is 0.2491
the 388 times test_loss is 0.3501
0.9343248852922853 0.9343074487340418 0.8580705009276438 0.8891129032258065 0.8181818181818182 0.8521739130434782
the 389 times train_loss is 0.2514
the 389 times test_loss is 0.3304
0.9383211540645944 0.9387248888471428 0.859925788497217 0.8716475095785441 0.8441558441558441 0.8576814326107446
the 390 times train_loss is 0.2481
the 390 times test_loss is 0.3370
0.9397530643223726 0.9403653838457268 0.852504638218924 0.8846153846153846 0.8107606679035251 0.846079380445305
the 391 times train_loss is 0.2484
the 391 times test_loss is 0.3422
0.9393090344587826 0.940172193570242 0.8506493506493507 0.8795180722891566 0.8126159554730983 0.8447444551591127
the 392 times train_loss is 0.2476
the 392 times test_loss is 0.3412
0.9367653284960468 0.9375196681649332 0.8543599257884972 0.8645038167938931 0.8404452690166976 0.8523047977422389
the 393 times train_loss is 0.2483
the 393 times test_loss is 0.3561
0.9340219811992937 0.9337984437330262 0.8506493506493507 0.8810483870967742 0.8107606679035251 0.8444444444444444
the 394 times train_loss is 0.2493
the 394 times test_loss is 0.3434
0.9343042327404903 0.9350659775683289 0.852504638218924 0.8653846153846154 0.8348794063079777 0.8498583569405098
the 395 times train_loss is 0.2480
the 395 times test_loss is 0.3476
0.9369064542666452 0.9381520305290838 0.8515769944341373 0.8843813387423936 0.8089053803339518 0.8449612403100776
the 396 times train_loss is 0.2461
the 396 times test_loss is 0.3470
0.9384313010075003 0.9397284217151973 0.8515769944341373 0.8859470468431772 0.8070500927643784 0.8446601941747572
the 397 times train_loss is 0.2460
the 397 times test_loss is 0.3415
0.9368548228871578 0.9380816777314949 0.8552875695732839 0.8620037807183365 0.8460111317254174 0.853932584269663
the 398 times train_loss is 0.2474
the 398 times test_loss is 0.3553
0.9342285067172424 0.9348769105591257 0.8506493506493507 0.8810483870967742 0.8107606679035251 0.8444444444444444
the 399 times train_loss is 0.2469
the 399 times test_loss is 0.3524
0.9325487658379257 0.9336182847068681 0.8450834879406308 0.8604651162790697 0.8237476808905381 0.8417061611374408
the 400 times train_loss is 0.2455
the 400 times test_loss is 0.3539
0.9345176424423708 0.9354382148203357 0.8478664192949907 0.874251497005988 0.8126159554730983 0.8423076923076923
the 401 times train_loss is 0.2444
the 401 times test_loss is 0.3564
0.9365519187941664 0.9373416672788996 0.852504638218924 0.8830645161290323 0.8126159554730983 0.8463768115942029
the 402 times train_loss is 0.2447
the 402 times test_loss is 0.3498
0.9360528154591233 0.9370130723005223 0.849721706864564 0.8618042226487524 0.8330241187384044 0.8471698113207546
the 403 times train_loss is 0.2455
the 403 times test_loss is 0.3598
0.93409082303861 0.9350484511754962 0.849721706864564 0.8777555110220441 0.8126159554730983 0.8439306358381503
the 404 times train_loss is 0.2439
the 404 times test_loss is 0.3563
0.9324076400673273 0.9335036444826088 0.8478664192949907 0.8669275929549902 0.8218923933209648 0.8438095238095238
the 405 times train_loss is 0.2440
the 405 times test_loss is 0.3602
0.9334471518410029 0.9340584834218454 0.8506493506493507 0.8795180722891566 0.8126159554730983 0.8447444551591127
the 406 times train_loss is 0.2433
the 406 times test_loss is 0.3548
0.9356948378946788 0.9362697331694921 0.8534322820037106 0.8699029126213592 0.8311688311688312 0.8500948766603416
the 407 times train_loss is 0.2431
the 407 times test_loss is 0.3569
0.935564038399978 0.9361932523371866 0.849721706864564 0.8732673267326733 0.8181818181818182 0.8448275862068967
the 408 times train_loss is 0.2428
the 408 times test_loss is 0.3525
0.9344797794307469 0.9354801595545938 0.8506493506493507 0.8720472440944882 0.8218923933209648 0.8462273161413563
the 409 times train_loss is 0.2427
the 409 times test_loss is 0.3591
0.9331821107596352 0.9341599829069281 0.8469387755102041 0.8770161290322581 0.8070500927643784 0.8405797101449274
the 410 times train_loss is 0.2429
the 410 times test_loss is 0.3572
0.933849876601003 0.9346647048031613 0.8515769944341373 0.8665377176015474 0.8311688311688312 0.8484848484848485
the 411 times train_loss is 0.2425
the 411 times test_loss is 0.3661
0.9344866636146785 0.9345779341246414 0.852504638218924 0.8815261044176707 0.8144712430426716 0.8466730954676952
the 412 times train_loss is 0.2451
the 412 times test_loss is 0.3509
0.9352026187435677 0.9361573706292203 0.8506493506493507 0.8539325842696629 0.8460111317254174 0.8499534016775396
the 413 times train_loss is 0.2512
the 413 times test_loss is 0.3895
0.9332475105069856 0.9335876778990138 0.8404452690166976 0.9068736141906873 0.7588126159554731 0.8262626262626264
the 414 times train_loss is 0.2605
the 414 times test_loss is 0.3431
0.935360954973995 0.9363491783944697 0.8534322820037106 0.8432432432432433 0.8682745825602969 0.8555758683729433
the 415 times train_loss is 0.2613
the 415 times test_loss is 0.3486
0.9352095029274992 0.9365724761335993 0.8460111317254174 0.872255489021956 0.8107606679035251 0.8403846153846154
the 416 times train_loss is 0.2458
the 416 times test_loss is 0.3693
0.9350890297086958 0.9358790999368729 0.8552875695732839 0.9031578947368422 0.7959183673469388 0.8461538461538461
the 417 times train_loss is 0.2561
the 417 times test_loss is 0.3410
0.9348033360755333 0.9348514034592063 0.859925788497217 0.8619402985074627 0.8571428571428571 0.8595348837209302
the 418 times train_loss is 0.2559
the 418 times test_loss is 0.3342
0.9370200433015169 0.9386019737796683 0.8580705009276438 0.8725868725868726 0.8385899814471243 0.8552507095553453
the 419 times train_loss is 0.2527
the 419 times test_loss is 0.3555
0.934806778167499 0.9364893673165424 0.8469387755102041 0.8847736625514403 0.7977736549165121 0.8390243902439025
the 420 times train_loss is 0.2514
the 420 times test_loss is 0.3579
0.9339290447162167 0.9341273676475681 0.8460111317254174 0.8767676767676768 0.8051948051948052 0.8394584139264991
the 421 times train_loss is 0.2509
the 421 times test_loss is 0.3478
0.9347000733165589 0.9341956943889388 0.8515769944341373 0.8542056074766355 0.8478664192949907 0.851024208566108
the 422 times train_loss is 0.2512
the 422 times test_loss is 0.3442
0.9379631765001497 0.9382864850305077 0.8543599257884972 0.8804780876494024 0.8200371057513914 0.8491834774255523
the 423 times train_loss is 0.2493
the 423 times test_loss is 0.3472
0.9384485114673294 0.9388472393115755 0.8534322820037106 0.8927835051546392 0.8033395176252319 0.845703125
the 424 times train_loss is 0.2495
the 424 times test_loss is 0.3365
0.9368169598755339 0.9368973040876548 0.8515769944341373 0.8693957115009746 0.8274582560296846 0.8479087452471483
the 425 times train_loss is 0.2461
the 425 times test_loss is 0.3335
0.9360149524474995 0.9361551470113386 0.852504638218924 0.8625954198473282 0.8385899814471243 0.8504233301975541
the 426 times train_loss is 0.2498
the 426 times test_loss is 0.3338
0.9390198987336543 0.9394895218131416 0.8562152133580705 0.8809523809523809 0.8237476808905381 0.8513902205177372
the 427 times train_loss is 0.2447
the 427 times test_loss is 0.3393
0.9395224441606632 0.9402081459969878 0.852504638218924 0.8861788617886179 0.8089053803339518 0.845780795344326
the 428 times train_loss is 0.2482
the 428 times test_loss is 0.3377
0.9380285762475002 0.9379345662881694 0.852504638218924 0.8754940711462451 0.8218923933209648 0.8478468899521531
the 429 times train_loss is 0.2437
the 429 times test_loss is 0.3427
0.9350924718006616 0.9344868525059681 0.8515769944341373 0.8679611650485437 0.8293135435992579 0.8481973434535105
the 430 times train_loss is 0.2458
the 430 times test_loss is 0.3478
0.9349892090416871 0.9351011510045104 0.8506493506493507 0.8735177865612648 0.8200371057513914 0.845933014354067
the 431 times train_loss is 0.2443
the 431 times test_loss is 0.3507
0.9358359636652771 0.9364761705498255 0.849721706864564 0.8808080808080808 0.8089053803339518 0.8433268858800774
the 432 times train_loss is 0.2439
the 432 times test_loss is 0.3487
0.9362593409770721 0.9367649211542978 0.8487940630797773 0.8790322580645161 0.8089053803339518 0.842512077294686
the 433 times train_loss is 0.2435
the 433 times test_loss is 0.3465
0.9359461106081832 0.9357675448043195 0.8543599257884972 0.8673076923076923 0.8367346938775511 0.8517469310670445
the 434 times train_loss is 0.2431
the 434 times test_loss is 0.3511
0.936410793023568 0.9360509578945418 0.8534322820037106 0.8699029126213592 0.8311688311688312 0.8500948766603416
the 435 times train_loss is 0.2431
the 435 times test_loss is 0.3526
0.9360287208153628 0.9360795272605815 0.849721706864564 0.8732673267326733 0.8181818181818182 0.8448275862068967
the 436 times train_loss is 0.2424
the 436 times test_loss is 0.3531
0.9348584095469863 0.9349903565565646 0.8515769944341373 0.8812877263581489 0.8126159554730983 0.8455598455598455
the 437 times train_loss is 0.2425
the 437 times test_loss is 0.3532
0.9342422750851056 0.9346640517056295 0.8487940630797773 0.8686274509803922 0.8218923933209648 0.8446139180171592
the 438 times train_loss is 0.2424
the 438 times test_loss is 0.3644
0.9340082128314304 0.9343398862021866 0.8460111317254174 0.8767676767676768 0.8051948051948052 0.8394584139264991
the 439 times train_loss is 0.2419
the 439 times test_loss is 0.3620
0.933832666141174 0.9342895280257678 0.8478664192949907 0.8640776699029126 0.8256029684601113 0.8444022770398482
the 440 times train_loss is 0.2424
the 440 times test_loss is 0.3728
0.9320944096984384 0.9320350890815722 0.8487940630797773 0.8868312757201646 0.7996289424860853 0.8409756097560975
the 441 times train_loss is 0.2454
the 441 times test_loss is 0.3540
0.9340770546707468 0.9356670180612134 0.8515769944341373 0.8568738229755178 0.8441558441558441 0.8504672897196262
the 442 times train_loss is 0.2528
the 442 times test_loss is 0.3764
0.9335194357722849 0.9340985658973177 0.8487940630797773 0.9017094017094017 0.7829313543599258 0.8381330685203575
the 443 times train_loss is 0.2481
the 443 times test_loss is 0.3564
0.9330203324372419 0.9335386266587058 0.8562152133580705 0.875 0.8311688311688312 0.8525214081826832
the 444 times train_loss is 0.2439
the 444 times test_loss is 0.3533
0.9338361082331397 0.9351557370441889 0.8543599257884972 0.8645038167938931 0.8404452690166976 0.8523047977422389
the 445 times train_loss is 0.2455
the 445 times test_loss is 0.3675
0.9335091094963875 0.9348866687043321 0.8515769944341373 0.8875255623721882 0.8051948051948052 0.8443579766536965
the 446 times train_loss is 0.2448
the 446 times test_loss is 0.3612
0.9327002178844214 0.9334808070158482 0.8515769944341373 0.8782435129740519 0.8163265306122449 0.846153846153846
the 447 times train_loss is 0.2433
the 447 times test_loss is 0.3586
0.9327346388040796 0.9335182699247273 0.8487940630797773 0.8601532567049809 0.8330241187384044 0.8463713477851085
the 448 times train_loss is 0.2441
the 448 times test_loss is 0.3686
0.9337534980259603 0.9348379625462766 0.8478664192949907 0.8712871287128713 0.8163265306122449 0.842911877394636
the 449 times train_loss is 0.2431
the 449 times test_loss is 0.3702
0.9331373635640796 0.9339010280322431 0.8441558441558441 0.8702594810379242 0.8089053803339518 0.8384615384615385
the 450 times train_loss is 0.2417
the 450 times test_loss is 0.3664
0.9313474757418568 0.9313755143578093 0.8487940630797773 0.862934362934363 0.8293135435992579 0.8457899716177862
the 451 times train_loss is 0.2430
the 451 times test_loss is 0.3638
0.9334368255651054 0.9334407437243897 0.8506493506493507 0.8735177865612648 0.8200371057513914 0.845933014354067
the 452 times train_loss is 0.2408
the 452 times test_loss is 0.3613
0.935140661088183 0.9358856275593738 0.8460111317254174 0.8707753479125249 0.8126159554730983 0.8406909788867563
the 453 times train_loss is 0.2417
the 453 times test_loss is 0.3545
0.9345382949941656 0.9349507950004852 0.8469387755102041 0.8666666666666667 0.8200371057513914 0.8427073403241183
the 454 times train_loss is 0.2405
the 454 times test_loss is 0.3569
0.933870529152798 0.9339665020095121 0.852504638218924 0.8784860557768924 0.8181818181818182 0.8472622478386167
the 455 times train_loss is 0.2412
the 455 times test_loss is 0.3580
0.9347241679603195 0.9353170615868898 0.8534322820037106 0.8757396449704142 0.8237476808905381 0.8489483747609943
the 456 times train_loss is 0.2409
the 456 times test_loss is 0.3646
0.9343420957521142 0.934447914845285 0.8506493506493507 0.878 0.8144712430426716 0.8450433108758422
the 457 times train_loss is 0.2402
the 457 times test_loss is 0.3591
0.9330031219774131 0.9331892744026962 0.852504638218924 0.8639846743295019 0.8367346938775511 0.8501413760603205
the 458 times train_loss is 0.2408
the 458 times test_loss is 0.3646
0.9331132689203191 0.9334350966565856 0.8432282003710575 0.87 0.8070500927643784 0.8373435996150144
the 459 times train_loss is 0.2398
the 459 times test_loss is 0.3605
0.9338980658885244 0.934561681636326 0.8478664192949907 0.8712871287128713 0.8163265306122449 0.842911877394636
the 460 times train_loss is 0.2401
the 460 times test_loss is 0.3622
0.9331339214721138 0.9329408471361141 0.8460111317254174 0.8678500986193294 0.8163265306122449 0.8413001912045889
the 461 times train_loss is 0.2396
the 461 times test_loss is 0.3568
0.9342835801886955 0.9344312342472416 0.852504638218924 0.8625954198473282 0.8385899814471243 0.8504233301975541
the 462 times train_loss is 0.2403
the 462 times test_loss is 0.3716
0.9338223398652765 0.9337180005577104 0.8469387755102041 0.8847736625514403 0.7977736549165121 0.8390243902439025
the 463 times train_loss is 0.2424
the 463 times test_loss is 0.3560
0.9338395503251056 0.9346166721157682 0.8506493506493507 0.8513011152416357 0.849721706864564 0.850510677808728
the 464 times train_loss is 0.2483
the 464 times test_loss is 0.3769
0.9318706737206605 0.9316574575077985 0.8450834879406308 0.8891213389121339 0.7884972170686456 0.8357915437561455
the 465 times train_loss is 0.2454
the 465 times test_loss is 0.3584
0.9330719638167293 0.9334828372155805 0.8552875695732839 0.8689788053949904 0.8367346938775511 0.8525519848771268
the 466 times train_loss is 0.2403
the 466 times test_loss is 0.3603
0.9337913610375842 0.9345878597805924 0.8487940630797773 0.8615384615384616 0.8311688311688312 0.8460812086874411
the 467 times train_loss is 0.2409
the 467 times test_loss is 0.3678
0.9334781306686952 0.9339003368827288 0.8487940630797773 0.8821138211382114 0.8051948051948052 0.8419010669253153
the 468 times train_loss is 0.2411
the 468 times test_loss is 0.3584
0.932927395954165 0.9333381671096269 0.8515769944341373 0.8651252408477842 0.8330241187384044 0.8487712665406426
the 469 times train_loss is 0.2414
the 469 times test_loss is 0.3634
0.9331821107596353 0.9341459627351667 0.8450834879406308 0.8661417322834646 0.8163265306122449 0.8404966571155683
the 470 times train_loss is 0.2399
the 470 times test_loss is 0.3718
0.9327449650799771 0.9331356135642761 0.8506493506493507 0.8764940239043825 0.8163265306122449 0.8453410182516811
the 471 times train_loss is 0.2408
the 471 times test_loss is 0.3644
0.9316331693750193 0.9313383392715687 0.852504638218924 0.8612167300380228 0.8404452690166976 0.8507042253521127
the 472 times train_loss is 0.2412
the 472 times test_loss is 0.3692
0.9329790273336523 0.9330032028087369 0.8515769944341373 0.8828282828282829 0.8107606679035251 0.8452611218568664
the 473 times train_loss is 0.2395
the 473 times test_loss is 0.3682
0.9326072814013445 0.9331924038559432 0.8460111317254174 0.8635477582846004 0.8218923933209648 0.8422053231939163
the 474 times train_loss is 0.2397
the 474 times test_loss is 0.3622
0.9331167110122849 0.9335413842960453 0.852504638218924 0.8682170542635659 0.8311688311688312 0.8492890995260663
the 475 times train_loss is 0.2387
the 475 times test_loss is 0.3714
0.933832666141174 0.9340752946388519 0.8450834879406308 0.8811475409836066 0.7977736549165121 0.8373904576436223
the 476 times train_loss is 0.2401
the 476 times test_loss is 0.3680
0.932579744665618 0.9325767678000279 0.8515769944341373 0.8665377176015474 0.8311688311688312 0.8484848484848485
the 477 times train_loss is 0.2388
the 477 times test_loss is 0.3732
0.931419759673139 0.9314410442724794 0.849721706864564 0.8732673267326733 0.8181818181818182 0.8448275862068967
the 478 times train_loss is 0.2390
the 478 times test_loss is 0.3646
0.9326451444129684 0.9334236908421398 0.8506493506493507 0.8705882352941177 0.8237476808905381 0.8465204957102002
the 479 times train_loss is 0.2430
the 479 times test_loss is 0.3714
0.9311306239480106 0.9311887203118787 0.8478664192949907 0.8772635814889336 0.8089053803339518 0.8416988416988418
the 480 times train_loss is 0.2403
the 480 times test_loss is 0.3644
0.9329721431497207 0.9332630850976457 0.8487940630797773 0.8601532567049809 0.8330241187384044 0.8463713477851085
the 481 times train_loss is 0.2411
the 481 times test_loss is 0.3653
0.9343248852922853 0.934332495596274 0.8478664192949907 0.874251497005988 0.8126159554730983 0.8423076923076923
the 482 times train_loss is 0.2379
the 482 times test_loss is 0.3676
0.9323697770557033 0.9319802740045515 0.8534322820037106 0.8848484848484849 0.8126159554730983 0.8471953578336556
the 483 times train_loss is 0.2395
the 483 times test_loss is 0.3665
0.9316194010071561 0.9319299395502342 0.852504638218924 0.8598484848484849 0.8423005565862709 0.8509840674789129
the 484 times train_loss is 0.2391
the 484 times test_loss is 0.3802
0.9325935130334813 0.932812046506587 0.8478664192949907 0.8818737270875764 0.8033395176252319 0.8407766990291262
the 485 times train_loss is 0.2412
the 485 times test_loss is 0.3608
0.9329618168738233 0.9331792598837894 0.8515769944341373 0.8595825426944972 0.8404452690166976 0.849906191369606
the 486 times train_loss is 0.2463
the 486 times test_loss is 0.3736
0.9306315206129677 0.9302831573370499 0.8469387755102041 0.8879668049792531 0.7940630797773655 0.8383937316356511
the 487 times train_loss is 0.2419
the 487 times test_loss is 0.3682
0.9323869875155325 0.9330429424889101 0.8506493506493507 0.8662790697674418 0.8293135435992579 0.84739336492891
the 488 times train_loss is 0.2422
the 488 times test_loss is 0.3576
0.934882504190747 0.9352438056078751 0.8562152133580705 0.867816091954023 0.8404452690166976 0.8539114043355325
the 489 times train_loss is 0.2394
the 489 times test_loss is 0.3709
0.9334643623008319 0.9326232640700486 0.8469387755102041 0.8879668049792531 0.7940630797773655 0.8383937316356511
the 490 times train_loss is 0.2442
the 490 times test_loss is 0.3627
0.9322011145493785 0.9318938169563876 0.8506493506493507 0.8662790697674418 0.8293135435992579 0.84739336492891
the 491 times train_loss is 0.2378
the 491 times test_loss is 0.3713
0.9313922229374124 0.9317757546351833 0.8515769944341373 0.8651252408477842 0.8330241187384044 0.8487712665406426
the 492 times train_loss is 0.2414
the 492 times test_loss is 0.3708
0.9316090747312586 0.9316805918287201 0.8487940630797773 0.876 0.8126159554730983 0.8431183830606351
the 493 times train_loss is 0.2392
the 493 times test_loss is 0.3590
0.9338774133367296 0.9339235678540049 0.8543599257884972 0.8715953307392996 0.8311688311688312 0.8509021842355177
the 494 times train_loss is 0.2412
the 494 times test_loss is 0.3616
0.9342112962574135 0.9343407885678691 0.852504638218924 0.8725490196078431 0.8256029684601113 0.8484270734032412
the 495 times train_loss is 0.2374
the 495 times test_loss is 0.3696
0.9318018318813444 0.9313351474540256 0.8469387755102041 0.8695652173913043 0.8163265306122449 0.8421052631578948
the 496 times train_loss is 0.2415
the 496 times test_loss is 0.3581
0.9334264992892081 0.9331012975625987 0.8543599257884972 0.8617424242424242 0.8441558441558441 0.852858481724461
the 497 times train_loss is 0.2406
the 497 times test_loss is 0.3692
0.9332647209668148 0.9324569165376997 0.8478664192949907 0.8865979381443299 0.7977736549165121 0.83984375
the 498 times train_loss is 0.2413
the 498 times test_loss is 0.3659
0.9325522079298916 0.9324810806080579 0.8515769944341373 0.8651252408477842 0.8330241187384044 0.8487712665406426
the 499 times train_loss is 0.2386
the 499 times test_loss is 0.3725
0.9331270372881822 0.9337118416065708 0.8469387755102041 0.861003861003861 0.8274582560296846 0.8438978240302744
the 500 times train_loss is 0.2425
the 500 times test_loss is 0.3786
0.9302115853931385 0.9297674094883888 0.8460111317254174 0.8861283643892339 0.7940630797773655 0.837573385518591
the 501 times train_loss is 0.2427
the 501 times test_loss is 0.3609
0.9327415229880112 0.9328877767464456 0.849721706864564 0.8631984585741811 0.8311688311688312 0.8468809073724007
the 502 times train_loss is 0.2403
the 502 times test_loss is 0.3679
0.9331029426444216 0.933445484773411 0.8515769944341373 0.873767258382643 0.8218923933209648 0.8470363288718928
the 503 times train_loss is 0.2384
the 503 times test_loss is 0.3672
0.9317639688697202 0.9315329057469417 0.8478664192949907 0.8698224852071006 0.8181818181818182 0.8432122370936903
the 504 times train_loss is 0.2411
the 504 times test_loss is 0.3565
0.9339496972680116 0.9338464875926373 0.8478664192949907 0.8654970760233918 0.8237476808905381 0.844106463878327
the 505 times train_loss is 0.2415
the 505 times test_loss is 0.3626
0.9333817520936524 0.9329812305625035 0.849721706864564 0.8762475049900199 0.8144712430426716 0.8442307692307692
the 506 times train_loss is 0.2393
the 506 times test_loss is 0.3702
0.9304938369343352 0.9301898369477817 0.8460111317254174 0.8649706457925636 0.8200371057513914 0.8419047619047619
the 507 times train_loss is 0.2414
the 507 times test_loss is 0.3718
0.933813734635362 0.933748575101164 0.8534322820037106 0.8772277227722772 0.8218923933209648 0.8486590038314178
the 508 times train_loss is 0.2400
the 508 times test_loss is 0.3687
0.933168342391772 0.9323879096341612 0.8580705009276438 0.8814229249011858 0.8274582560296846 0.8535885167464116
the 509 times train_loss is 0.2381
the 509 times test_loss is 0.3701
0.9312648655346774 0.9304144767785031 0.8515769944341373 0.8752475247524752 0.8200371057513914 0.846743295019157
the 510 times train_loss is 0.2382
the 510 times test_loss is 0.3763
0.9324248505271565 0.93280013419763 0.8478664192949907 0.8727634194831014 0.8144712430426716 0.8426103646833014
the 511 times train_loss is 0.2397
the 511 times test_loss is 0.3670
0.9315953063633954 0.9316522807173132 0.8534322820037106 0.864244741873805 0.8385899814471243 0.8512241054613936
the 512 times train_loss is 0.2367
the 512 times test_loss is 0.3733
0.9319429576519426 0.9314168079172322 0.8506493506493507 0.8857142857142857 0.8051948051948052 0.8435374149659864
the 513 times train_loss is 0.2385
the 513 times test_loss is 0.3665
0.9329927957015156 0.9328498883707083 0.8571428571428571 0.8723404255319149 0.8367346938775511 0.8541666666666667
the 514 times train_loss is 0.2366
the 514 times test_loss is 0.3727
0.9313715703856176 0.931229954903456 0.8487940630797773 0.8686274509803922 0.8218923933209648 0.8446139180171592
the 515 times train_loss is 0.2366
the 515 times test_loss is 0.3702
0.9314610647767286 0.9312976918678719 0.8515769944341373 0.873767258382643 0.8218923933209648 0.8470363288718928
the 516 times train_loss is 0.2358
the 516 times test_loss is 0.3668
0.9334540360249346 0.9333999685539547 0.8506493506493507 0.869140625 0.8256029684601113 0.8468125594671742
the 517 times train_loss is 0.2369
the 517 times test_loss is 0.3733
0.9328275752871565 0.9320732927632372 0.8534322820037106 0.878727634194831 0.8200371057513914 0.8483685220729366
the 518 times train_loss is 0.2351
the 518 times test_loss is 0.3764
0.9309654035336515 0.9301587882625972 0.8515769944341373 0.8665377176015474 0.8311688311688312 0.8484848484848485
the 519 times train_loss is 0.2359
the 519 times test_loss is 0.3780
0.9314954856963868 0.9312374514584982 0.8515769944341373 0.8722986247544204 0.8237476808905381 0.8473282442748091
the 520 times train_loss is 0.2354
the 520 times test_loss is 0.3783
0.9299947335992922 0.9294199019000678 0.852504638218924 0.876984126984127 0.8200371057513914 0.8475551294343241
the 521 times train_loss is 0.2359
the 521 times test_loss is 0.3766
0.9321907882734812 0.9319909752671909 0.8552875695732839 0.8747553816046967 0.8293135435992579 0.8514285714285714
the 522 times train_loss is 0.2350
the 522 times test_loss is 0.3805
0.9312958443623697 0.9311137324044423 0.8534322820037106 0.8772277227722772 0.8218923933209648 0.8486590038314178
the 523 times train_loss is 0.2351
the 523 times test_loss is 0.3726
0.9307244570960447 0.9304941131094899 0.8543599257884972 0.8673076923076923 0.8367346938775511 0.8517469310670445
the 524 times train_loss is 0.2361
the 524 times test_loss is 0.3906
0.9307244570960447 0.9308111300625425 0.8469387755102041 0.8879668049792531 0.7940630797773655 0.8383937316356511
the 525 times train_loss is 0.2388
the 525 times test_loss is 0.3758
0.9302494484047625 0.9302373646275609 0.8460111317254174 0.8372513562386981 0.8589981447124304 0.847985347985348
the 526 times train_loss is 0.2489
the 526 times test_loss is 0.4195
0.9338085714974133 0.9339200022978867 0.8404452690166976 0.9123595505617977 0.7532467532467533 0.8252032520325203
the 527 times train_loss is 0.2631
the 527 times test_loss is 0.3538
0.9355743646758755 0.9356776468931175 0.8589981447124304 0.8461538461538461 0.8775510204081632 0.8615664845173042
the 528 times train_loss is 0.2722
the 528 times test_loss is 0.3489
0.9322389775610024 0.9323445577721616 0.8543599257884972 0.8715953307392996 0.8311688311688312 0.8509021842355177
the 529 times train_loss is 0.2483
the 529 times test_loss is 0.3800
0.9274613539124539 0.9291417196898507 0.8404452690166976 0.9032967032967033 0.7625231910946196 0.8269617706237424
the 530 times train_loss is 0.2600
the 530 times test_loss is 0.3562
0.9308242777630533 0.9322266709989562 0.8469387755102041 0.8582375478927203 0.8311688311688312 0.8444863336475024
the 531 times train_loss is 0.2484
the 531 times test_loss is 0.3550
0.9365863397138244 0.9376012511943019 0.8487940630797773 0.8560606060606061 0.8385899814471243 0.8472352389878164
the 532 times train_loss is 0.2523
the 532 times test_loss is 0.3621
0.9370028328416877 0.9358104926144561 0.852504638218924 0.8784860557768924 0.8181818181818182 0.8472622478386167
the 533 times train_loss is 0.2501
the 533 times test_loss is 0.3703
0.9334574781169004 0.9311843466079975 0.8487940630797773 0.8884297520661157 0.7977736549165121 0.8406647116324536
the 534 times train_loss is 0.2504
the 534 times test_loss is 0.3583
0.9303974583592924 0.9291452498890942 0.8478664192949907 0.8626692456479691 0.8274582560296846 0.8446969696969698
the 535 times train_loss is 0.2445
the 535 times test_loss is 0.3468
0.9320117994912588 0.9323513683515081 0.8478664192949907 0.8531073446327684 0.8404452690166976 0.8467289719626169
the 536 times train_loss is 0.2478
the 536 times test_loss is 0.3399
0.9363350670003201 0.9367009061716501 0.8580705009276438 0.8784313725490196 0.8311688311688312 0.8541468064823643
the 537 times train_loss is 0.2476
the 537 times test_loss is 0.3393
0.938548332134338 0.9385743410638205 0.8571428571428571 0.8888888888888888 0.8163265306122449 0.851063829787234
the 538 times train_loss is 0.2459
the 538 times test_loss is 0.3354
0.9382591964092095 0.9373525600346684 0.8562152133580705 0.875 0.8311688311688312 0.8525214081826832
the 539 times train_loss is 0.2424
the 539 times test_loss is 0.3394
0.9365656871620297 0.9346358212042347 0.8571428571428571 0.8723404255319149 0.8367346938775511 0.8541666666666667
the 540 times train_loss is 0.2453
the 540 times test_loss is 0.3441
0.9376120831196368 0.9359598863019504 0.8562152133580705 0.8764705882352941 0.8293135435992579 0.8522402287893232
the 541 times train_loss is 0.2424
the 541 times test_loss is 0.3507
0.9377463247063035 0.9369482249563631 0.852504638218924 0.8815261044176707 0.8144712430426716 0.8466730954676952
the 542 times train_loss is 0.2419
the 542 times test_loss is 0.3505
0.9355984593196361 0.9353572919811434 0.8534322820037106 0.8713450292397661 0.8293135435992579 0.8498098859315589
the 543 times train_loss is 0.2405
the 543 times test_loss is 0.3524
0.9334058467374131 0.9328176015404996 0.852504638218924 0.8584905660377359 0.8441558441558441 0.8512628624883068
the 544 times train_loss is 0.2418
the 544 times test_loss is 0.3566
0.9340185391073278 0.933087174302948 0.8469387755102041 0.8725099601593626 0.8126159554730983 0.8414985590778098
the 545 times train_loss is 0.2397
the 545 times test_loss is 0.3599
0.934861851638952 0.9333543913479017 0.8469387755102041 0.8770161290322581 0.8070500927643784 0.8405797101449274
the 546 times train_loss is 0.2399
the 546 times test_loss is 0.3556
0.9349582302139948 0.9330908031704717 0.8534322820037106 0.8684719535783365 0.8330241187384044 0.8503787878787877
the 547 times train_loss is 0.2392
the 547 times test_loss is 0.3573
0.9341218018663022 0.9321803405803928 0.8543599257884972 0.8687258687258688 0.8348794063079777 0.8514664143803218
the 548 times train_loss is 0.2391
the 548 times test_loss is 0.3627
0.9343765166717725 0.9335849607841136 0.8478664192949907 0.8698224852071006 0.8181818181818182 0.8432122370936903
the 549 times train_loss is 0.2390
the 549 times test_loss is 0.3688
0.9317433163179255 0.9305989416680268 0.8450834879406308 0.8765182186234818 0.8033395176252319 0.8383349467570185
the 550 times train_loss is 0.2384
the 550 times test_loss is 0.3666
0.9309791719015149 0.9304512305173563 0.8478664192949907 0.861271676300578 0.8293135435992579 0.8449905482041588
the 551 times train_loss is 0.2376
the 551 times test_loss is 0.3724
0.9317536425938229 0.9313556812910982 0.8534322820037106 0.87279843444227 0.8274582560296846 0.8495238095238095
the 552 times train_loss is 0.2373
the 552 times test_loss is 0.3785
0.931271749718609 0.9302758207085419 0.8487940630797773 0.8805668016194332 0.8070500927643784 0.8422071636011617
the 553 times train_loss is 0.2373
the 553 times test_loss is 0.3720
0.9318465790768996 0.9310863160566074 0.849721706864564 0.8660194174757282 0.8274582560296846 0.8462998102466792
the 554 times train_loss is 0.2381
the 554 times test_loss is 0.3756
0.9296815032304034 0.9287297651207381 0.8469387755102041 0.8725099601593626 0.8126159554730983 0.8414985590778098
the 555 times train_loss is 0.2372
the 555 times test_loss is 0.3794
0.9314438543168997 0.9313812208176286 0.8562152133580705 0.8809523809523809 0.8237476808905381 0.8513902205177372
the 556 times train_loss is 0.2368
the 556 times test_loss is 0.3778
0.930018828243053 0.9301386481997422 0.8515769944341373 0.8708414872798435 0.8256029684601113 0.8476190476190475
the 557 times train_loss is 0.2356
the 557 times test_loss is 0.3764
0.9298777024724547 0.92969179774452 0.8543599257884972 0.8745098039215686 0.8274582560296846 0.8503336510962821
the 558 times train_loss is 0.2357
the 558 times test_loss is 0.3825
0.9320634308707461 0.9319465582289104 0.8515769944341373 0.8812877263581489 0.8126159554730983 0.8455598455598455
the 559 times train_loss is 0.2367
the 559 times test_loss is 0.3847
0.9298845866563864 0.9292792329098626 0.8506493506493507 0.8735177865612648 0.8200371057513914 0.845933014354067
the 560 times train_loss is 0.2371
the 560 times test_loss is 0.3834
0.930018828243053 0.9300700092606131 0.8506493506493507 0.8620689655172413 0.8348794063079777 0.8482563619227145
the 561 times train_loss is 0.2388
the 561 times test_loss is 0.3884
0.9283115506280097 0.9278764457807226 0.8450834879406308 0.8811475409836066 0.7977736549165121 0.8373904576436223
the 562 times train_loss is 0.2396
the 562 times test_loss is 0.3758
0.9308346040389508 0.9309161702432752 0.8469387755102041 0.865234375 0.8218923933209648 0.8430066603235015
the 563 times train_loss is 0.2373
the 563 times test_loss is 0.3739
0.9303905741753609 0.9301551047152073 0.8534322820037106 0.8699029126213592 0.8311688311688312 0.8500948766603416
the 564 times train_loss is 0.2352
the 564 times test_loss is 0.3782
0.9305764471415149 0.9303060561880494 0.8487940630797773 0.873015873015873 0.8163265306122449 0.8437200383509109
the 565 times train_loss is 0.2382
the 565 times test_loss is 0.3757
0.9319945890314298 0.9319705047227841 0.8487940630797773 0.873015873015873 0.8163265306122449 0.8437200383509109
the 566 times train_loss is 0.2377
the 566 times test_loss is 0.3741
0.9293476203097195 0.9289689297154305 0.8543599257884972 0.8645038167938931 0.8404452690166976 0.8523047977422389
the 567 times train_loss is 0.2361
the 567 times test_loss is 0.3854
0.9294199042410015 0.9292541395245445 0.8506493506493507 0.878 0.8144712430426716 0.8450433108758422
the 568 times train_loss is 0.2368
the 568 times test_loss is 0.3820
0.9309516351657884 0.9308358954139416 0.8423005565862709 0.8653465346534653 0.8107606679035251 0.8371647509578545
the 569 times train_loss is 0.2350
the 569 times test_loss is 0.3763
0.9296436402187793 0.928866512868683 0.852504638218924 0.8625954198473282 0.8385899814471243 0.8504233301975541
the 570 times train_loss is 0.2356
the 570 times test_loss is 0.3862
0.9313956650293782 0.9308770204053494 0.8469387755102041 0.8831967213114754 0.7996289424860853 0.8393378773125608
the 571 times train_loss is 0.2357
the 571 times test_loss is 0.3770
0.9308845143724549 0.9302839780671752 0.852504638218924 0.8682170542635659 0.8311688311688312 0.8492890995260663
the 572 times train_loss is 0.2342
the 572 times test_loss is 0.3759
0.9306074259692072 0.9299816468140127 0.8534322820037106 0.8699029126213592 0.8311688311688312 0.8500948766603416
the 573 times train_loss is 0.2335
the 573 times test_loss is 0.3848
0.9303905741753608 0.9297833874706903 0.8478664192949907 0.8818737270875764 0.8033395176252319 0.8407766990291262
the 574 times train_loss is 0.2349
the 574 times test_loss is 0.3793
0.9294233463329673 0.9288791009564678 0.8515769944341373 0.8651252408477842 0.8330241187384044 0.8487712665406426
the 575 times train_loss is 0.2341
the 575 times test_loss is 0.3839
0.9301874907493779 0.9298222044394695 0.8487940630797773 0.873015873015873 0.8163265306122449 0.8437200383509109
the 576 times train_loss is 0.2333
the 576 times test_loss is 0.3855
0.9296677348625401 0.9290705281927762 0.8506493506493507 0.8810483870967742 0.8107606679035251 0.8444444444444444
the 577 times train_loss is 0.2339
the 577 times test_loss is 0.3797
0.9300119440591215 0.9296252014397315 0.8534322820037106 0.8684719535783365 0.8330241187384044 0.8503787878787877
the 578 times train_loss is 0.2340
the 578 times test_loss is 0.3893
0.9288313065148476 0.9283384548780363 0.8506493506493507 0.8795180722891566 0.8126159554730983 0.8447444551591127
the 579 times train_loss is 0.2338
the 579 times test_loss is 0.3866
0.9301427435538223 0.9301216467048523 0.8478664192949907 0.8712871287128713 0.8163265306122449 0.842911877394636
the 580 times train_loss is 0.2337
the 580 times test_loss is 0.3872
0.9270586291524537 0.9262515024570507 0.849721706864564 0.8646034816247582 0.8293135435992579 0.8465909090909091
the 581 times train_loss is 0.2346
the 581 times test_loss is 0.3944
0.9305833313254464 0.9305660915985008 0.8478664192949907 0.8787878787878788 0.8070500927643784 0.8413926499032882
the 582 times train_loss is 0.2355
the 582 times test_loss is 0.3859
0.9281566564895481 0.9277261637492318 0.8506493506493507 0.8648648648648649 0.8311688311688312 0.847682119205298
the 583 times train_loss is 0.2338
the 583 times test_loss is 0.3870
0.9296677348625401 0.9295424572647424 0.849721706864564 0.8747514910536779 0.8163265306122449 0.8445297504798464
the 584 times train_loss is 0.2325
the 584 times test_loss is 0.3906
0.9294336726088648 0.9294203310134359 0.8487940630797773 0.876 0.8126159554730983 0.8431183830606351
the 585 times train_loss is 0.2326
the 585 times test_loss is 0.3873
0.9279398046957019 0.927830014300948 0.8534322820037106 0.8670520231213873 0.8348794063079777 0.8506616257088847
the 586 times train_loss is 0.2332
the 586 times test_loss is 0.3926
0.9298880287483521 0.9300751538437938 0.8478664192949907 0.874251497005988 0.8126159554730983 0.8423076923076923
the 587 times train_loss is 0.2336
the 587 times test_loss is 0.3924
0.9272685967623684 0.9268308684742919 0.849721706864564 0.8732673267326733 0.8181818181818182 0.8448275862068967
the 588 times train_loss is 0.2337
the 588 times test_loss is 0.3868
0.9300394807948479 0.9304439885751838 0.849721706864564 0.8604206500956023 0.8348794063079777 0.8474576271186441
the 589 times train_loss is 0.2366
the 589 times test_loss is 0.4043
0.9263185793798039 0.9257917551646242 0.839517625231911 0.8796680497925311 0.7866419294990723 0.830558276199804
the 590 times train_loss is 0.2438
the 590 times test_loss is 0.3723
0.9319911469394639 0.9326806441924258 0.8534322820037106 0.8614800759013282 0.8423005565862709 0.8517823639774859
the 591 times train_loss is 0.2460
the 591 times test_loss is 0.3848
0.92782621566083 0.9273030569855673 0.849721706864564 0.8732673267326733 0.8181818181818182 0.8448275862068967
the 592 times train_loss is 0.2371
the 592 times test_loss is 0.3940
0.9271756602792913 0.9271866405648952 0.849721706864564 0.8732673267326733 0.8181818181818182 0.8448275862068967
the 593 times train_loss is 0.2439
the 593 times test_loss is 0.3727
0.9323422403199769 0.9328831676295776 0.8515769944341373 0.8797595190380761 0.8144712430426716 0.8458574181117534
the 594 times train_loss is 0.2380
the 594 times test_loss is 0.3681
0.9336089301633961 0.934645801607763 0.8506493506493507 0.867704280155642 0.8274582560296846 0.8471035137701803
the 595 times train_loss is 0.2423
the 595 times test_loss is 0.3833
0.9305798892334806 0.9313379082965556 0.8469387755102041 0.871031746031746 0.8144712430426716 0.8418024928092043
the 596 times train_loss is 0.2361
the 596 times test_loss is 0.3918
0.9252687413302308 0.9246476736599838 0.8413729128014842 0.8650793650793651 0.8089053803339518 0.8360498561840845
the 597 times train_loss is 0.2387
the 597 times test_loss is 0.3884
0.9269553663934793 0.9259101005393298 0.8423005565862709 0.8712273641851107 0.8033395176252319 0.8359073359073359
the 598 times train_loss is 0.2378
the 598 times test_loss is 0.3669
0.9316985691223698 0.9314485518509448 0.849721706864564 0.8604206500956023 0.8348794063079777 0.8474576271186441
the 599 times train_loss is 0.2365
the 599 times test_loss is 0.3727
0.9351957345596359 0.9354416660736767 0.849721706864564 0.8839103869653768 0.8051948051948052 0.8427184466019418
the 600 times train_loss is 0.2389
the 600 times test_loss is 0.3614
0.9332509525989515 0.9330137132365883 0.8571428571428571 0.8723404255319149 0.8367346938775511 0.8541666666666667
the 601 times train_loss is 0.2364
the 601 times test_loss is 0.3669
0.9317450373639082 0.9311695480415764 0.852504638218924 0.8682170542635659 0.8311688311688312 0.8492890995260663
the 602 times train_loss is 0.2342
the 602 times test_loss is 0.3784
0.9306108680611729 0.9293979018839893 0.8469387755102041 0.874 0.8107606679035251 0.8411934552454283
the 603 times train_loss is 0.2350
the 603 times test_loss is 0.3773
0.9291135580560441 0.927911902228704 0.8562152133580705 0.8636363636363636 0.8460111317254174 0.8547328959700093
the 604 times train_loss is 0.2358
the 604 times test_loss is 0.3904
0.9312132341551902 0.9311239346245809 0.8432282003710575 0.8714859437751004 0.8051948051948052 0.8370298939247831
the 605 times train_loss is 0.2366
the 605 times test_loss is 0.3837
0.927881289132283 0.9267873009174202 0.852504638218924 0.8667953667953668 0.8330241187384044 0.8495742667928099
the 606 times train_loss is 0.2352
the 606 times test_loss is 0.3804
0.9306969203603181 0.9305233976865993 0.8478664192949907 0.8654970760233918 0.8237476808905381 0.844106463878327
the 607 times train_loss is 0.2347
the 607 times test_loss is 0.3855
0.9285938021692064 0.927813873587428 0.8534322820037106 0.8802395209580839 0.8181818181818182 0.8480769230769232
the 608 times train_loss is 0.2341
the 608 times test_loss is 0.3788
0.9300291545189505 0.9293188786433517 0.8552875695732839 0.8689788053949904 0.8367346938775511 0.8525519848771268
the 609 times train_loss is 0.2335
the 609 times test_loss is 0.3838
0.9314851594204894 0.9311151602786908 0.8506493506493507 0.8764940239043825 0.8163265306122449 0.8453410182516811
the 610 times train_loss is 0.2338
the 610 times test_loss is 0.3878
0.9285938021692064 0.9275055335827392 0.8571428571428571 0.8781925343811395 0.8293135435992579 0.8530534351145038
the 611 times train_loss is 0.2331
the 611 times test_loss is 0.3920
0.928215172052967 0.9278731593061766 0.8506493506493507 0.8735177865612648 0.8200371057513914 0.845933014354067
the 612 times train_loss is 0.2324
the 612 times test_loss is 0.3944
0.9283872766512576 0.9282897663057423 0.8487940630797773 0.873015873015873 0.8163265306122449 0.8437200383509109
the 613 times train_loss is 0.2325
the 613 times test_loss is 0.3903
0.9280465095466421 0.9272108620801744 0.8515769944341373 0.8752475247524752 0.8200371057513914 0.846743295019157
the 614 times train_loss is 0.2326
the 614 times test_loss is 0.3904
0.9297331346098905 0.929460055085999 0.8506493506493507 0.878 0.8144712430426716 0.8450433108758422
the 615 times train_loss is 0.2325
the 615 times test_loss is 0.3891
0.9279535730635652 0.9273666396197119 0.8515769944341373 0.8665377176015474 0.8311688311688312 0.8484848484848485
the 616 times train_loss is 0.2322
the 616 times test_loss is 0.3929
0.9285593812495482 0.9284157018391098 0.8506493506493507 0.875 0.8181818181818182 0.8456375838926175
the 617 times train_loss is 0.2319
the 617 times test_loss is 0.3900
0.9288330275608303 0.9287157578662576 0.8543599257884972 0.8745098039215686 0.8274582560296846 0.8503336510962821
the 618 times train_loss is 0.2316
the 618 times test_loss is 0.3953
0.9281876353172405 0.9276705839063503 0.8534322820037106 0.8742632612966601 0.8256029684601113 0.8492366412213739
the 619 times train_loss is 0.2314
the 619 times test_loss is 0.3991
0.9282186141449328 0.9280804361082812 0.8478664192949907 0.874251497005988 0.8126159554730983 0.8423076923076923
the 620 times train_loss is 0.2315
the 620 times test_loss is 0.3953
0.9264769156102313 0.926008534852997 0.8552875695732839 0.8732943469785575 0.8311688311688312 0.8517110266159695
the 621 times train_loss is 0.2316
the 621 times test_loss is 0.3989
0.928046509546642 0.9279756896693231 0.8469387755102041 0.8770161290322581 0.8070500927643784 0.8405797101449274
the 622 times train_loss is 0.2318
the 622 times test_loss is 0.3925
0.9267867038871545 0.9261076987052717 0.8506493506493507 0.8620689655172413 0.8348794063079777 0.8482563619227145
the 623 times train_loss is 0.2323
the 623 times test_loss is 0.3993
0.9293992516892066 0.9290464734332322 0.8460111317254174 0.8767676767676768 0.8051948051948052 0.8394584139264991
the 624 times train_loss is 0.2327
the 624 times test_loss is 0.3950
0.9264665893343338 0.9255223484817195 0.8534322820037106 0.8628571428571429 0.8404452690166976 0.8515037593984963
the 625 times train_loss is 0.2325
the 625 times test_loss is 0.4037
0.9282599192485224 0.9280500031167134 0.8450834879406308 0.875 0.8051948051948052 0.8386473429951691
the 626 times train_loss is 0.2321
the 626 times test_loss is 0.3950
0.926865872002368 0.9263489034962691 0.8543599257884972 0.8715953307392996 0.8311688311688312 0.8509021842355177
the 627 times train_loss is 0.2311
the 627 times test_loss is 0.3997
0.9269347138416844 0.9264189898426249 0.852504638218924 0.8784860557768924 0.8181818181818182 0.8472622478386167
the 628 times train_loss is 0.2308
the 628 times test_loss is 0.3968
0.9285490549736507 0.928604656306563 0.8478664192949907 0.8698224852071006 0.8181818181818182 0.8432122370936903
the 629 times train_loss is 0.2317
the 629 times test_loss is 0.4008
0.9248212693746751 0.9239171154817526 0.8460111317254174 0.8678500986193294 0.8163265306122449 0.8413001912045889
the 630 times train_loss is 0.2333
the 630 times test_loss is 0.3968
0.9291066738721124 0.9296466854148061 0.849721706864564 0.8703339882121808 0.8218923933209648 0.8454198473282444
the 631 times train_loss is 0.2346
the 631 times test_loss is 0.4003
0.9257781709411712 0.9250810050430933 0.8469387755102041 0.8695652173913043 0.8163265306122449 0.8421052631578948
the 632 times train_loss is 0.2329
the 632 times test_loss is 0.3939
0.9272513863025393 0.9263789258603852 0.8506493506493507 0.8662790697674418 0.8293135435992579 0.84739336492891
the 633 times train_loss is 0.2313
the 633 times test_loss is 0.3983
0.9299155654840785 0.9297335222722692 0.8469387755102041 0.874 0.8107606679035251 0.8411934552454283
the 634 times train_loss is 0.2337
the 634 times test_loss is 0.3940
0.9260363278386071 0.9253940415738138 0.8487940630797773 0.862934362934363 0.8293135435992579 0.8457899716177862
the 635 times train_loss is 0.2327
the 635 times test_loss is 0.4041
0.9276885319821974 0.9274012907191945 0.849721706864564 0.8823529411764706 0.8070500927643784 0.8430232558139534
the 636 times train_loss is 0.2321
the 636 times test_loss is 0.3929
0.9278744049483515 0.9275827604423522 0.8478664192949907 0.8531073446327684 0.8404452690166976 0.8467289719626169
the 637 times train_loss is 0.2345
the 637 times test_loss is 0.4093
0.9275542903955308 0.9270353079164702 0.8450834879406308 0.8891213389121339 0.7884972170686456 0.8357915437561455
the 638 times train_loss is 0.2390
the 638 times test_loss is 0.3793
0.929819186909036 0.929592746733898 0.8562152133580705 0.8542435424354243 0.8589981447124304 0.8566142460684553
the 639 times train_loss is 0.2417
the 639 times test_loss is 0.3991
0.929481861896386 0.9293316460661831 0.8487940630797773 0.8868312757201646 0.7996289424860853 0.8409756097560975
the 640 times train_loss is 0.2362
the 640 times test_loss is 0.3897
0.9268383352666416 0.9267754537987699 0.8460111317254174 0.8579654510556622 0.8293135435992579 0.8433962264150944
the 641 times train_loss is 0.2367
the 641 times test_loss is 0.3816
0.9296092192991212 0.9288069440861948 0.852504638218924 0.8667953667953668 0.8330241187384044 0.8495742667928099
the 642 times train_loss is 0.2331
the 642 times test_loss is 0.3913
0.9315712117196346 0.9309554854479134 0.8515769944341373 0.8828282828282829 0.8107606679035251 0.8452611218568664
the 643 times train_loss is 0.2364
the 643 times test_loss is 0.3839
0.9281583775355309 0.9269368002447238 0.8469387755102041 0.8555133079847909 0.8348794063079777 0.8450704225352114
the 644 times train_loss is 0.2353
the 644 times test_loss is 0.3868
0.9297537871616854 0.9297063912077312 0.8441558441558441 0.8615984405458089 0.8200371057513914 0.8403041825095056
the 645 times train_loss is 0.2334
the 645 times test_loss is 0.3881
0.9285972442611721 0.927905340399787 0.8506493506493507 0.8810483870967742 0.8107606679035251 0.8444444444444444
the 646 times train_loss is 0.2349
the 646 times test_loss is 0.3795
0.9284492343066423 0.927474494560359 0.849721706864564 0.8604206500956023 0.8348794063079777 0.8474576271186441
the 647 times train_loss is 0.2327
the 647 times test_loss is 0.3914
0.9292340312748476 0.9288250195472842 0.852504638218924 0.8725490196078431 0.8256029684601113 0.8484270734032412
the 648 times train_loss is 0.2343
the 648 times test_loss is 0.3851
0.9290171794810014 0.9282735551422596 0.849721706864564 0.8732673267326733 0.8181818181818182 0.8448275862068967
the 649 times train_loss is 0.2315
the 649 times test_loss is 0.3821
0.9293992516892066 0.9286702285142232 0.8534322820037106 0.8713450292397661 0.8293135435992579 0.8498098859315589
the 650 times train_loss is 0.2326
the 650 times test_loss is 0.3899
0.9298157448170701 0.9293013278456094 0.8478664192949907 0.8727634194831014 0.8144712430426716 0.8426103646833014
the 651 times train_loss is 0.2310
the 651 times test_loss is 0.3962
0.9281119092939925 0.9268152286845981 0.8450834879406308 0.8690476190476191 0.8126159554730983 0.8398849472674976
the 652 times train_loss is 0.2324
the 652 times test_loss is 0.3878
0.9287831172273261 0.9276151673320399 0.8506493506493507 0.8634615384615385 0.8330241187384044 0.8479697828139754
the 653 times train_loss is 0.2320
the 653 times test_loss is 0.3982
0.929024063664933 0.9280309337152294 0.8515769944341373 0.8843813387423936 0.8089053803339518 0.8449612403100776
the 654 times train_loss is 0.2329
the 654 times test_loss is 0.3924
0.9274166067168983 0.9266364796142893 0.8478664192949907 0.8571428571428571 0.8348794063079777 0.8458646616541353
the 655 times train_loss is 0.2321
the 655 times test_loss is 0.3977
0.9270792817042486 0.9262555905278048 0.852504638218924 0.876984126984127 0.8200371057513914 0.8475551294343241
the 656 times train_loss is 0.2312
the 656 times test_loss is 0.3922
0.9286041284451038 0.9278150706672147 0.8562152133580705 0.8824701195219123 0.8218923933209648 0.851104707012488
the 657 times train_loss is 0.2313
the 657 times test_loss is 0.3930
0.927292691406129 0.9264284404918445 0.8506493506493507 0.8634615384615385 0.8330241187384044 0.8479697828139754
the 658 times train_loss is 0.2307
the 658 times test_loss is 0.4047
0.9266042730129664 0.9260557645892322 0.8487940630797773 0.8775100401606426 0.8107606679035251 0.8428158148505305
the 659 times train_loss is 0.2320
the 659 times test_loss is 0.3929
0.9278296577527958 0.92722895753705 0.8487940630797773 0.862934362934363 0.8293135435992579 0.8457899716177862
the 660 times train_loss is 0.2324
the 660 times test_loss is 0.4031
0.9268968508300606 0.9259037517759191 0.8487940630797773 0.8805668016194332 0.8070500927643784 0.8422071636011617
the 661 times train_loss is 0.2330
the 661 times test_loss is 0.3951
0.928710833296044 0.9285301352938152 0.8487940630797773 0.8615384615384616 0.8311688311688312 0.8460812086874411
the 662 times train_loss is 0.2312
the 662 times test_loss is 0.3973
0.9269519243015134 0.9264319525517438 0.849721706864564 0.8646034816247582 0.8293135435992579 0.8465909090909091
the 663 times train_loss is 0.2301
the 663 times test_loss is 0.4034
0.9260604224823679 0.924999407243371 0.8487940630797773 0.8790322580645161 0.8089053803339518 0.842512077294686
the 664 times train_loss is 0.2312
the 664 times test_loss is 0.3965
0.9269002929220262 0.9261584346319072 0.852504638218924 0.8682170542635659 0.8311688311688312 0.8492890995260663
the 665 times train_loss is 0.2309
the 665 times test_loss is 0.4027
0.9280189728109154 0.9276271615193047 0.8460111317254174 0.8707753479125249 0.8126159554730983 0.8406909788867563
the 666 times train_loss is 0.2304
the 666 times test_loss is 0.3973
0.927179102371257 0.9263809184106773 0.8562152133580705 0.8764705882352941 0.8293135435992579 0.8522402287893232
the 667 times train_loss is 0.2300
the 667 times test_loss is 0.3994
0.9270827237962144 0.9264201830834009 0.8478664192949907 0.8698224852071006 0.8181818181818182 0.8432122370936903
the 668 times train_loss is 0.2297
the 668 times test_loss is 0.4096
0.9245183652816836 0.9235706050834913 0.8478664192949907 0.8712871287128713 0.8163265306122449 0.842911877394636
the 669 times train_loss is 0.2305
the 669 times test_loss is 0.4017
0.9264528209664705 0.9254115491108817 0.8487940630797773 0.8657587548638133 0.8256029684601113 0.8452041785375118
the 670 times train_loss is 0.2294
the 670 times test_loss is 0.4040
0.9276816477982659 0.9268706562220715 0.8506493506493507 0.878 0.8144712430426716 0.8450433108758422
the 671 times train_loss is 0.2297
the 671 times test_loss is 0.4026
0.9266249255647613 0.9256766295397407 0.8506493506493507 0.867704280155642 0.8274582560296846 0.8471035137701803
the 672 times train_loss is 0.2300
the 672 times test_loss is 0.4047
0.9275439641196334 0.9268707924679639 0.849721706864564 0.8762475049900199 0.8144712430426716 0.8442307692307692
the 673 times train_loss is 0.2299
the 673 times test_loss is 0.4018
0.9246904698799743 0.9232093870472808 0.8534322820037106 0.8684719535783365 0.8330241187384044 0.8503787878787877
the 674 times train_loss is 0.2306
the 674 times test_loss is 0.4081
0.9279329205117702 0.9276801506933122 0.8432282003710575 0.87 0.8070500927643784 0.8373435996150144
the 675 times train_loss is 0.2313
the 675 times test_loss is 0.4026
0.9248315956505726 0.9238272389984858 0.8478664192949907 0.858508604206501 0.8330241187384044 0.8455743879472694
the 676 times train_loss is 0.2311
the 676 times test_loss is 0.4079
0.9281635406734796 0.927981784626957 0.8469387755102041 0.8770161290322581 0.8070500927643784 0.8405797101449274
the 677 times train_loss is 0.2321
the 677 times test_loss is 0.4041
0.9242980713958715 0.9233601000705582 0.8478664192949907 0.8598848368522073 0.8311688311688312 0.8452830188679245
the 678 times train_loss is 0.2306
the 678 times test_loss is 0.4082
0.9265216628057867 0.9256583950054444 0.8441558441558441 0.8717434869739479 0.8070500927643784 0.838150289017341
the 679 times train_loss is 0.2295
the 679 times test_loss is 0.3955
0.9276678794304025 0.927036034853034 0.849721706864564 0.8674463937621832 0.8256029684601113 0.8460076045627375
the 680 times train_loss is 0.2299
the 680 times test_loss is 0.4052
0.9250174686167265 0.9241734796639253 0.8441558441558441 0.8673267326732673 0.8126159554730983 0.8390804597701149
the 681 times train_loss is 0.2313
the 681 times test_loss is 0.3948
0.9287900014112576 0.9287810603747065 0.8469387755102041 0.861003861003861 0.8274582560296846 0.8438978240302744
the 682 times train_loss is 0.2342
the 682 times test_loss is 0.4060
0.9243497027753588 0.9230267768379823 0.8404452690166976 0.8707070707070707 0.7996289424860853 0.8336557059961315
the 683 times train_loss is 0.2390
the 683 times test_loss is 0.3787
0.929870818288523 0.9287602180901469 0.8487940630797773 0.8643410852713178 0.8274582560296846 0.8454976303317535
the 684 times train_loss is 0.2343
the 684 times test_loss is 0.3927
0.9287314858478389 0.9287869229871067 0.8487940630797773 0.8686274509803922 0.8218923933209648 0.8446139180171592
the 685 times train_loss is 0.2359
the 685 times test_loss is 0.3934
0.9257575183893763 0.9253918115955746 0.8506493506493507 0.8720472440944882 0.8218923933209648 0.8462273161413563
the 686 times train_loss is 0.2344
the 686 times test_loss is 0.3877
0.9290825792283518 0.9275337664815209 0.8506493506493507 0.8825910931174089 0.8089053803339518 0.8441432720232332
the 687 times train_loss is 0.2343
the 687 times test_loss is 0.3932
0.929099789688181 0.9287511684120295 0.8478664192949907 0.858508604206501 0.8330241187384044 0.8455743879472694
the 688 times train_loss is 0.2340
the 688 times test_loss is 0.4079
0.9273099018659581 0.9269084105891213 0.8404452690166976 0.8722109533468559 0.7977736549165121 0.8333333333333334
the 689 times train_loss is 0.2321
the 689 times test_loss is 0.3921
0.9237060315777517 0.9217033446726204 0.8460111317254174 0.8621359223300971 0.8237476808905381 0.842504743833017
the 690 times train_loss is 0.2365
the 690 times test_loss is 0.3999
0.9296987136902324 0.9290747630882126 0.8450834879406308 0.8780487804878049 0.8014842300556586 0.8380213385063044
the 691 times train_loss is 0.2327
the 691 times test_loss is 0.3969
0.9281497723056165 0.927823460253532 0.8478664192949907 0.8491620111731844 0.8460111317254174 0.8475836431226765
the 692 times train_loss is 0.2377
the 692 times test_loss is 0.3960
0.9281704248574114 0.9269864098890839 0.8460111317254174 0.8767676767676768 0.8051948051948052 0.8394584139264991
the 693 times train_loss is 0.2333
the 693 times test_loss is 0.3895
0.9282736876163857 0.9270650795962037 0.8534322820037106 0.8832997987927566 0.8144712430426716 0.8474903474903476
the 694 times train_loss is 0.2331
the 694 times test_loss is 0.3911
0.9252962780659573 0.9255156868872563 0.8487940630797773 0.8533834586466166 0.8423005565862709 0.8478057889822597
the 695 times train_loss is 0.2352
the 695 times test_loss is 0.4193
0.9251035209158718 0.9250948154093002 0.839517625231911 0.88125 0.7847866419294991 0.830225711481845
the 696 times train_loss is 0.2374
the 696 times test_loss is 0.3834
0.9274579118204881 0.9254805848887042 0.852504638218924 0.8625954198473282 0.8385899814471243 0.8504233301975541
the 697 times train_loss is 0.2400
the 697 times test_loss is 0.3794
0.9314782752365578 0.9307758496784199 0.8469387755102041 0.8755020080321285 0.8089053803339518 0.8408871745419478
the 698 times train_loss is 0.2369
the 698 times test_loss is 0.3955
0.9242292295565553 0.9243232800150437 0.8478664192949907 0.8571428571428571 0.8348794063079777 0.8458646616541353
the 699 times train_loss is 0.2402
the 699 times test_loss is 0.4026
0.928838190698779 0.9285100270813095 0.8515769944341373 0.8797595190380761 0.8144712430426716 0.8458574181117534
the 700 times train_loss is 0.2372
the 700 times test_loss is 0.3790
0.9317811793295493 0.9306229850984593 0.8478664192949907 0.8626692456479691 0.8274582560296846 0.8446969696969698
the 701 times train_loss is 0.2372
the 701 times test_loss is 0.3823
0.9276162480509152 0.9256854828039182 0.849721706864564 0.8703339882121808 0.8218923933209648 0.8454198473282444
the 702 times train_loss is 0.2353
the 702 times test_loss is 0.3977
0.9257093291018549 0.9252523592722823 0.8423005565862709 0.8819875776397516 0.7903525046382189 0.8336594911937378
the 703 times train_loss is 0.2337
the 703 times test_loss is 0.3921
0.9273271123257871 0.9277458403634383 0.8460111317254174 0.8635477582846004 0.8218923933209648 0.8422053231939163
the 704 times train_loss is 0.2343
the 704 times test_loss is 0.3799
0.9296298718509162 0.9289854051179443 0.849721706864564 0.8646034816247582 0.8293135435992579 0.8465909090909091
the 705 times train_loss is 0.2332
the 705 times test_loss is 0.3866
0.9301152068180958 0.9289517149917782 0.8478664192949907 0.8772635814889336 0.8089053803339518 0.8416988416988418
the 706 times train_loss is 0.2335
the 706 times test_loss is 0.3856
0.9282254983288644 0.9271054257552362 0.8534322820037106 0.8699029126213592 0.8311688311688312 0.8500948766603416
the 707 times train_loss is 0.2305
the 707 times test_loss is 0.3906
0.9273202281418556 0.9266312107452637 0.8460111317254174 0.8607350096711799 0.8256029684601113 0.8428030303030303
the 708 times train_loss is 0.2323
the 708 times test_loss is 0.3944
0.9278021210170694 0.9268551834064872 0.8478664192949907 0.8787878787878788 0.8070500927643784 0.8413926499032882
the 709 times train_loss is 0.2319
the 709 times test_loss is 0.3836
0.9290688108604885 0.9273398986620136 0.852504638218924 0.8653846153846154 0.8348794063079777 0.8498583569405098
the 710 times train_loss is 0.2316
the 710 times test_loss is 0.3838
0.9311753711435662 0.9300361489368671 0.8515769944341373 0.8693957115009746 0.8274582560296846 0.8479087452471483
the 711 times train_loss is 0.2301
the 711 times test_loss is 0.3998
0.9277814684652744 0.926475375647705 0.8506493506493507 0.8764940239043825 0.8163265306122449 0.8453410182516811
the 712 times train_loss is 0.2300
the 712 times test_loss is 0.4012
0.9255854137910856 0.9242975406941224 0.8460111317254174 0.8621359223300971 0.8237476808905381 0.842504743833017
the 713 times train_loss is 0.2302
the 713 times test_loss is 0.3989
0.9284010450191207 0.9279534905129903 0.839517625231911 0.860236220472441 0.8107606679035251 0.8347659980897804
the 714 times train_loss is 0.2312
the 714 times test_loss is 0.4018
0.9251241734676667 0.9241524928741163 0.8441558441558441 0.863013698630137 0.8181818181818182 0.8400000000000001
the 715 times train_loss is 0.2312
the 715 times test_loss is 0.3996
0.9275095431999751 0.9270959303825209 0.8487940630797773 0.8686274509803922 0.8218923933209648 0.8446139180171592
the 716 times train_loss is 0.2291
the 716 times test_loss is 0.3977
0.9281187934779243 0.9281429478039486 0.849721706864564 0.8703339882121808 0.8218923933209648 0.8454198473282444
the 717 times train_loss is 0.2297
the 717 times test_loss is 0.3978
0.9257781709411712 0.92521515621517 0.8478664192949907 0.8698224852071006 0.8181818181818182 0.8432122370936903
the 718 times train_loss is 0.2295
the 718 times test_loss is 0.4031
0.9258642232403165 0.925238189759978 0.8441558441558441 0.8717434869739479 0.8070500927643784 0.838150289017341
the 719 times train_loss is 0.2284
the 719 times test_loss is 0.4078
0.9261981061610004 0.9258030014429877 0.8450834879406308 0.8661417322834646 0.8163265306122449 0.8404966571155683
the 720 times train_loss is 0.2293
the 720 times test_loss is 0.4173
0.9236957053018543 0.9231126703594461 0.8413729128014842 0.8694779116465864 0.8033395176252319 0.8351012536162007
the 721 times train_loss is 0.2289
the 721 times test_loss is 0.4162
0.9249555109613419 0.9243154311841053 0.8450834879406308 0.875 0.8051948051948052 0.8386473429951691
the 722 times train_loss is 0.2283
the 722 times test_loss is 0.4101
0.9251207313757008 0.9247875520627068 0.8441558441558441 0.8588007736943907 0.8237476808905381 0.8409090909090909
the 723 times train_loss is 0.2292
the 723 times test_loss is 0.4237
0.9246732594201451 0.9242498424263205 0.8469387755102041 0.8770161290322581 0.8070500927643784 0.8405797101449274
the 724 times train_loss is 0.2303
the 724 times test_loss is 0.4059
0.9253720040892054 0.9244869090823237 0.852504638218924 0.8653846153846154 0.8348794063079777 0.8498583569405098
the 725 times train_loss is 0.2298
the 725 times test_loss is 0.4118
0.925655976676385 0.9257321644898314 0.8487940630797773 0.8775100401606426 0.8107606679035251 0.8428158148505305
the 726 times train_loss is 0.2287
the 726 times test_loss is 0.4184
0.9234478746803158 0.9242153925621592 0.8487940630797773 0.8700787401574803 0.8200371057513914 0.8443170964660935
the 727 times train_loss is 0.2294
the 727 times test_loss is 0.4211
0.9249623951452735 0.9254771127523693 0.8404452690166976 0.869215291750503 0.8014842300556586 0.8339768339768339
the 728 times train_loss is 0.2277
the 728 times test_loss is 0.4177
0.9240743354180936 0.9238847021386903 0.8450834879406308 0.8618677042801557 0.8218923933209648 0.8414055080721748
the 729 times train_loss is 0.2280
the 729 times test_loss is 0.4291
0.9228489506782642 0.9227350372299131 0.839517625231911 0.8734693877551021 0.7940630797773655 0.8318756073858115
the 730 times train_loss is 0.2285
the 730 times test_loss is 0.4200
0.9232964226338198 0.9235763796676228 0.8441558441558441 0.863013698630137 0.8181818181818182 0.8400000000000001
the 731 times train_loss is 0.2280
the 731 times test_loss is 0.4207
0.9245286915575811 0.9245701217571298 0.8432282003710575 0.8729838709677419 0.8033395176252319 0.8367149758454107
the 732 times train_loss is 0.2273
the 732 times test_loss is 0.4175
0.9236234213705722 0.923023578754412 0.849721706864564 0.8688845401174168 0.8237476808905381 0.8457142857142858
the 733 times train_loss is 0.2274
the 733 times test_loss is 0.4220
0.9249107637657863 0.9248880724017798 0.8432282003710575 0.8729838709677419 0.8033395176252319 0.8367149758454107
the 734 times train_loss is 0.2276
the 734 times test_loss is 0.4175
0.9229883554028797 0.9228397521938246 0.8487940630797773 0.8643410852713178 0.8274582560296846 0.8454976303317535
the 735 times train_loss is 0.2275
the 735 times test_loss is 0.4252
0.9248866691220257 0.924880894199447 0.8441558441558441 0.8778004073319755 0.7996289424860853 0.8368932038834951
the 736 times train_loss is 0.2282
the 736 times test_loss is 0.4166
0.9240674512341621 0.9238301832879735 0.8469387755102041 0.8541666666666666 0.8367346938775511 0.845360824742268
the 737 times train_loss is 0.2295
the 737 times test_loss is 0.4353
0.9254408459285215 0.9257000540059849 0.8441558441558441 0.8872651356993737 0.7884972170686456 0.8349705304518664
the 738 times train_loss is 0.2307
the 738 times test_loss is 0.4156
0.9220452222042468 0.9220263916096201 0.8460111317254174 0.849906191369606 0.8404452690166976 0.8451492537313433
the 739 times train_loss is 0.2316
the 739 times test_loss is 0.4284
0.9260535382984362 0.9276415718798865 0.8385899814471243 0.8762886597938144 0.7884972170686456 0.8300781249999999
the 740 times train_loss is 0.2324
the 740 times test_loss is 0.4204
0.9219161437555288 0.9222772833213995 0.8515769944341373 0.8665377176015474 0.8311688311688312 0.8484848484848485
the 741 times train_loss is 0.2284
the 741 times test_loss is 0.4136
0.9235442532553585 0.9236586425613162 0.8515769944341373 0.8637236084452975 0.8348794063079777 0.8490566037735849
the 742 times train_loss is 0.2286
the 742 times test_loss is 0.4263
0.9257953814010003 0.9262012188866235 0.8432282003710575 0.8854166666666666 0.7884972170686456 0.8341511285574092
the 743 times train_loss is 0.2306
the 743 times test_loss is 0.4073
0.9245631124772391 0.9245247992142082 0.8469387755102041 0.8624031007751938 0.8256029684601113 0.8436018957345971
the 744 times train_loss is 0.2280
the 744 times test_loss is 0.4140
0.9245837650290342 0.9250639264613741 0.8478664192949907 0.8669275929549902 0.8218923933209648 0.8438095238095238
the 745 times train_loss is 0.2269
the 745 times test_loss is 0.4254
0.9249383005015128 0.9255991562198672 0.8404452690166976 0.8722109533468559 0.7977736549165121 0.8333333333333334
the 746 times train_loss is 0.2283
the 746 times test_loss is 0.4156
0.92259767796476 0.9223226963878437 0.8413729128014842 0.857976653696498 0.8181818181818182 0.8376068376068376
the 747 times train_loss is 0.2281
the 747 times test_loss is 0.4244
0.923809294336726 0.9240706272904419 0.8404452690166976 0.8677354709418837 0.8033395176252319 0.8342967244701349
the 748 times train_loss is 0.2266
the 748 times test_loss is 0.4247
0.9253685619972395 0.9262650016994527 0.8413729128014842 0.8636363636363636 0.8107606679035251 0.8363636363636363
the 749 times train_loss is 0.2276
the 749 times test_loss is 0.4200
0.9230554761962131 0.9229167208840188 0.8515769944341373 0.8693957115009746 0.8274582560296846 0.8479087452471483
the 750 times train_loss is 0.2277
the 750 times test_loss is 0.4199
0.9243290502235639 0.9248396222786524 0.8432282003710575 0.8641732283464567 0.8144712430426716 0.8385864374403056
the 751 times train_loss is 0.2281
the 751 times test_loss is 0.4319
0.9219746593189477 0.9220971843734228 0.839517625231911 0.875 0.7922077922077922 0.8315481986368063
the 752 times train_loss is 0.2278
the 752 times test_loss is 0.4182
0.9233101910016832 0.9237802533358394 0.8441558441558441 0.8533333333333334 0.8311688311688312 0.8421052631578949
the 753 times train_loss is 0.2297
the 753 times test_loss is 0.4364
0.9252446466864701 0.9256642466275139 0.8413729128014842 0.8849372384937239 0.7847866419294991 0.8318584070796461
the 754 times train_loss is 0.2306
the 754 times test_loss is 0.4077
0.9246835856960426 0.9246890696269374 0.8460111317254174 0.8525519848771267 0.8367346938775511 0.8445692883895132
the 755 times train_loss is 0.2323
the 755 times test_loss is 0.4225
0.9234650851401447 0.9234052763640141 0.8413729128014842 0.8770491803278688 0.7940630797773655 0.8334956183057449
the 756 times train_loss is 0.2288
the 756 times test_loss is 0.4233
0.923311912047666 0.9241057504398692 0.8413729128014842 0.8636363636363636 0.8107606679035251 0.8363636363636363
the 757 times train_loss is 0.2281
the 757 times test_loss is 0.4160
0.9241844823609997 0.9250367520719853 0.8460111317254174 0.859344894026975 0.8274582560296846 0.8431001890359169
the 758 times train_loss is 0.2282
the 758 times test_loss is 0.4277
0.9228110876666402 0.9228681749135913 0.8423005565862709 0.8757637474541752 0.7977736549165121 0.8349514563106797
the 759 times train_loss is 0.2309
the 759 times test_loss is 0.4181
0.9243462606833929 0.9247601072641009 0.8487940630797773 0.8745019920318725 0.8144712430426716 0.8434197886647453
the 760 times train_loss is 0.2270
the 760 times test_loss is 0.4209
0.9243841236950169 0.9251020960451637 0.8441558441558441 0.8615984405458089 0.8200371057513914 0.8403041825095056
the 761 times train_loss is 0.2283
the 761 times test_loss is 0.4280
0.9225150677575803 0.9225975449325199 0.8460111317254174 0.8752515090543259 0.8070500927643784 0.8397683397683396
the 762 times train_loss is 0.2306
the 762 times test_loss is 0.4067
0.9252515308704017 0.925012104515724 0.8450834879406308 0.859073359073359 0.8256029684601113 0.8420056764427625
the 763 times train_loss is 0.2303
the 763 times test_loss is 0.4181
0.9241707139931366 0.9240537072205662 0.8460111317254174 0.8678500986193294 0.8163265306122449 0.8413001912045889
the 764 times train_loss is 0.2278
the 764 times test_loss is 0.4265
0.9238884624519398 0.9245072289922536 0.8367346938775511 0.8711656441717791 0.7903525046382189 0.8287937743190661
the 765 times train_loss is 0.2288
the 765 times test_loss is 0.4136
0.9241741560851023 0.9242679254198051 0.8469387755102041 0.8596153846153847 0.8293135435992579 0.8441926345609065
the 766 times train_loss is 0.2287
the 766 times test_loss is 0.4210
0.9244185446146751 0.9243733467808202 0.8469387755102041 0.8770161290322581 0.8070500927643784 0.8405797101449274
the 767 times train_loss is 0.2273
the 767 times test_loss is 0.4225
0.9219918697787768 0.9220975822643341 0.8432282003710575 0.8641732283464567 0.8144712430426716 0.8385864374403056
the 768 times train_loss is 0.2285
the 768 times test_loss is 0.4232
0.9255509928714276 0.9267280461035226 0.8404452690166976 0.8737270875763747 0.7959183673469388 0.8330097087378641
the 769 times train_loss is 0.2305
the 769 times test_loss is 0.4215
0.9209730105568961 0.9209898112795953 0.8450834879406308 0.848314606741573 0.8404452690166976 0.8443616029822926
the 770 times train_loss is 0.2330
the 770 times test_loss is 0.4332
0.9260225594707439 0.9265763961104881 0.839517625231911 0.878099173553719 0.7884972170686456 0.8308895405669598
the 771 times train_loss is 0.2352
the 771 times test_loss is 0.4095
0.9244460813504015 0.9244056885913483 0.8515769944341373 0.8623326959847036 0.8367346938775511 0.8493408662900188
the 772 times train_loss is 0.2299
the 772 times test_loss is 0.4144
0.9215719345589476 0.9215976148014019 0.8450834879406308 0.8576923076923076 0.8274582560296846 0.8423040604343719
the 773 times train_loss is 0.2320
the 773 times test_loss is 0.4252
0.9262841584601457 0.9282971267150596 0.8385899814471243 0.8732106339468303 0.7922077922077922 0.830739299610895
the 774 times train_loss is 0.2363
the 774 times test_loss is 0.4084
0.9223360789753581 0.9224961891799424 0.8478664192949907 0.8598848368522073 0.8311688311688312 0.8452830188679245
the 775 times train_loss is 0.2301
the 775 times test_loss is 0.4126
0.9215409557312553 0.9215040719392767 0.8450834879406308 0.8576923076923076 0.8274582560296846 0.8423040604343719
the 776 times train_loss is 0.2339
the 776 times test_loss is 0.4231
0.9268761982782656 0.9284396448887045 0.8376623376623377 0.8744855967078189 0.7884972170686456 0.8292682926829269
the 777 times train_loss is 0.2363
the 777 times test_loss is 0.4120
0.9251413839274958 0.9254003232427276 0.8441558441558441 0.8732394366197183 0.8051948051948052 0.8378378378378378
the 778 times train_loss is 0.2284
the 778 times test_loss is 0.4105
0.921620123846469 0.9212746469719235 0.8423005565862709 0.8514285714285714 0.8293135435992579 0.8402255639097743
the 779 times train_loss is 0.2347
the 779 times test_loss is 0.4223
0.9253410252615129 0.9259188415178357 0.8404452690166976 0.8767967145790554 0.7922077922077922 0.8323586744639375
the 780 times train_loss is 0.2301
the 780 times test_loss is 0.3965
0.9279294784198046 0.9290939167119736 0.8478664192949907 0.8654970760233918 0.8237476808905381 0.844106463878327
the 781 times train_loss is 0.2355
the 781 times test_loss is 0.4176
0.9228558348621958 0.9225328636926691 0.8385899814471243 0.8825995807127882 0.7810760667903525 0.8287401574803149
the 782 times train_loss is 0.2374
the 782 times test_loss is 0.4107
0.9227560141951873 0.9237541009571193 0.8385899814471243 0.8476190476190476 0.8256029684601113 0.8364661654135339
the 783 times train_loss is 0.2357
the 783 times test_loss is 0.4181
0.9261395905975816 0.9284072453517456 0.8432282003710575 0.8627450980392157 0.8163265306122449 0.8388941849380362
the 784 times train_loss is 0.2362
the 784 times test_loss is 0.4223
0.9247386591674956 0.9255694051776665 0.8423005565862709 0.888421052631579 0.7829313543599258 0.8323471400394478
the 785 times train_loss is 0.2378
the 785 times test_loss is 0.4006
0.922669961896042 0.9227575376759827 0.8450834879406308 0.8522727272727273 0.8348794063079777 0.8434864104967198
the 786 times train_loss is 0.2339
the 786 times test_loss is 0.4033
0.9255544349633935 0.9262921140555441 0.8478664192949907 0.8626692456479691 0.8274582560296846 0.8446969696969698
the 787 times train_loss is 0.2327
the 787 times test_loss is 0.4018
0.9285215182379243 0.9291404211193 0.8460111317254174 0.879837067209776 0.8014842300556586 0.8388349514563107
the 788 times train_loss is 0.2311
the 788 times test_loss is 0.3965
0.9273890699811718 0.9271638925162095 0.849721706864564 0.8823529411764706 0.8070500927643784 0.8430232558139534
the 789 times train_loss is 0.2316
the 789 times test_loss is 0.4052
0.9229418871613411 0.9221910259487376 0.8460111317254174 0.8664047151277013 0.8181818181818182 0.8416030534351144
the 790 times train_loss is 0.2298
the 790 times test_loss is 0.4142
0.9231793915069824 0.9233310214487029 0.8487940630797773 0.8657587548638133 0.8256029684601113 0.8452041785375118
the 791 times train_loss is 0.2299
the 791 times test_loss is 0.4105
0.9266249255647613 0.9270500760141194 0.8515769944341373 0.8722986247544204 0.8237476808905381 0.8473282442748091
the 792 times train_loss is 0.2292
the 792 times test_loss is 0.4037
0.9280155307189497 0.9276507799455986 0.8534322820037106 0.8832997987927566 0.8144712430426716 0.8474903474903476
the 793 times train_loss is 0.2304
the 793 times test_loss is 0.4019
0.9260500962064706 0.9258440211538773 0.852504638218924 0.8725490196078431 0.8256029684601113 0.8484270734032412
the 794 times train_loss is 0.2275
the 794 times test_loss is 0.4200
0.9227388037353581 0.9231200745712711 0.8432282003710575 0.8685258964143426 0.8089053803339518 0.8376560999039385
the 795 times train_loss is 0.2294
the 795 times test_loss is 0.4150
0.9226320988844179 0.9224833081684615 0.8404452690166976 0.8563106796116505 0.8181818181818182 0.8368121442125238
the 796 times train_loss is 0.2275
the 796 times test_loss is 0.4134
0.9249830476970683 0.9242121854033989 0.8487940630797773 0.8790322580645161 0.8089053803339518 0.842512077294686
the 797 times train_loss is 0.2280
the 797 times test_loss is 0.4108
0.926738514599633 0.9270102431772985 0.8460111317254174 0.8621359223300971 0.8237476808905381 0.842504743833017
the 798 times train_loss is 0.2278
the 798 times test_loss is 0.4267
0.9240295882225381 0.9242570026759066 0.8450834879406308 0.872 0.8089053803339518 0.8392685274302214
the 799 times train_loss is 0.2281
the 799 times test_loss is 0.4215
0.9211898623507423 0.9211427449322782 0.8367346938775511 0.847036328871893 0.8218923933209648 0.8342749529190207
the 800 times train_loss is 0.2288
the 800 times test_loss is 0.4302
0.9230898971158712 0.9226590201529749 0.8404452690166976 0.8767967145790554 0.7922077922077922 0.8323586744639375
the 801 times train_loss is 0.2292
the 801 times test_loss is 0.4126
0.9251826890310855 0.9254176152677049 0.8469387755102041 0.865234375 0.8218923933209648 0.8430066603235015
the 802 times train_loss is 0.2267
the 802 times test_loss is 0.4114
0.9253479094454445 0.9260630453577199 0.8506493506493507 0.8662790697674418 0.8293135435992579 0.84739336492891
the 803 times train_loss is 0.2272
the 803 times test_loss is 0.4203
0.9244391971664698 0.9251960782098894 0.8432282003710575 0.8760162601626016 0.7996289424860853 0.8360814742967991
the 804 times train_loss is 0.2277
the 804 times test_loss is 0.4183
0.9235924425428799 0.9240872728962113 0.8441558441558441 0.8702594810379242 0.8089053803339518 0.8384615384615385
the 805 times train_loss is 0.2259
the 805 times test_loss is 0.4248
0.9226906144478367 0.9230209908705207 0.8385899814471243 0.8599605522682445 0.8089053803339518 0.8336520076481837
the 806 times train_loss is 0.2266
the 806 times test_loss is 0.4398
0.9219987539627084 0.9218572794225977 0.8385899814471243 0.8686868686868687 0.7977736549165121 0.8317214700193424
the 807 times train_loss is 0.2275
the 807 times test_loss is 0.4272
0.922484088929888 0.922368933305859 0.8413729128014842 0.8552123552123552 0.8218923933209648 0.8382213812677388
the 808 times train_loss is 0.2263
the 808 times test_loss is 0.4212
0.9242670925681792 0.9245065404550581 0.8404452690166976 0.8633663366336634 0.8089053803339518 0.8352490421455938
the 809 times train_loss is 0.2259
the 809 times test_loss is 0.4300
0.9239366517394613 0.9241669371009258 0.8385899814471243 0.8716904276985743 0.7940630797773655 0.8310679611650484
the 810 times train_loss is 0.2270
the 810 times test_loss is 0.4255
0.9228214139425377 0.9229587357815485 0.8460111317254174 0.8621359223300971 0.8237476808905381 0.842504743833017
the 811 times train_loss is 0.2257
the 811 times test_loss is 0.4312
0.9215134189955287 0.9215812052342371 0.8441558441558441 0.8615984405458089 0.8200371057513914 0.8403041825095056
the 812 times train_loss is 0.2256
the 812 times test_loss is 0.4382
0.921620123846469 0.9216573684286575 0.8413729128014842 0.8739837398373984 0.7977736549165121 0.834141610087294
the 813 times train_loss is 0.2260
the 813 times test_loss is 0.4283
0.9229418871613412 0.9234708579525525 0.8460111317254174 0.8678500986193294 0.8163265306122449 0.8413001912045889
the 814 times train_loss is 0.2256
the 814 times test_loss is 0.4304
0.922814529758606 0.9233424180335228 0.8450834879406308 0.8661417322834646 0.8163265306122449 0.8404966571155683
the 815 times train_loss is 0.2251
the 815 times test_loss is 0.4359
0.922356731527153 0.9226412741034417 0.8432282003710575 0.87 0.8070500927643784 0.8373435996150144
the 816 times train_loss is 0.2254
the 816 times test_loss is 0.4299
0.9223980366307427 0.9225852553344115 0.8413729128014842 0.8636363636363636 0.8107606679035251 0.8363636363636363
the 817 times train_loss is 0.2253
the 817 times test_loss is 0.4349
0.9218713965599732 0.922010471148157 0.8404452690166976 0.8648111332007953 0.8070500927643784 0.8349328214971209
the 818 times train_loss is 0.2248
the 818 times test_loss is 0.4394
0.9213516406731355 0.9218141328662017 0.8385899814471243 0.8672032193158954 0.7996289424860853 0.8320463320463322
the 819 times train_loss is 0.2249
the 819 times test_loss is 0.4359
0.9216029133866399 0.9222151195133144 0.8441558441558441 0.8658777120315582 0.8144712430426716 0.8393881453154874
the 820 times train_loss is 0.2249
the 820 times test_loss is 0.4383
0.92170961823758 0.9222083383920884 0.8423005565862709 0.8697394789579158 0.8051948051948052 0.8362235067437379
the 821 times train_loss is 0.2246
the 821 times test_loss is 0.4412
0.9214135983285202 0.9219010088553303 0.8413729128014842 0.8694779116465864 0.8033395176252319 0.8351012536162007
the 822 times train_loss is 0.2246
the 822 times test_loss is 0.4389
0.9212724725579217 0.9218307324102546 0.8432282003710575 0.8641732283464567 0.8144712430426716 0.8385864374403056
the 823 times train_loss is 0.2248
the 823 times test_loss is 0.4424
0.9211554414310841 0.9217213255886842 0.8413729128014842 0.8694779116465864 0.8033395176252319 0.8351012536162007
the 824 times train_loss is 0.2245
the 824 times test_loss is 0.4407
0.9214996506276655 0.9218822089597281 0.8413729128014842 0.868 0.8051948051948052 0.8354186717998076
the 825 times train_loss is 0.2244
the 825 times test_loss is 0.4407
0.9215650503750161 0.9220189623467286 0.8441558441558441 0.8644400785854617 0.8163265306122449 0.8396946564885495
the 826 times train_loss is 0.2244
the 826 times test_loss is 0.4454
0.9212001886266398 0.9216118490502707 0.8404452690166976 0.8677354709418837 0.8033395176252319 0.8342967244701349
the 827 times train_loss is 0.2244
the 827 times test_loss is 0.4421
0.9209695684649302 0.9215290810105564 0.8413729128014842 0.8650793650793651 0.8089053803339518 0.8360498561840845
the 828 times train_loss is 0.2243
the 828 times test_loss is 0.4440
0.9204876755897163 0.9211959573197592 0.8413729128014842 0.868 0.8051948051948052 0.8354186717998076
the 829 times train_loss is 0.2242
the 829 times test_loss is 0.4446
0.9210246419363832 0.9217844959707734 0.8404452690166976 0.8677354709418837 0.8033395176252319 0.8342967244701349
the 830 times train_loss is 0.2242
the 830 times test_loss is 0.4431
0.9212483779141609 0.9220531375623754 0.8423005565862709 0.8653465346534653 0.8107606679035251 0.8371647509578545
the 831 times train_loss is 0.2242
the 831 times test_loss is 0.4472
0.9202742658878361 0.9210555886535478 0.8404452690166976 0.8662674650698603 0.8051948051948052 0.8346153846153846
the 832 times train_loss is 0.2242
the 832 times test_loss is 0.4456
0.9203293393592891 0.9212586082765652 0.8404452690166976 0.8619329388560157 0.8107606679035251 0.8355640535372849
the 833 times train_loss is 0.2241
the 833 times test_loss is 0.4489
0.9206873169237336 0.9216224339402208 0.8413729128014842 0.8694779116465864 0.8033395176252319 0.8351012536162007
the 834 times train_loss is 0.2240
the 834 times test_loss is 0.4473
0.9208284426943318 0.9215818426253019 0.8404452690166976 0.8662674650698603 0.8051948051948052 0.8346153846153846
the 835 times train_loss is 0.2239
the 835 times test_loss is 0.4471
0.9208043480505713 0.9215628415627357 0.8423005565862709 0.8667992047713717 0.8089053803339518 0.836852207293666
the 836 times train_loss is 0.2239
the 836 times test_loss is 0.4507
0.920332781451255 0.9212250264974149 0.839517625231911 0.8674698795180723 0.8014842300556586 0.8331726133076183
the 837 times train_loss is 0.2239
the 837 times test_loss is 0.4480
0.9200677403698873 0.9211171247506879 0.839517625231911 0.8616600790513834 0.8089053803339518 0.8344497607655502
the 838 times train_loss is 0.2240
the 838 times test_loss is 0.4531
0.9197132048974086 0.9206721749139943 0.8385899814471243 0.8672032193158954 0.7996289424860853 0.8320463320463322
the 839 times train_loss is 0.2241
the 839 times test_loss is 0.4472
0.9203052447155284 0.921309883256642 0.8432282003710575 0.8670634920634921 0.8107606679035251 0.837967401725791
the 840 times train_loss is 0.2241
the 840 times test_loss is 0.4529
0.9200298773582632 0.921085105536869 0.8385899814471243 0.8672032193158954 0.7996289424860853 0.8320463320463322
the 841 times train_loss is 0.2240
the 841 times test_loss is 0.4482
0.9199025199555282 0.920979407086444 0.8413729128014842 0.8636363636363636 0.8107606679035251 0.8363636363636363
the 842 times train_loss is 0.2238
the 842 times test_loss is 0.4519
0.9199162883233913 0.9209613818112469 0.8385899814471243 0.8672032193158954 0.7996289424860853 0.8320463320463322
the 843 times train_loss is 0.2236
the 843 times test_loss is 0.4515
0.9200092248064683 0.9210676943767582 0.8404452690166976 0.8677354709418837 0.8033395176252319 0.8342967244701349
the 844 times train_loss is 0.2236
the 844 times test_loss is 0.4521
0.9199575934269812 0.9210495233770238 0.839517625231911 0.8674698795180723 0.8014842300556586 0.8331726133076183
the 845 times train_loss is 0.2235
the 845 times test_loss is 0.4542
0.9195273319312545 0.9206444045469947 0.8385899814471243 0.8672032193158954 0.7996289424860853 0.8320463320463322
the 846 times train_loss is 0.2236
the 846 times test_loss is 0.4515
0.9197166469893743 0.9208493029489475 0.839517625231911 0.8630952380952381 0.8070500927643784 0.8341323106423777
the 847 times train_loss is 0.2237
the 847 times test_loss is 0.4574
0.9193586694249298 0.9204334777357353 0.839517625231911 0.8689516129032258 0.7996289424860853 0.8328502415458937
the 848 times train_loss is 0.2241
the 848 times test_loss is 0.4477
0.9198749832198017 0.9208654775613418 0.8404452690166976 0.8619329388560157 0.8107606679035251 0.8355640535372849
the 849 times train_loss is 0.2245
the 849 times test_loss is 0.4595
0.9193242485052716 0.9204716011689348 0.8367346938775511 0.869653767820774 0.7922077922077922 0.8291262135922332
the 850 times train_loss is 0.2249
the 850 times test_loss is 0.4473
0.9194929110115964 0.9206666966514934 0.8413729128014842 0.857976653696498 0.8181818181818182 0.8376068376068376
the 851 times train_loss is 0.2249
the 851 times test_loss is 0.4576
0.9200264352662975 0.9209392605055109 0.8358070500927643 0.8709016393442623 0.7884972170686456 0.8276533592989289
the 852 times train_loss is 0.2247
the 852 times test_loss is 0.4474
0.9195583107589468 0.9205965762749195 0.8432282003710575 0.8599221789883269 0.8200371057513914 0.8395061728395062
the 853 times train_loss is 0.2241
the 853 times test_loss is 0.4518
0.9204257179343318 0.9216653414052428 0.8404452690166976 0.8707070707070707 0.7996289424860853 0.8336557059961315
the 854 times train_loss is 0.2237
the 854 times test_loss is 0.4519
0.9191865648266391 0.9205026198528643 0.839517625231911 0.8674698795180723 0.8014842300556586 0.8331726133076183
the 855 times train_loss is 0.2235
the 855 times test_loss is 0.4482
0.9194516059080067 0.920485447925106 0.8423005565862709 0.8667992047713717 0.8089053803339518 0.836852207293666
the 856 times train_loss is 0.2236
the 856 times test_loss is 0.4565
0.9201641189449299 0.9211414776114597 0.839517625231911 0.8734693877551021 0.7940630797773655 0.8318756073858115
the 857 times train_loss is 0.2240
the 857 times test_loss is 0.4476
0.9195479844830494 0.9206257170780037 0.8423005565862709 0.8596491228070176 0.8181818181818182 0.838403041825095
the 858 times train_loss is 0.2243
the 858 times test_loss is 0.4558
0.9203637602789472 0.9212227084708329 0.8376623376623377 0.8744855967078189 0.7884972170686456 0.8292682926829269
the 859 times train_loss is 0.2243
the 859 times test_loss is 0.4486
0.9194516059080067 0.9205563705355598 0.8404452690166976 0.8576998050682261 0.8163265306122449 0.8365019011406843
the 860 times train_loss is 0.2240
the 860 times test_loss is 0.4548
0.920332781451255 0.9213327946664444 0.8413729128014842 0.8739837398373984 0.7977736549165121 0.834141610087294
the 861 times train_loss is 0.2236
the 861 times test_loss is 0.4502
0.9193208064133057 0.9203890231364164 0.8432282003710575 0.8670634920634921 0.8107606679035251 0.837967401725791
the 862 times train_loss is 0.2232
the 862 times test_loss is 0.4521
0.9195445423910835 0.9207865153818566 0.8385899814471243 0.8672032193158954 0.7996289424860853 0.8320463320463322
the 863 times train_loss is 0.2231
the 863 times test_loss is 0.4549
0.9198302360242461 0.9210313373415907 0.8367346938775511 0.8681541582150102 0.7940630797773655 0.8294573643410853
the 864 times train_loss is 0.2232
the 864 times test_loss is 0.4509
0.9192554066659552 0.9202761678179693 0.8432282003710575 0.8656126482213439 0.8126159554730983 0.8382775119617224
the 865 times train_loss is 0.2234
the 865 times test_loss is 0.4604
0.9194860268276648 0.9205157388447225 0.8376623376623377 0.8729508196721312 0.7903525046382189 0.8296007789678675
the 866 times train_loss is 0.2238
the 866 times test_loss is 0.4501
0.9192691750338187 0.9205083350931274 0.8441558441558441 0.863013698630137 0.8181818181818182 0.8400000000000001
the 867 times train_loss is 0.2243
the 867 times test_loss is 0.4618
0.9190523232399723 0.9201029866888351 0.8376623376623377 0.8714285714285714 0.7922077922077922 0.8299319727891157
the 868 times train_loss is 0.2254
the 868 times test_loss is 0.4432
0.9198026992885197 0.9209003370569295 0.8385899814471243 0.8557504873294347 0.8144712430426716 0.8346007604562737
the 869 times train_loss is 0.2262
the 869 times test_loss is 0.4574
0.9193552273329639 0.9206457749661101 0.8358070500927643 0.8678861788617886 0.7922077922077922 0.8283220174587779
the 870 times train_loss is 0.2249
the 870 times test_loss is 0.4487
0.9199472671510838 0.9210741447884787 0.8432282003710575 0.8685258964143426 0.8089053803339518 0.8376560999039385
the 871 times train_loss is 0.2236
the 871 times test_loss is 0.4484
0.9203327814512549 0.9214771302795055 0.8367346938775511 0.8637274549098196 0.7996289424860853 0.8304431599229286
the 872 times train_loss is 0.2245
the 872 times test_loss is 0.4576
0.9179302012591172 0.9193965620823081 0.8376623376623377 0.864 0.8014842300556586 0.8315688161693936
the 873 times train_loss is 0.2258
the 873 times test_loss is 0.4465
0.9204911176816821 0.9214945475586458 0.8441558441558441 0.8732394366197183 0.8051948051948052 0.8378378378378378
the 874 times train_loss is 0.2240
the 874 times test_loss is 0.4482
0.92075615876305 0.9219776610296403 0.8423005565862709 0.863905325443787 0.8126159554730983 0.8374760994263862
the 875 times train_loss is 0.2235
the 875 times test_loss is 0.4561
0.918783840066639 0.9196768206477469 0.8376623376623377 0.8654618473895582 0.7996289424860853 0.8312439729990356
the 876 times train_loss is 0.2249
the 876 times test_loss is 0.4426
0.9192691750338186 0.9199239254055502 0.8423005565862709 0.8697394789579158 0.8051948051948052 0.8362235067437379
the 877 times train_loss is 0.2242
the 877 times test_loss is 0.4451
0.921713060329546 0.9228905528545194 0.8404452690166976 0.8677354709418837 0.8033395176252319 0.8342967244701349
the 878 times train_loss is 0.2234
the 878 times test_loss is 0.4497
0.9204119495664685 0.9214755168676588 0.8423005565862709 0.8697394789579158 0.8051948051948052 0.8362235067437379
the 879 times train_loss is 0.2240
the 879 times test_loss is 0.4399
0.9197992571965538 0.9198572279171754 0.839517625231911 0.8630952380952381 0.8070500927643784 0.8341323106423777
the 880 times train_loss is 0.2247
the 880 times test_loss is 0.4438
0.9209661263729645 0.9217135621539025 0.8413729128014842 0.868 0.8051948051948052 0.8354186717998076
the 881 times train_loss is 0.2228
the 881 times test_loss is 0.4478
0.9217405970652726 0.9227765249061566 0.8423005565862709 0.8697394789579158 0.8051948051948052 0.8362235067437379
the 882 times train_loss is 0.2241
the 882 times test_loss is 0.4388
0.9204670230379215 0.9208306413124184 0.8413729128014842 0.8665338645418327 0.8070500927643784 0.8357348703170029
the 883 times train_loss is 0.2242
the 883 times test_loss is 0.4472
0.9198233518403146 0.9202066501543946 0.8367346938775511 0.8637274549098196 0.7996289424860853 0.8304431599229286
the 884 times train_loss is 0.2234
the 884 times test_loss is 0.4486
0.9210039893845884 0.9220866332062098 0.8441558441558441 0.8687872763419483 0.8107606679035251 0.8387715930902112
the 885 times train_loss is 0.2236
the 885 times test_loss is 0.4431
0.921269030465956 0.9219410182141514 0.839517625231911 0.8704453441295547 0.7977736549165121 0.8325266214908035
the 886 times train_loss is 0.2241
the 886 times test_loss is 0.4487
0.9182881788235617 0.9189132219366597 0.839517625231911 0.8616600790513834 0.8089053803339518 0.8344497607655502
the 887 times train_loss is 0.2244
the 887 times test_loss is 0.4560
0.9217681338009989 0.9225432955972922 0.8358070500927643 0.8755186721991701 0.7829313543599258 0.8266405484818805
the 888 times train_loss is 0.2260
the 888 times test_loss is 0.4435
0.9198440043921093 0.9210038593376412 0.8423005565862709 0.8410351201478743 0.8441558441558441 0.8425925925925926
the 889 times train_loss is 0.2335
the 889 times test_loss is 0.4733
0.9216476605821954 0.9214683981020255 0.8246753246753247 0.8959276018099548 0.7346938775510204 0.8073394495412844
the 890 times train_loss is 0.2443
the 890 times test_loss is 0.4344
0.9193689957008272 0.9202137305179877 0.8358070500927643 0.8278985507246377 0.8478664192949907 0.8377635197066912
the 891 times train_loss is 0.2453
the 891 times test_loss is 0.4180
0.925709329101855 0.929072759969165 0.8413729128014842 0.8650793650793651 0.8089053803339518 0.8360498561840845
the 892 times train_loss is 0.2433
the 892 times test_loss is 0.4449
0.9211072521435628 0.923501720512401 0.8330241187384044 0.8893709327548807 0.7606679035250464 0.8200000000000001
the 893 times train_loss is 0.2458
the 893 times test_loss is 0.4113
0.9210005472926224 0.9219904028312049 0.8515769944341373 0.8528864059590316 0.849721706864564 0.8513011152416358
the 894 times train_loss is 0.2403
the 894 times test_loss is 0.4140
0.9190385548721091 0.9203680624178268 0.8348794063079777 0.839924670433145 0.8274582560296846 0.8336448598130841
the 895 times train_loss is 0.2384
the 895 times test_loss is 0.4154
0.9236681685661277 0.9257927035930408 0.8376623376623377 0.8669354838709677 0.7977736549165121 0.8309178743961352
the 896 times train_loss is 0.2381
the 896 times test_loss is 0.4014
0.9261740115172397 0.9269821847821204 0.8358070500927643 0.8739669421487604 0.7847866419294991 0.8269794721407624
the 897 times train_loss is 0.2364
the 897 times test_loss is 0.3889
0.9274441434526248 0.9275009075564734 0.8506493506493507 0.8720472440944882 0.8218923933209648 0.8462273161413563
the 898 times train_loss is 0.2356
the 898 times test_loss is 0.3900
0.9263770949432226 0.9261154719830453 0.8506493506493507 0.8593155893536122 0.8385899814471243 0.8488262910798122
the 899 times train_loss is 0.2338
the 899 times test_loss is 0.4124
0.9228558348621958 0.9225245696641965 0.8469387755102041 0.8695652173913043 0.8163265306122449 0.8421052631578948
the 900 times train_loss is 0.2371
the 900 times test_loss is 0.3927
0.9263013689199748 0.9253618629673173 0.8515769944341373 0.8679611650485437 0.8293135435992579 0.8481973434535105
the 901 times train_loss is 0.2298
the 901 times test_loss is 0.3813
0.9304490897387795 0.9298123915548419 0.8515769944341373 0.8693957115009746 0.8274582560296846 0.8479087452471483
the 902 times train_loss is 0.2308
the 902 times test_loss is 0.3824
0.9309929402693782 0.9304026856826493 0.8515769944341373 0.8767395626242545 0.8181818181818182 0.8464491362763915
the 903 times train_loss is 0.2330
the 903 times test_loss is 0.3892
0.928876053710403 0.9285738590069184 0.8487940630797773 0.876 0.8126159554730983 0.8431183830606351
the 904 times train_loss is 0.2294
the 904 times test_loss is 0.3960
0.924952068869376 0.9246052813318876 0.852504638218924 0.8682170542635659 0.8311688311688312 0.8492890995260663
the 905 times train_loss is 0.2299
the 905 times test_loss is 0.4010
0.9228282981264694 0.9222093818890854 0.8469387755102041 0.8638132295719845 0.8237476808905381 0.8433048433048433
the 906 times train_loss is 0.2304
the 906 times test_loss is 0.3949
0.925891759976043 0.925042936459277 0.8478664192949907 0.8683693516699411 0.8200371057513914 0.8435114503816794
the 907 times train_loss is 0.2274
the 907 times test_loss is 0.3923
0.9294990723562153 0.928859466926988 0.849721706864564 0.8717948717948718 0.8200371057513914 0.8451242829827916
the 908 times train_loss is 0.2288
the 908 times test_loss is 0.3994
0.9282805718003173 0.9272264081629573 0.8478664192949907 0.875751503006012 0.8107606679035251 0.8420038535645472
the 909 times train_loss is 0.2294
the 909 times test_loss is 0.3990
0.9266421360245902 0.9255443970235804 0.8506493506493507 0.8606870229007634 0.8367346938775511 0.8485418626528692
the 910 times train_loss is 0.2278
the 910 times test_loss is 0.4045
0.9246801436040768 0.9240063011536169 0.8460111317254174 0.8621359223300971 0.8237476808905381 0.842504743833017
the 911 times train_loss is 0.2271
the 911 times test_loss is 0.4086
0.9246147438567263 0.9241919707277418 0.8432282003710575 0.87 0.8070500927643784 0.8373435996150144
the 912 times train_loss is 0.2275
the 912 times test_loss is 0.4028
0.9252962780659574 0.9251534715936374 0.8478664192949907 0.8669275929549902 0.8218923933209648 0.8438095238095238
the 913 times train_loss is 0.2263
the 913 times test_loss is 0.4066
0.925155152295359 0.9252768949211274 0.8460111317254174 0.8635477582846004 0.8218923933209648 0.8422053231939163
the 914 times train_loss is 0.2262
the 914 times test_loss is 0.4152
0.9255165719517694 0.9255958261280683 0.8478664192949907 0.8712871287128713 0.8163265306122449 0.842911877394636
the 915 times train_loss is 0.2264
the 915 times test_loss is 0.4187
0.9253720040892053 0.925264745685076 0.8469387755102041 0.8695652173913043 0.8163265306122449 0.8421052631578948
the 916 times train_loss is 0.2257
the 916 times test_loss is 0.4243
0.9230692445640762 0.9228388027068221 0.8469387755102041 0.8666666666666667 0.8200371057513914 0.8427073403241183
the 917 times train_loss is 0.2252
the 917 times test_loss is 0.4314
0.9215375136392894 0.9215627422718409 0.8423005565862709 0.8653465346534653 0.8107606679035251 0.8371647509578545
the 918 times train_loss is 0.2254
the 918 times test_loss is 0.4319
0.9223464052512556 0.9224417662089426 0.8348794063079777 0.8588469184890656 0.8014842300556586 0.8291746641074854
the 919 times train_loss is 0.2248
the 919 times test_loss is 0.4288
0.9230692445640762 0.9230611388494332 0.8432282003710575 0.8685258964143426 0.8089053803339518 0.8376560999039385
the 920 times train_loss is 0.2250
the 920 times test_loss is 0.4277
0.9225701412290334 0.9225323190779556 0.8423005565862709 0.863905325443787 0.8126159554730983 0.8374760994263862
the 921 times train_loss is 0.2247
the 921 times test_loss is 0.4311
0.9219471225832212 0.9225616896695253 0.8441558441558441 0.8644400785854617 0.8163265306122449 0.8396946564885495
the 922 times train_loss is 0.2241
the 922 times test_loss is 0.4381
0.9210418523962123 0.9222002281186765 0.8423005565862709 0.8653465346534653 0.8107606679035251 0.8371647509578545
the 923 times train_loss is 0.2244
the 923 times test_loss is 0.4411
0.9201675610368957 0.921206513480511 0.8423005565862709 0.8712273641851107 0.8033395176252319 0.8359073359073359
the 924 times train_loss is 0.2240
the 924 times test_loss is 0.4380
0.9207458324871525 0.9214226121104071 0.8441558441558441 0.8687872763419483 0.8107606679035251 0.8387715930902112
the 925 times train_loss is 0.2240
the 925 times test_loss is 0.4398
0.9220744799859562 0.9227650528760657 0.8413729128014842 0.8665338645418327 0.8070500927643784 0.8357348703170029
the 926 times train_loss is 0.2237
the 926 times test_loss is 0.4456
0.9220400590662982 0.9229611724208043 0.8413729128014842 0.8665338645418327 0.8070500927643784 0.8357348703170029
the 927 times train_loss is 0.2237
the 927 times test_loss is 0.4473
0.9202329607842462 0.9211694227190024 0.8413729128014842 0.8650793650793651 0.8089053803339518 0.8360498561840845
the 928 times train_loss is 0.2235
the 928 times test_loss is 0.4510
0.918871613411767 0.9196858227007645 0.8413729128014842 0.868 0.8051948051948052 0.8354186717998076
the 929 times train_loss is 0.2235
the 929 times test_loss is 0.4540
0.919592731678605 0.920630922627476 0.8404452690166976 0.869215291750503 0.8014842300556586 0.8339768339768339
the 930 times train_loss is 0.2233
the 930 times test_loss is 0.4515
0.9206012646245882 0.9218137683940302 0.8432282003710575 0.8670634920634921 0.8107606679035251 0.837967401725791
the 931 times train_loss is 0.2233
the 931 times test_loss is 0.4504
0.9201021612895454 0.9212519228948811 0.8423005565862709 0.8667992047713717 0.8089053803339518 0.836852207293666
the 932 times train_loss is 0.2231
the 932 times test_loss is 0.4497
0.9192519645739895 0.9204688178811052 0.8423005565862709 0.8667992047713717 0.8089053803339518 0.836852207293666
the 933 times train_loss is 0.2231
the 933 times test_loss is 0.4536
0.9186530405719379 0.9200921302432757 0.8423005565862709 0.8667992047713717 0.8089053803339518 0.836852207293666
the 934 times train_loss is 0.2230
the 934 times test_loss is 0.4542
0.9193139222293741 0.9206948857883862 0.8423005565862709 0.8667992047713717 0.8089053803339518 0.836852207293666
the 935 times train_loss is 0.2228
the 935 times test_loss is 0.4535
0.919795815104588 0.9208209963545284 0.8432282003710575 0.8685258964143426 0.8089053803339518 0.8376560999039385
the 936 times train_loss is 0.2228
the 936 times test_loss is 0.4573
0.9192691750338184 0.9204251289745814 0.8404452690166976 0.8648111332007953 0.8070500927643784 0.8349328214971209
the 937 times train_loss is 0.2229
the 937 times test_loss is 0.4571
0.9190815810216817 0.9204068154053856 0.8432282003710575 0.8670634920634921 0.8107606679035251 0.837967401725791
the 938 times train_loss is 0.2228
the 938 times test_loss is 0.4604
0.9182950630074935 0.919590204945935 0.8358070500927643 0.8663967611336032 0.7940630797773655 0.8286544046466601
the 939 times train_loss is 0.2228
the 939 times test_loss is 0.4543
0.9191177229873229 0.920486094476904 0.8432282003710575 0.8656126482213439 0.8126159554730983 0.8382775119617224
the 940 times train_loss is 0.2228
the 940 times test_loss is 0.4587
0.9193552273329639 0.9207838683709433 0.839517625231911 0.8674698795180723 0.8014842300556586 0.8331726133076183
the 941 times train_loss is 0.2229
the 941 times test_loss is 0.4532
0.9199197304153572 0.9212487492816926 0.8432282003710575 0.8670634920634921 0.8107606679035251 0.837967401725791
the 942 times train_loss is 0.2227
the 942 times test_loss is 0.4580
0.9187494191469808 0.9201564337356083 0.8432282003710575 0.8685258964143426 0.8089053803339518 0.8376560999039385
the 943 times train_loss is 0.2226
the 943 times test_loss is 0.4569
0.918890544917579 0.9202043017247717 0.8404452690166976 0.8662674650698603 0.8051948051948052 0.8346153846153846
the 944 times train_loss is 0.2224
the 944 times test_loss is 0.4575
0.9189008711934765 0.9201666265880843 0.8423005565862709 0.8653465346534653 0.8107606679035251 0.8371647509578545
the 945 times train_loss is 0.2223
the 945 times test_loss is 0.4577
0.9192141015623656 0.920567795780684 0.8413729128014842 0.8636363636363636 0.8107606679035251 0.8363636363636363
the 946 times train_loss is 0.2223
the 946 times test_loss is 0.4590
0.9188871028256133 0.92033001026595 0.839517625231911 0.8645418326693227 0.8051948051948052 0.8338136407300673
the 947 times train_loss is 0.2223
the 947 times test_loss is 0.4613
0.9179646221787754 0.9195675560555822 0.8385899814471243 0.8642714570858283 0.8033395176252319 0.8326923076923077
the 948 times train_loss is 0.2223
the 948 times test_loss is 0.4569
0.918966270940827 0.9204412914908735 0.8413729128014842 0.8665338645418327 0.8070500927643784 0.8357348703170029
the 949 times train_loss is 0.2224
the 949 times test_loss is 0.4613
0.9187563033309123 0.9202560297164091 0.8404452690166976 0.869215291750503 0.8014842300556586 0.8339768339768339
the 950 times train_loss is 0.2226
the 950 times test_loss is 0.4547
0.9191418176310835 0.9204888399274733 0.8404452690166976 0.8633663366336634 0.8089053803339518 0.8352490421455938
the 951 times train_loss is 0.2228
the 951 times test_loss is 0.4637
0.9183191576512542 0.9197303294802951 0.8358070500927643 0.8649193548387096 0.7959183673469388 0.8289855072463767
the 952 times train_loss is 0.2232
the 952 times test_loss is 0.4543
0.9190282285962117 0.9205027145536689 0.8423005565862709 0.862475442043222 0.8144712430426716 0.8377862595419847
the 953 times train_loss is 0.2233
the 953 times test_loss is 0.4643
0.9183983257664678 0.9199380421279214 0.8348794063079777 0.8646464646464647 0.7940630797773655 0.8278529980657641
the 954 times train_loss is 0.2231
the 954 times test_loss is 0.4545
0.9187838400666388 0.92018087914696 0.8423005565862709 0.863905325443787 0.8126159554730983 0.8374760994263862
the 955 times train_loss is 0.2228
the 955 times test_loss is 0.4610
0.9187218824112542 0.92030496389125 0.8376623376623377 0.8669354838709677 0.7977736549165121 0.8309178743961352
the 956 times train_loss is 0.2223
the 956 times test_loss is 0.4574
0.9192313120221948 0.9207674168693152 0.8441558441558441 0.8702594810379242 0.8089053803339518 0.8384615384615385
the 957 times train_loss is 0.2219
the 957 times test_loss is 0.4571
0.9187149982273227 0.9201272611987288 0.8432282003710575 0.8670634920634921 0.8107606679035251 0.837967401725791
the 958 times train_loss is 0.2220
the 958 times test_loss is 0.4628
0.9179405275350146 0.9193608830142791 0.8358070500927643 0.8649193548387096 0.7959183673469388 0.8289855072463767
the 959 times train_loss is 0.2224
the 959 times test_loss is 0.4551
0.9187390928710834 0.9200182545150184 0.8423005565862709 0.863905325443787 0.8126159554730983 0.8374760994263862
the 960 times train_loss is 0.2225
the 960 times test_loss is 0.4614
0.9187838400666389 0.9201424655681448 0.8385899814471243 0.8686868686868687 0.7977736549165121 0.8317214700193424
the 961 times train_loss is 0.2222
the 961 times test_loss is 0.4567
0.9183983257664677 0.9196801537484111 0.8432282003710575 0.8656126482213439 0.8126159554730983 0.8382775119617224
the 962 times train_loss is 0.2220
the 962 times test_loss is 0.4602
0.9183329260191173 0.9196783573146315 0.839517625231911 0.8674698795180723 0.8014842300556586 0.8331726133076183
the 963 times train_loss is 0.2217
the 963 times test_loss is 0.4606
0.9185119148013396 0.9199039263807919 0.8404452690166976 0.8662674650698603 0.8051948051948052 0.8346153846153846
the 964 times train_loss is 0.2217
the 964 times test_loss is 0.4583
0.9186943456755278 0.9200498813086364 0.8432282003710575 0.8670634920634921 0.8107606679035251 0.837967401725791
the 965 times train_loss is 0.2218
the 965 times test_loss is 0.4630
0.9180024851903993 0.9194612806236347 0.8367346938775511 0.8622754491017964 0.8014842300556586 0.8307692307692308
the 966 times train_loss is 0.2220
the 966 times test_loss is 0.4586
0.9184947043415106 0.9198568648806213 0.8423005565862709 0.8682634730538922 0.8070500927643784 0.8365384615384616
the 967 times train_loss is 0.2220
the 967 times test_loss is 0.4636
0.9178131701322796 0.9194350647408164 0.8404452690166976 0.8648111332007953 0.8070500927643784 0.8349328214971209
the 968 times train_loss is 0.2220
the 968 times test_loss is 0.4593
0.9187907242505706 0.9199692661406342 0.8413729128014842 0.8709677419354839 0.8014842300556586 0.8347826086956522
the 969 times train_loss is 0.2223
the 969 times test_loss is 0.4619
0.9176032025223649 0.9194654830576213 0.8432282003710575 0.8585271317829457 0.8218923933209648 0.8398104265402844
the 970 times train_loss is 0.2232
the 970 times test_loss is 0.4662
0.9195755212187757 0.920681385315868 0.8348794063079777 0.8737060041407867 0.7829313543599258 0.8258317025440313
the 971 times train_loss is 0.2260
the 971 times test_loss is 0.4641
0.9165155014611679 0.9188741263268132 0.8367346938775511 0.8354898336414048 0.8385899814471243 0.8370370370370371
the 972 times train_loss is 0.2299
the 972 times test_loss is 0.4716
0.9197751625527932 0.9207574186385347 0.8274582560296846 0.8779443254817987 0.7606679035250464 0.8151093439363817
the 973 times train_loss is 0.2314
the 973 times test_loss is 0.4443
0.9196615735179212 0.9217477789278543 0.8450834879406308 0.8522727272727273 0.8348794063079777 0.8434864104967198
the 974 times train_loss is 0.2274
the 974 times test_loss is 0.4530
0.9180128114662969 0.920587441797008 0.8385899814471243 0.8585461689587426 0.8107606679035251 0.833969465648855
the 975 times train_loss is 0.2321
the 975 times test_loss is 0.4184
0.9223773840789478 0.9243728710379743 0.8367346938775511 0.8651911468812877 0.7977736549165121 0.8301158301158302
the 976 times train_loss is 0.2344
the 976 times test_loss is 0.4315
0.9192313120221945 0.9196748857802473 0.8320964749536178 0.8698347107438017 0.7810760667903525 0.823069403714565
the 977 times train_loss is 0.2311
the 977 times test_loss is 0.4374
0.91916935436681 0.9210826536660045 0.8385899814471243 0.8529980657640233 0.8181818181818182 0.8352272727272728
the 978 times train_loss is 0.2302
the 978 times test_loss is 0.4391
0.9227491300112556 0.9244952273464897 0.8432282003710575 0.8627450980392157 0.8163265306122449 0.8388941849380362
the 979 times train_loss is 0.2304
the 979 times test_loss is 0.4318
0.9230141710926233 0.9236306353433629 0.8423005565862709 0.8697394789579158 0.8051948051948052 0.8362235067437379
the 980 times train_loss is 0.2276
the 980 times test_loss is 0.4317
0.9209454738211695 0.9217071764413733 0.839517625231911 0.8689516129032258 0.7996289424860853 0.8328502415458937
the 981 times train_loss is 0.2301
the 981 times test_loss is 0.4344
0.9192829434016818 0.9208050690213403 0.839517625231911 0.857421875 0.8144712430426716 0.8353948620361561
the 982 times train_loss is 0.2267
the 982 times test_loss is 0.4300
0.9222190478485205 0.9236355891137055 0.8423005565862709 0.863905325443787 0.8126159554730983 0.8374760994263862
the 983 times train_loss is 0.2280
the 983 times test_loss is 0.4189
0.9238402731644183 0.9242879302377713 0.8506493506493507 0.8648648648648649 0.8311688311688312 0.847682119205298
the 984 times train_loss is 0.2272
the 984 times test_loss is 0.4320
0.9221226692734775 0.9224988247708985 0.8441558441558441 0.8793456032719836 0.7977736549165121 0.8365758754863813
the 985 times train_loss is 0.2274
the 985 times test_loss is 0.4358
0.9202501712440753 0.9217608478217727 0.8404452690166976 0.8633663366336634 0.8089053803339518 0.8352490421455938
the 986 times train_loss is 0.2267
the 986 times test_loss is 0.4459
0.917565339510741 0.9187108405335742 0.8339517625231911 0.8614457831325302 0.7959183673469388 0.8273866923818708
the 987 times train_loss is 0.2298
the 987 times test_loss is 0.4185
0.9245011548218545 0.9262005322260247 0.8534322820037106 0.8534322820037106 0.8534322820037106 0.8534322820037106
the 988 times train_loss is 0.2326
the 988 times test_loss is 0.4380
0.9234857376919396 0.9238690814766146 0.8358070500927643 0.8917748917748918 0.764378478664193 0.8231768231768232
the 989 times train_loss is 0.2381
the 989 times test_loss is 0.4033
0.9252756255141625 0.926627239377478 0.8515769944341373 0.8595825426944972 0.8404452690166976 0.849906191369606
the 990 times train_loss is 0.2312
the 990 times test_loss is 0.4068
0.9227835509309138 0.9240565378251755 0.8478664192949907 0.8654970760233918 0.8237476808905381 0.844106463878327
the 991 times train_loss is 0.2275
the 991 times test_loss is 0.4278
0.920880074073819 0.922466707836657 0.8311688311688312 0.8695652173913043 0.7792207792207793 0.821917808219178
the 992 times train_loss is 0.2310
the 992 times test_loss is 0.4174
0.9240330303145039 0.9249123314020662 0.8487940630797773 0.8601532567049809 0.8330241187384044 0.8463713477851085
the 993 times train_loss is 0.2261
the 993 times test_loss is 0.4202
0.9254442880204874 0.9263935979411375 0.8469387755102041 0.8555133079847909 0.8348794063079777 0.8450704225352114
the 994 times train_loss is 0.2285
the 994 times test_loss is 0.4383
0.921341314397238 0.9212362164785248 0.8348794063079777 0.8617234468937875 0.7977736549165121 0.8285163776493255
the 995 times train_loss is 0.2288
the 995 times test_loss is 0.4267
0.9211175784194603 0.9211541758739916 0.8367346938775511 0.8651911468812877 0.7977736549165121 0.8301158301158302
the 996 times train_loss is 0.2253
the 996 times test_loss is 0.4083
0.9248040589148461 0.9257430105250978 0.8460111317254174 0.8579654510556622 0.8293135435992579 0.8433962264150944
the 997 times train_loss is 0.2281
the 997 times test_loss is 0.4248
0.9222224899404863 0.9230392978052102 0.8450834879406308 0.872 0.8089053803339518 0.8392685274302214
the 998 times train_loss is 0.2254
the 998 times test_loss is 0.4344
0.9210452944881782 0.9213432490272574 0.8358070500927643 0.8709016393442623 0.7884972170686456 0.8276533592989289
the 999 times train_loss is 0.2257
the 999 times test_loss is 0.4282
0.9219367963073237 0.9215963805030901 0.8404452690166976 0.8590998043052838 0.8144712430426716 0.8361904761904762
File saved successfully with AUC 0.9492 and seed 9854 in the folder 'saved_predictions'.

